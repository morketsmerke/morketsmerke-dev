<!DOCTYPE html>
	<html>
		<head>
			<meta charset="utf-8" />
			<link rel="icon" type="image/png" href="https://i.ibb.co/khy45hh/mm.png">
			<style>
				.code-block {
					display: block;
					background-color: silver;
					font-family: monospace;
					font-weight: bolder;
					text-align: left;
				}
				.code-inline {
					background-color: silver;
					font-family: monospace;
					font-weight: bolder;
				}
				ul {
					text-align: left;
				}
        p { text-align: justify; }
        .toc { list-style-type: none; }
			</style>
		</head>
		<body style="font-family: monospace;" >
<pre>
    __    _                       ____            __     __                      
   / /   (_)___  __  ___  __     / __ \____  ____/ /____/ /_____ __      ____  __
  / /   / / __ \/ / / / |/_/    / /_/ / __ \/ __  / ___/ __/ __ `/ | /| / / / / /
 / /___/ / / / / /_/ />  <_    / ____/ /_/ / /_/ (__  ) /_/ /_/ /| |/ |/ / /_/ / 
/_____/_/_/ /_/\__,_/_/|_(_)  /_/    \____/\__,_/____/\__/\__,_/ |__/|__/\__, (_)
                                                                        /____/   

</pre>
<p style="margin: 0; padding: 0; outline: 0; font-size: 18pt;">
	&#9760;&nbsp;<a href="https://morketsmerke.github.io">morketsmerke</a>&nbsp;&#9760;
</p>
			<div style="margin-left: auto; margin-right: auto; width: 80%;">
        <h1>Linux. Podstawy.</h1>
        <div>
          <h2>Spis treści</h2>
          <ul class="toc">
            <li><a href="#1.howlinuxismade">1. Budowa systemu Linux<a>
              <ul class="toc">
                <li><a href="#1.1.hardware">1.1. Sprzęt</a>
                  <ul class="toc">
                    <li><a href="#1.1.1.ram">1.1.1. Pamięć operacyjna</a>
                  </ul>
                </li>
                <li><a href="#1.2.kernel">1.2. Jądro</a>
                <li><a href="#1.3.userspace">1.3. Przestrzeń użytkownika</a>
                <li><a href="#1.4.users">1.4. Użytkownicy</a>
              </ul></li>
              <li><a href="#2.linuxbasics">2. Podstawy obsługi Linuksa</a>
                <ul class="toc">
                  <li><a href="#2.1.shells">2.1. Powłoka</a></li>
                  <li><a href="#2.2.shellusage">2.2. Korzystanie z powłoki</a>
                    <ul class="toc">
                      <li><a href="#2.2.1.catcommand">2.2.1. Polecenie cat</a></li>
                      <li><a href="#2.2.2.stdinstdout">2.2.2. Standardowe wejście i standardowe wyjście</a></li>
                    </ul></li>
                  <li><a href="#2.3.basicscommands">2.3. Podstawowe polecenia</a></li>
                  <li><a href="#2.4.commandsworksondir">2.4. Polecenia działające na katalogach</a>
                    <ul class="toc">
                      <li><a href="#2.4.1.globbing">2.4.1. Nazwy wieloznaczne</a></li>
                    </ul></li>
                  <li><a href="#2.5.proxycommands">2.5. Polecenia pośredniczące</a></li>
                  <li><a href="#2.6.passwdandchsh">2.6. Zmiana hasła i powłoki</a></li>
                  <li><a href="#2.7.dotfiles">2.7. Plik z kropką</a></li>
                  <li><a href="#2.8.shellandenvvars">2.8. Zmienne środowiskowe i powłoki</a></li>
                  <li><a href="#2.9.path">2,9, Ścieżka poleceń</a></li>
                  <li><a href="#2.10.specialchars">2.10. Znaki specjalne</a></li>
                  <li><a href="#2.11.commadlineedit">2.11. Edycja wiersza poleceń</a></li>
                  <li><a href="#2.12.texteditors">2.12. Edytory tekstu</a></li>
                  <li><a href="#2.13.gettinghelp">2.13. Uzyskiwanie pomocy</a></li>
                  <li><a href="#2.14.shellio">2.14. Wejście i wyjście powłoki</a>
                    <ul class="toc">
                      <li><a href="#2.14.1.stderr">2.14.1. Standardowy strumień błędów</a></li>
                      <li><a href="#2.14.2.stdin">2.14.2. Przekierowanie standardowego wejścia</a></li>
                    </ul></li>
                  <li><a href="#2.15.readingerrors">2.15. Odczytwanie komunikatów o błędach</a></li>
                  <li><a href="#2.16.manipulatingprocesses">2.16. Przeglądanie procesów i manipulowanie nimi</a>
                    <ul class="toc">
                      <li><a href="#2.16.1.processkilling">2.16.1. Przerywanie działania procesów</a></li>
                      <li><a href="#2.16.2.jobcontrol">2.16.2. Kontrola zadań</a></li>
                      <li><a href="#2.16.3.processinbg">2.16.3. Procesy działające w tle</a></li>
                    </ul></li>
                  <li><a href="#2.17.filemodeandpermissions">2.17. Tryb pliku i uprawnienia</a>
                    <ul class="toc">
                      <li><a href="#2.17.1.modifypermissions">2.17.1. Modyfikacja uprawnień</a></li>
                      <li><a href="#2.17.2.sylinks">2.17.2. Dowiązania symboliczne</a></li> 
                    </ul></li>
                  <li><a href="#2.18.archvesandcompression">2.18. Archiwizowanie i kompresowanie danych</a>
                    <ul class="toc">
                      <li><a href="#2.18.1.tarprogram">2.18.1. Program tar</a></li>
                      <li><a href="#2.18.2.gzipprogram">2.18.2. Program gzip</a></li>
                      <li><a href="#2.18.3.compressedarchives">2.18.3. Skompresowane archiwa</a></li>
                      <li><a href="#2.18.4.othercommpression">2.18.4. Inne metody kompresji</a></li>
                    </ul></li>
                  <li><a href="#2.19.filesystemhierarchy">2.19. Hierarchia katalogów</a>
                    <ul class="toc">
                      <li><a href="#2.19.1.othermainsubdirs">2.19.1. Pozostałe katalogi główne</a></li>
                      <li><a href="#2.19.2.usrdirectory">2.19.2. Katalog /usr</a></li>
                      <li><a href="#2.19.3.kernelplace">2.19.3. Umiejscowienie jądra w systemie</a></li>
                    </ul></li>
                  <li><a href="#2.20.runitasroot">2.20. Uruchamianie poleceń przez superużytkownika</a>
                    <ul class="toc">
                      <li><a href="#2.20.1.sudoersfile">2.20.1. Plik /etc/sudoers</a></li>
                    </ul></li>
                  <li><a href="#2.21.summary">2.21. Podsumowanie</a></li>
                </ul></li>
              <li><a href="#3.devices">3. Urządzenia</a>
                <ul class="toc">
                  <li><a href="#3.1.devicefiles">3.1. Pliki urządzeń</a>
                  <li><a href="#3.2.sysfsdevicepath">3.2. Ścieżka urządzeń sysfs</a></li>
                  <li><a href="#3.3.ddcommand">3.3. Polecenie dd</a></li>
                  <li><a href="#3.4.namingsummary">3.4. Podsumowanie nazewnictwa urządzeń</a>
                    <ul class="toc">
                      <li><a href="#3.4.1.makedev">3.4.1. Tworzenie plików urządzeń</a></li>  
                    </ul></li>
                  <li><a href="#3.5.udev">3.5. System udev></a>
                    <ul class="toc">
                      <li><a href=#3.5.1.devtmpfs">3.5.1. System plików devtmpfs</a></li>
                    </ul></li>
                </ul></li>
              <li><a href="#4.disksandfs">4. Dyski i systemy plików</a>
                <ul class="toc">
                  <li><a href="4.1.paritioning">4.1. Partycjonowanie</a>
                    <ul class="toc">
                      <li><a href="4.1.1.listingpartitiontable">4.1.1. Przeglądanie tablicy
                        partycji</a></li>
                      <li><a href="4.1.2.modifypartition">4.1.2. Modyfikowanie tablicy partycji</a></li>
                    </ul></li>
                  <li><a href="4.2.filesystems">4.2. Systemy plików</a>
                    <ul class="toc">
                      <li><a href="#4.2.1.fstypes">4.2.1. Typy systemów plików</a></li>
                      <li><a href="#4.2.2.createfs">4.2.2. Tworzenie systemów plików</a></li>
                      <li><a href="#4.2.3.mountfs">4.2.3. Montowanie systemów plików</a></li>
                      <li><a href="#4.2.4.uuid">4.2.4. Identyfikator UUID systemu plików</a></li>
                      <li><a href="#4.2.5.diskcache">4.2.5. Buforowanie dysku i systemu pliku</a></li>
                      <li><a href="#4.2.6.mountoptions">4.2.6. Opcje montowania</a></li>
                      <li><a href="#4.2.7.remount">4.2.7. Ponowne montowanie systemu plików</a></li>
                      <li><a href="#4.2.8.fstabfile">4.2.8. Tablica systemów plików /etc/fstab</a></li>
                      <li><a href="#4.2.9.fscapacity">4.2.9. Pojemność systemu plików</a></li>
                      <li><a href="#4.2.10.fsrescue">4.2.10. Sprawdzenie i naprawianie systemu plików</a></li>
                      <li><a href="#4.2.11.specialfs">4.2.11. Systemy plików o specjalnym znaczeniu</a></li>
                    </ul></li>
                  <li><a href="#4.3.swapspace">4.3. Przestrzeń wymiany</a>
                    <ul class="toc">
                      <li><a href="#4.3.1.swappartition">4.3.1. Wykorzystanie partycji jako przestrzeni wymiany.</a></li>
                      <li><a href="#4.3.2.swapfile">4.3.2. Wykorzystanie pliku jako przestrzeni wymiany</a></li>
                      <li><a href="#4.3.3.swapsize">4,3,3, Jak dużej przestrzeni wymiany potrzebuje</a></li>
                    </ul></li>
                  <li><a href="#4.4.fsfuture">4.4. Przyszłość systemów plików</a></li>
                </ul></li>
            <li><a href="#5.startingkernel">5. Uruchamianie jądra Linux</a>
              <ul class="toc">
                <li><a href="#5.1.dmesg">5.1. Komunikaty rozruchowe</a></li>
                <li><a href="#5.2.kernelinitandbootoptions">5.2. Inicjowanie jądra i opcje rozruchu</a></li>
                <li><a href="#5.3.kernelparameters">5.3. Parametry jądra</a></li>
                <li><a href="#5.4.bootloaders">5.4. Programy rozruchowe</a></li>
                <li><a href="#5.5.practicalusagegrub">5.5. Praktyczne użytcie programu rozruchowego GRUB</a>
                  <ul class="toc">
                    <li><a href="#5.5.1.firstcontactwithgrub">5.5.1. Pierwszym kontakt z GRUB</a></li>
                    <li><a href="#5.5.2.grubinstallationinbiosmode">5.5.2. Instalacja GRUB w trybie BIOS</a></li>
                    <li><a href="#5.5.3.grubinstallationinefimode">5.5.3. Instalacja GRUB w trybie UEFI</a></li>
                    <li><a href="#5.5.4.changegruborder">5.5.4. Zmiana kolejności w menu GRUB</a></li>
                  </ul></li>
                <li><a href="#5.6.usagerefindasbootmanager">5.6. Wykorzystanie rEFInd jako menedżer rozruchu.</a></li>
              </ul></li>
            <li><a href="#6.startinguserspace">6. Uruchamianie przestrzeni użytkownika</a>
              <ul class="toc">
                <li><a href="#6.1.initprocess">6.1. Proces init</a></li>
                <li><a href="#6.2.runlevels">6.2. Poziomy uruchomienia</a></li>
                <li><a href="#6.3.initidentify">6.3. Rozpoznawanie programu typu init</a></li>
                <li><a href="#6.4.introductiontochoosedinitprograms">6.4. Wprowadzenie do wybranych programów typu init</a>
                  <ul class="toc">
                    <li><a href="#6.4.1.systemd">6.4.1. Systemd</a></li>
                    <li><a href="#6.4.2.sysvinit">6.4.2. Proces typu init w stylu System V</a></li>
                  </ul></li>
                <li><a href="#6.5.shutdownthesystem">6.5. Wyłączenie systemu</a></li>
                <li><a href="#6.6.initramfs">6.6. Początkowy system plików w pamięci RAM</a></li>
                <li><a href="#6.7.oneusermode">6.7. Tryb jednego użytkownika</a></li> 
              </ul></li>
          </ul>
        </div>
        <p>
          Opisywany tutaj materiał będzie kompatybilny z dystrybucjami 
          pochodnymi od GNU/Linux Debian zarówno tymi opartymi na 
          <em>systemd</em> jak <em>sysvinit</em> oraz tymi z rodziny
          <em>RHEL</em>/<em>Fedora</em>/<em>CentOS</em>. 
        </p>
        <p>
          GNU/Linux czy raczej sam Linux? Sama nazwa, jest już tematem dość
          kontrowersyjnym. Ludzie związani z projektem GNU twierdzą, że ta
          pierwsza liczba jest właściwa ponieważ wskazuje ona na to, że isotne
          elemnty projektu GNU zostały wykorzystane do stworzenia tego systemu.
          W mowie potocznej jednak przyjęło się użycie tej drugiej nazwy. Jest
          to jedno, łatwe do zapamiętania słowo. Jeśli mówimy następujące
          zdanie wyrażające chęć zainstalowania na jakiejś maszynie omawianego
          tutaj systemu, mówimy że "zainstalujemy jakiegoś Linuksa". Słowo
          "jakiegoś" zostało tu użyte w kontekscie wyboru konkretnej
          dystrybucji. Co to dystrybucja wyjaśnie za chwilę. Bez projektu GNU
          niebyło by Linuksa. Wydaje mi się, że każdy kto jest nieco bardziej
          związany z tym środowiskiem o tym wie. Ja również jestem tego świadom
          dla tego też w tym dokumencie użyje nazwy Linux. Poprostu.
        </p>
        <h1 id="1.howlinuxismade">1. Budowa systemu Linux</h1>
        <p>
          Nie zagłebiając się w szczegóły, to Linux składa się z 
          <strong>jądra</strong> oraz
          <strong>przestrzeni użytkownika</strong>. Oba kompomenty rezydują w 
          pamięci więc
          wiele, nie które teksty popularno-naukowe mogą włączać pamięć lub
          ogólnie sprzęt do składowych systemu operacyjnego Linux, w mojej
          opinii jest raczej cecha wykorzystywanych przez nas komputerów
          konwencjonalnych. 
        </p>
        <p>
          Mówiąc o jądrze możemy wskazać konktretny program, konkretny plik.
          W przypadku przestrzeni użytkownika, w systemie nie istnieje żaden
          namacalny byt cyfrowy jak w przypadku jądra. Przestrzeń użytkownika
          jest bowiem <strong>warstwą abstrakcji</strong> - czyli terminem,
          bądź założeniem wykorzystywanym w celu określenia czynności, funkcji,
          zjawiska bez wdawania się w szczegóły. Przestrzeń użytkownika jest
          miejscem uruchamiania <strong>procesów</strong> użytkownika. Procesy
          to nic innego jak wystąpienia programów uruchomionych przez
          użytkownika. Nie wszystkie procesy są programami użytkownika w
          dosłownym tych słów znaczeniu. Część tych procesów to programy
          wspomagające wykorzystanie komputera i jego zasobów. Bez nich systemy
          operacyjne dalej mogły by spełniać swoją rolę, jednak nie miały by
          powszechnie znanej nam dzisiaj formy. Przestrzeń użytkownika  składa 
          się z wielu ogólno dostępnych kompnentów ich istnienie w danej wersji
          systemu oraz ich konfiguracja sprawia, iż nie mamy doczynienia z
          gotowym jednolitym produktem, ale z dystrybucją. Z jedną z wersji, 
          gdzie ktoś
          wziął jądro, które jest ogolno dostępne i skomponował przestrzeń
          użytkownika. Obecnie na rynku mamy dostępnych ok. 600 dystrybucji.
          Wiekszość z nich to pochodne innych, oryginalnych rozwiązań
          rozwijanych przez setki osób na całym świecie. Kilka takich głównych
          dystrybucji, znajduje się w tabeli poniżej. Przejrzałem większość z
          nich, a z częsci osobiście korzystałem. 
        </p>
        <table border="1">
          <thead>
            <th>Logo</th>
            <th>Nazwa</th>
            <th>Opis</th>
          </thead>
          <tbody>
            <tr>
              <td><img src="https://i.ibb.co/GspTqqK/linux-mint-logo32.png" alt="linux-mint-logo32" border="0"></td>
              <td>Linux Mint</td>
              <td>
                Dystrybucja bardzo przyjazna użytkownikowi. Wykorzystywana 
                przez nowych niedoświadczonych użytkowników system Linux. 
                Pod czas
                instalacji mogą być instalowane nie wolne moduły oraz nie
                wolne oprogramownie. Jej głównym zadaniem jest sprzyjanie
                użytkownikowi i umożliwienie mu wykorzystanie Linuksa przy
                codziennym wykorzystaniu komputera. Mint rozwijany jest przez
                społeczność zebraną wokół niego.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/ckrkfjX/ubuntu-logo32.png" alt="ubuntu-logo32" border="0"></td>
              <td>Ubuntu</td>
              <td>
                  Podobnie jak Linux Mint, Ubuntu również jest skierowane dla
                  osób ceniących sobie wygodne i prostę rozwiązania. Jest
                  przyjazna użytkownikowi, ma nieco bardziej konserwatywne
                  podejście do ideii wolnego oprogramowania, jądro może
                  zawierać nie wolne moduły, jednak zamknięte oprogramowanie
                  nie jest domyślnie instalowane. Ubuntu rozwijane jest przez 
                  firmę
                  Canonical. Jej technologię są wdrażane do Ubuntu, dzięki
                  czemu może ona uchdzić za system klasy <em>enterprise</em> 
                  wśród
                  dystrybucji opartych o GNU/Linux Debian. Poza wersją na
                  komputery biurkowe istnieją również wersja skierowana
                  na serwery oraz inne wersje z preinstalowanymi różnymi
                  środowiskami graficznymi czy wersja skierowana do obróbki
                  multimediów zawierająca pozwalające do tego oprogramowanie.
                  Społeczność zebrana
                  wokół systemu Linux zarzuca jej siłowe próby wdrożenia
                  manedżera oprogramowania <em>Snap</em>, rozwijanego przez tę 
                  firmę
                  przez co może ona pretendować do stopniowego zarzucenia
                  klasycznego schematu dystrybucji pakietów rozwijanego wraz
                  z GNU/Linux Debian.
              </td> 
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/v4026kk/fedora-logo32.png" alt="fedora-logo32" border="0"></td>
              <td>Fedora Linux</td>
              <td>
                  Fedora jest dystrybucją skierowaną do różnej maści
                  użytkowników, ponieważ istnieje w kilku głównych wersjach.
                  oraz wiele wersji pobocznych tzw. <em>spins</em>. Fedora ma
                  najprzyjźniejszy instalator chyba ze wszystkich możliwych
                  dystrybucji. Wymaga on głównie wybrania miejsca instalacji
                  i kliknięcia przycisku dalej. Fedora została stworzona i jest
                  rozwiajana przez firme Red Hat Inc. (obecnie IBM) jako
                  <em>upstream</em> (poligon doświadczalny dla zmian), dla 
                  glównego produktu tej firmy Red Hat Enterprise Linux - 
                  płatnej dystrybucji skierowanej do środowisk produkcyjnych 
                  (100$ rocznie). Jest to system o dużej stabilości ze
                  wsparciem dla najnowszego sprzetu. Fedora również
                  charakteryzuje się wprowadzeniej jako pierwsza środowiska
                  GNOME w najnowszej wersji 41 oraz innych nowych technologi
                  wśród otwartego oraz wolnego oprogramowania. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/Q965txs/debian-logo32.png" alt="debian-logo32" border="0"></td>
              <td>GNU/Linux Debian</td>
              <td>
                  Debian jest jedną z pierwszy dostępnych dystrybucji, początek
                  jej istnienia jest datowany na 1993 rok. Dystrybucja 
                  konserwatywna, posiadała w pierwszych latach swojego 
                  istnienia aprobatę FSF (Free Software Fundation). Jednak
                  została ona wycofana, za zezwolenie na instalację zamkniętego
                  oprogramowania. Kernel przygotowywany przez twórców tej
                  dystrybucji pozbawiony jest tzw. blobów binarnych (nie
                  wolnych prekompilowanych modułów, używanych przy budowaniu
                  jądra.) Bloby najczęściej dotyczą sterowników sprzętu.
                  Dystrybucja charkteryzuje się wysoką stabilnościa
                  porównywalną z RHEL, wsparciem dla starszego sprzętu. Jedną
                  z cech, która może odstraszać potencjalnych użytkowników
                  od niej jest długi cykl wydawniczy (co dwa lata) oraz
                  używanie sprawdzone oprogramowania czy technologii (pozostaje
                  dość mocno w tyle jeśli chodzi o najnowsze wersje
                  oprogramowania). Wydaje mi się, że niema
                  stabilniejszego gotowego rozwiązania niż GNU/Linux Debian.
                  Debian wymaga nieco większego zaawansowania niż dystrybucje
                  podane do tej pory. Stosowany jest częściej w środowiskach
                  produkcyjnych niż np. Ubuntu. Rozwój Debiana opiera się
                  na zaangażowaniu społeczności z całego świata.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/MpCcKqy/arch-linux-logo32.png" alt="arch-linux-logo32" border="0"></td>
              <td>Arch Linux</td>
              <td>
                  Dystrybucja skierowana do zaawansowanych użytkowników.
                  Charakteryzuje się wysoką konfigurowalnością oraz
                  dostępnością najnowszych wersji oprogramowania. Nie posiada
                  oficjalnego instalatora, choć można pobrać skrypt z sieci.
                  Instalacji dokonuj się ręcznie, wpisującac kolejne polecenia
                  z podręcznika instalacji w środowisku LiveCD, gdzie
                  przygotowuje się dysk, pobiera się pakiety i je konfiguruje.
                  Instalacja i konfiguracji Arch Linux nie jest tak
                  pracochłonna jak innych dystrybucji, można by powiedzieć,
                  meta-dystrybucji. Dość ciekawą cechą jest społeczność zebrana
                  wokół niej, która przechwalająca się swoją wyższością na
                  innymi (ponieważ przebrneli przez proces instalacji) 
                  używając frazy "I use Arch BTW.". Dystrybucja rozwijana
                  jest przez społeczność na całym świecie.
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/vz98yMx/void-linux-logo32.png" alt="void-linux-logo32" border="0"></td>
              <td>Void Linux</td>
              <td>
                  Nie zależna dystrybucjna, trochę odmienna od inny dystrybucji
                  głównego nurtu. Systemd zastąpiono programem <em>runit</em>,
                  zamiast OpenSSL, użyto projektu OpenBSD LibreSSL jak jedyna
                  z dystrybucji Linuksa. Kernel Void-a pozbawiony jest blobów,
                  a domyślna instalacja zawiera tylko wolne oprogramowanie,
                  posiada on jednak oficjalne repozytorium z zamkniętym
                  oprogramowaniem. Instalacja pakietów opiera się stworzonym
                  dla Void menedżerze pakietów XBPS. Pakiety są wydawane stylu
                  <em>rolling release</em>, co daje szybkie i stabline
                  aktualizacje. Obok standardowej biblioteki języka C -
                  GNU libc, mamy również bibliotekę <em>musl</em>. Za pomoca
                  programu <em>xbps-src</em> możemy tworzyć z kodu źródłowego
                  własne pakiety XBPS. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/0QsPfPh/gentoo-linux-logo32.png" alt="gentoo-linux-logo32" border="0"></td>
              <td>Gentoo Linux</td>
              <td>
                  Gentoo jest dystybucją na tyle zaawansowaną, że można by się
                  pokusić o nazwanie jej meta-dystrybucją. Jest ona bowiem
                  jedną z najbardziej konfigurowalnych dystrybucji. Jedną z
                  ciekawszych czynności, jakie należy wykonać podczas
                  instalacji, to ręczna kompliacja jądra. Dystrybucja
                  skierowana do jeszcze bardziej zaawansowanych użytkowników
                  niż w przypadku Arch Linux. Instalacja Gentoo na maszynie
                  wirtualnej wraz z poradnikiem, zajeło mi to jakieś dwie
                  godziny. 
              </td>
            </tr>
            <tr>
              <td><img src="https://i.ibb.co/hKwFYQh/lfs-logo32.jpg" alt="lfs-logo32" border="0"></td>
              <td>Linux from scratch</td>
              <td>
                  LFS to w zasadzie projekt, a niżejli sama dystrybucja.
                  Umożliwia on stworzenie oraz skonfigurowanie własnej
                  dystrybucji. Na stronie projektu zawarte są wskazówki, co
                  należy zrobić, aby stworzyć rozwiązanie najbardziej
                  elastyczne dla siebie. LFS z pewnością może nosić miano
                  meta dystrybucji.
              </td>
            </tr>
          </tbody>
        </table> 
        <p>
          W powyższej tabeli przedstawiłem  dystrybucje, na które
          warto zwrócić uwagę. Teraz prawdopodobnie czekać będzie Cię duży
          dylemat, którą wybrać. W pierwszej kolejności ważny jest sprzęt,
          na którym będziemy z tego systemu korzystać. Część sprzętu, 
          z którego chcemy korzystać może 
          nie działać <em>out of box</em>, wowczas potrzebne będą sterowniki,
          które mogą być własnościowe (nie wolne, generalnie być zamkniętym 
          oprogramowaniem), jeśli zależy nam na prywatności, to lepiej upewnić
          się z jakiego rodzaju sprzętem będzie mieć doczynienia, ponieważ 
          każde zamknięte oprogramowanie można teoretycznie uznać za
          oprogramowanie szkodliwe. Dobrym wyborem może być zakup Thinkpada z
          przed 2008 roku. Wówczas będziemy mogli bez obaw wybrać Debiana i
          zainstalować np. XFCE (to dość lekkie środowisko graficzne, nadające
          się do codziennej pracy, bez zniechęcania się). Kolejną rzeczą do
          wyboru dystrybucji jest zapał do pracy. Mimo iż opisując dystrybucje
          napisałem że ta jest dla początkujących, a ta dla zaawansowanych to 
          żadna z
          nich nie jest ani dla jednych ani dla drugich. Obsługa czego kolwiek
          związanego z komputerami wymaga przeczytania dokumentacji ze
          zrozumieniem i umiejętności radzenie sobie z ewentualnymi problemami.
          Dlatego dlaczego by nie wybrać Gentoo, zainstalować go 
          z poradnikiem, skonfigurować, a wrazie problemów użyć Googla, lub
          poprość kogoś ze społeczności o pomoc.  
        </p>
        <p>
          Dość częstym zjawiskiem, wśród społeczności użytkowników Linuksa jest
          tzw. <em>distro-hopping</em>, czyli przesiadanie się z jednej
          dystrybucji na drugą. Jest to normalne zjawisko, chciaż można
          powszechną opinia jego jest raczej negatywna, głównym argumentem
          oponetów jest stwierdzenie, że przez to nie uczymy się niczego. Moim
          zdaniem, możemy dojść do wniosku, że tak naprawdę nie ma dystrybucji
          tylko produkt w ciągłej ewolucji z dostępnym takim a takim
          oprogramowaniem. Nie mam mendżera pakietów, mam program do instalacji
          i konfiguracji oprogramowania, nieważne czy jest apt, dnf, yum czy
          pacman. Mam stronę podręcznika i znajduj sobie potrzebne opcje. Mam
          dostęp do internetu, i wystarczy wyszukać konkretną potrzebną 
          czynność np.: "Remove packages with all dependencies pacman". I mam
          gotowy wynik. Wiele miesięcy błądziłem słuchając mendrców jak RMS
          (<em>Richard Matthew Stallman</em>). Myślcie samodzielnie, 
          przeskakujcie z distro na distro i bawcię się dobrze.
        </p>
        <h2 id="1.1.hardware">1.1. Sprzęt</h2>
        <p>
          Sprzęt sam w sobie nie mozę wchodzić z skład systemu operacyjnego,
          to jego elementy jak pamieć operacyjna, procesor czy pamięć masowa
          odgrywają w nim bardzo ważna rolę.
        </p>
        <h3 id="1.1.1.ram">1.1.1. Pamięć operacyjna</h3>
        <p>
          W działaniu systemów operacyjnych takich jak Linux, najważniejszym
          komponentem sprzętowym może być pamięć operacyjna, ponieważ to w
          niej rezyduje jądro oraz przestrzeń użytkownika. Dane zapisane w
          pamięci nie są niczym innym jak zbiorem zer i jedynek określanych
          mianem <strong>bitów</strong> (najmniejsze przetwarzanej ilości
          informacji). Procesy oraz jądro są jednymi z takich zbiorów. Takie
          zbiory określa się mianem <strong>obrazu</strong>. 
        </p>
        <h2 id="1.2.kernel">1.2. Jądro</h2>
        <p>
          Jądro Linux jest to nadrzędy proces w całym systemie, realizuje swoje
          działania w czterech obszarch funkcjonalności systemu operacyjnego.
        </p>
        <ul>
          <li><strong>Zarządzanie procesami</strong> - jądro jest
            odpowiedzialne za uruchamianie, wstrzymywanie, ponowne uruchomienie
            oraz kończenie pracy procesów. Korzystając ze współczesnych
            systemów operacyjnych możemy mieć wrażenie uruchomione przez nas
            programy (a co za tym idzie ich procesy) mogą działać jednocześnie.
            Dzieje się tak dlatego, iż jądro uruchamia kod procesu na ułamek
            sekundy, po upłynięciu danego przez jądro <strong>wycinka czasu</strong>
            stan procesora wykonującego kod danego procesu zapisywany jest
            w pamięci, a jądro wybiera kolejny proces i ładuje stan procesora
            po czym wznawia jego wykonanie. Tych czynności jest znacznie więcej
            zostało tu wymionionych. Te
            czynności nazywane są <strong>przełączaniem kontekstu</strong>.
            Na współczesnych procesorach dzieje się to tak szybko, że możemy
            mieć złudzenie <strong>wielozadaniowości</strong>. W przypadku 
            maszyn wielordzeniowych jak i wieloprocesorowych jądro nie musi
            zwalniać wykorzystywanego procesora (rdzenia), ale robi to aby
            jak najlepiej wykorzystać zasoby.</li>
          <li><strong>Zarządzanie pamięcią</strong> - każdy proces jest obrazem
            w pamięci, każdy proces również potrzebuje pamięci na swoje
            obliczenia. Zadaniem jądra jest przydzielanie, zwalnianie jak i
            ochrona (przed tym aby proces nie uzyskał dostępu do obszaru
            innego procesu) przekazanych procesom obszarów. Czynności z tym
            związane są dość złożone, ale jądro może posiłkować się 
            rozszerzenim MMU we współczesnych procesorach. Pozwala ono podczas
            dzielenia pamięci wykorzystać metodę <strong>pamięci wirtualnej</strong>,
            polegającej na zamianie adresów pamięci, przez co proces jest
            skonfigurowany, że "tak jakby" miał do dyspozycji całą pamięć
            fizyczną maszyny. Zamiana adresów wiąże się z potrzebą posiadania
            map (czy też tabel), pozwalających na odzorowanie adresów, co
            dokłada czynność aktualizacji mapy podczas przełączania kontekstu.
            Mapy adresów nazywane są <strong>tablicami stron</strong>.
          <li><strong>Sterowniki urządzeń</strong> - zadaniem sterowników
            jest dostarczenie identycznego interfejsu do komunikacji z
            poszczególnymi urządzeniami zainstalowanymi w komputerze. Za racji
            to iż swobodny dostęp do sprzetu jest potencjalnie niebezpieczny,
            to jaka kolwiek próba komunikacji z urządzeniem odbywać się
            zawsze będzie za pośrednictwem jądra systemu. Sterowniki w systemie
            Linux są częścią jądra, nie oznacza to jednak, że nie możemy
            jakiegoś brakującego do instalować. Sterowniki są przechowywane w
            postaci modułów, które są ładowane podczas uruchamiania jądra, a
            nie które znich mogą być ładowane podczas pracy systemu.</li>
          <li><strong>Wywołania systemowe</strong> - są to funkcje udostępnione
            przez jądro procesom użytkownika. Wywołania realizują zadania,
            które są trudne do zrealizowania przez procesy użytkownika lub w
            ogóle nie wykonalne. Przykładem wykonywania wywołań systemowych
            jest obsługa plików (otwieranie, odczyt czy zapis), innymi
            bardzo często wykorzystywanymi wywołaniami są <em>fork()</em> oraz
            <em>exec()</em>, wykonywane są za każdym wydanym poleceniem w
            powłoce.</li> 
        </ul>
        <p>
          Inną ciekawą cechą jądra są <strong>pseudourządzenia</strong>.
          Procesy widzą takie urządenia jak każde inne, jednak występują on
          wyłącznie w warstwie programowej, dzięki temu nie muszą być częścią
          jądra, ale ze względów praktycznych się je tam umieszcza. Inna
          implementacja urządzenia <em>/dev/random</em> - służacego
          do generowania liczb pseudolosowych, które jest urządzeniem 
          programowym mogłoby nie być zbyt bezpieczne.
        </p>
        <h2 id="1.3.userspace">1.3. Przestrzeń użytkownika</h2>
        <p>
          Przestrzeń użytkownika formalnie jest obszarem pamięci, w którym
          spedzimy 99% czasu pracy na Linuksie. Wewnątrz przestrzeni
          użytkownika znajdują się procesy definiujące dystrybucje wykonujące
          różne zadania dla użytkownika, teoretycznie są one wobec siebie
          równe, to jednak przestrzeń użytkownika można podzielić na trzy
          warstwy, na której warstwie będzie znajdować się proces zależy jak
          bardzo skomplikowane zadania wykonuje. Przeglądarka sieci WWW, może
          się taka nie wydawać ale to potężny subsystem więc będzie znajdować
          na najwyższej warstwie, z kolei proces służący za rejestrowanie
          logów, tzw. protokół diagnostyczne będzie znajdować się na najniższej
          warstwie blisko jądra, ponieważ nie jest on zbyt skomplikowany w
          porównaniu do na przykład przeglądarki, warstwa środkowa
          zarezerowana jest dla różnej maści serwerów. Najproście rzecz ujmując
          podstawowe usługi znajdują się na najniższej warstwie, usługi
          pomocnicze na warstwie środkowej, a aplikacje, które kontroluje już
          sam użytkownik będą znajdować się na samej górze. Procesy mogą
          komunikować się z innymi procesami o ile te znajdują się na tym
          samym lub niższym poziomie. Używanie tego rozdzaju podziału, może
          być kłopotliwe ponieważ obecne serwery nie są już tak prostym
          oprogramowaniem więc powinny znajdować się tej samej warstwie co
          przeglądarka czy klient pocztowy, jednak to te aplikacje mogą
          wykorzystywać serwery do realizacji zadań użytkownika, więc ich
          miejsce jest raczej na warstwie centralnej (środkowej).
        </p>
        <h2 id="1.4.users">1.4. Użytkownicy</h2>
        <p>
          Użytkownicy w Linksie są odwzorowaniem rzeczywistych obiektów, czyli
          <em>encją</em>. Użytkownicy mają prawo do uruchamiania procesów oraz
          posiadnia (bycia właścielem) plików. Jądro nie rozpoznaje
          użytkowników po ich nazwach, tak jak mają w zwyczaju to ludzie,
          używa ono identyfikatorów <strong>userid</strong> w skrócie
          <strong>UID</strong>. Identyfikatory są przedstawiane za pomocą 
          liczb. 
        </p>
        <p>
          Użytkownicy istnieją wyłącznie po to aby wyznaczać granice. Każdy
          proces ma swojego właściela, dlatego też mówi się że proces
          uruchamia się z uprawnieniami takiego a takiego użytkownika.
          Użytkownicy mogą uruchamiać i konczyć procesy w własnych granicach
          (tylko te, których są właścicielami), przez co nie mogą wpływać na
          procesy innych użytkowników. Poza procesami, użytkownicy mogą 
          tworzyć własne pliki, których automatycznie stają się właścicielami.
          Mogą oni decydować czy chcą się nimi dzielić, ustalając im
          odpowiednie uprawnienia.
        </p>
        <p>
          Poza użytkownikami przypisanymi do konkretnych osób (raczej
          spotkamy jednego), istnieje kilku dodatkowych specjalnych 
          użytkowników, głównie mają oni na celu ograniczenie uprawnień
          serwerów. Po za tymi specjalnymi istnieje jeszcze użytkownik
          <strong>root</strong>, którego nie tyczą się zapisane powyżej
          ograniczenia dlatego jest on nazywany <em>superużytkownikiem</em>.
        </p>
        <p>
          Osoba pracująca na koncie użytkownika <em>root</em>, nazywana jest
          <em>administratorem systemu</em>. <em>Root</em> może kończyć
          procesy innych użytkowników, przeglądać cudze pliki czy instalować
          oprogramowanie z repozytorium. Praca na tym koncie jest dość
          niebezpieczna z punktu widzenia systemu, ponieważ ten użytkownik
          jest wstanie wykonać czynności prowadzące do zniszczenia całego
          systemu. Na Linuksie <em>root</em> ma do tego pełne prawo, dlatego
          projektancji dystrybucji starają się ograniczyć konieczność pracy
          z wykorzystaniem tego użytkownika.
        </p>
        <p>
          Innym tworem podobnym to użytkowników są <strong>grupy</strong>.
          Grupy są zbiorem użytkowników, a ich zadaniem jest współdzielenie
          plików wewnątrz jednej grupy, między jej użytkownikami.
        </p>
        <h1 id="2.linuxbasics">2. Podstawy obsługi Linuksa</h1>
        <p>
          W tym rozdziale przedstawione zostaną podstawy obsługi systemu
          Linux, oczywiście z poziomu powłoki, ponieważ inne sposóby
          zależą w dużej mierze od programów, które do tego celu będziemy
          wykorzystywać. Takich programów może być kilka, powłok
          również dostępnych jest kilka rodzajów, jednak sam program powłoki
          nie będzie wpływać na prezentowane w tym rozdziale czynności. Ten
          rozdział zaczniem od tego czy jest powłoka.
        </p>
        <h2 id="2.1.shells">2.1. Powłoka</h2>
        <p>
          <strong>Powłoka</strong> jest chyba jednym z najistoniejszych 
          komponentów systemu
          Linux, pozwala ona na uruchamianie róznych poleceń wydawanych przez
          użytkownika. Powłoki są również małymi środowiskami programistycznymi.
          Nie które narzędzia systemowe są <strong>skryptami powłoki</strong> - 
          plikami tekstowymi zawierającymi zbiór wykonywanych kolejno (jedno po
          drugim) poleceń powłoki.
        </p>
        <p>
          Pierwotną powłoką była <strong>powłoka Bourna</strong>, opracowana
          jeszcze dla systemu UNIX w laboratoriach <em>Bell Labs</em>. Mimo
          niezbyt częstego wykorzystywania, powłoka ta jest stałym kompenetem
          nie tylko systemu Linux, ale i innych systemów uniksopodbnych.
          Obecnie wykorzystywaną powłoką jest <strong>BASH</strong> - 
          ulepszona wersja oryginalnej powłoki. Korzystając z róznych
          dystrybucji, domyślna powłoka może być inna. Ten materiał zakłada
          wykorzystanie powłoki BASH, szczególnie w rozdziale poświęconym 
          skryptom powłoki.
        </p>
        <h2 id="2.2.shellusage">2.2. Korzystanie z powłoki</h2>
        <p>
          Dostęp do powłoki może odbywać się w dwojaki sposób wykorzystać
          możemy wbudowaną w każdą dystrybucję konsole, nie zależnie od
          instalacji wybranej przez nas dystrybucji. Jeśli jest to dystrybucja
          skierowana do komputery biurkowe, to możemy skorzystać z wbudowanego
          programu <em>terminal</em>. Po uruchomieniu okna powłoki, w prawym
          górnym rogu pojawi się <strong>symbol zachęty</strong>. Jest to ciąg
          znaków wskazujący wiersz, w którym będziemy wprowadzać polecenia.
          Znak zachęty może przyjmować różną formę:
        </p>
        <ul>
          <li><code class="code-inline">użytkownik@host:ścieżka$</code> - 
            <code class="code-inline">użytkownik</code> - nazwa użytkownika,
            <code class="code-inline">host</code> - nazwa komputera,
            <code class="code-inline">ścieżka</code> - obecna ścieżka
            (czym jest ścieżka, będzie za chwilę). Tego typu symbol zachęty
            stosowany jest w dystrybucjach opartych na GNU/Linux Debian takich
            Linux Mint (Mint oparty jest na Ubuntu, a Ubuntu na GNU/Linux
            Debian) czy Ubuntu.</li>
          <li><code class="code-inline">[użytkownik@host:katalog]$</code> -
            <code class="code-inline">użytkownik</code> i
            <code class="code-inline">host</code> podobnie jak wyżej,
            <code class="code-inline">katalog</code> - katalog w którym się
            obecnie znajdujemy, z tego typu znakiem zachęty spotkamy się
            w dystrybucjach RHEL/Fedora/CentOS oraz Arch Linux.</li>
          <li><code class="code-inline">bash-wersja$</code> - Originalny symbol
            zachęty powłoki BASH, <code class="code-inline">wersja</code>
            przedstawia wersję wykorzystywanej powłoki, spotkamy go
            w ręcznych instalacjach powłoki (kompilacji kodu źródłowego)</li>
          <li><code class="code-inline">$</code> - symbol zachęty
            wykorzystywany w celu zaoszczędzenia miejsca w wierszu polecenia.</li>
        </ul>
        <p>
          W tych symbolach jeden element jest stały jest to znak dolara
          (<strong>$</strong>), oznacza on że polecenia wydawane będą jako
          zwykły użytkownika, innym symbolem jest znak krzyżyka
          (<strong>#</strong>), który mówi nam że polecenia będą uruchamiane
          przez superużytkownika. Najprostsze polecenie jakie możemy wydać
          jest użycie polecenia <strong>echo</strong>, które zwraca na
          standardowe wyjście podajny mu jako argument ciągu znaków:
        </p>
<pre class="code-block">
$ echo Witaj świecie.
</pre>
        <p>
          W przykładach w tym materiale, jeśli polecenia ma zostać wydane z
          uprawnieniami zywkłego użytkownika, przed poleceniem będzie
          pojawiać się znak dolara (<strong>$</strong>), a jeśli polecenie ma 
          być uruchomione z wyższymi uprawnieniami, będą one poprzedzone 
          znakiem krzyżyka (<strong>#</strong>) oznaczający uprawnienia 
          użytkownika <em>root</em>.
        </p>
        <h3 id="2.2.1.catcommand">2.2.1. Polecnie cat</h3>
        <p>
          Polecenie <strong>cat</strong> wypisuje na standardowe wyjście
          podane w argumentach pliki jeden po drugim dokonując tym samym
          połączenia (konkatenacji - stąd nazwa polecenia) na jednym
          strumieniu zawartości tych wszystkich plików.
        </p>
<pre class="code-block">
$ cat plik1 plik2 plik3 ...
</pre>
        <h3 id="2.2.2.stdinstdout">2.2.2. Standardowe wyjście i standardowe
        wejście</h3>
        <p>
          Użyłem powyższego polecenia <em>cat</em>, aby nakreślić kontekst dla
          omówienia dwóch podstawowcyh strumieni. Linux wykorzystuje strumień
          wejściowy do odczytu danych, a strumień wyjściowy do ich zapisu. 
          Źródłem strumienia wejściowego może być plik, urządzenie, terminal czy
          strumień wyjściowy innego procesu. 
        </p>
        <p>
          Strumień wejściowy możemy zaobserować poprzez uruchomienie polecenia
          <em>cat</em> bez żadnego pliku. Program nie zwróci od razu znaku
          zachęty, ponieważ oczekuje na dane. Możemy wpisać co kolwiek, a po
          naciśnięciu klawisza <em>enter</em> polecenie powtórzy ten wpisany
          tekst. Z racji tego iż nie podaliśmy mu żadnego pliku polecenie
          zaczęło korzystać ze strumienia <strong>standardowego wejścia</strong>,
          przekazanego
          mu przez jądro, w tym przypadku był to terminal, którym zostało
          uruchomione to polecenie. Aby zakończyć to polecenie należy wciśnąć
          kombinacje klawiszy <em>Ctrl+d</em>, która oznacza koniec 
          danych ze standardowego wejścia. 
        </p>
        <p>
          Ze <strong>standardowym wyjściem</strong> jest podobnie, jądro
          przezkazuje strumień standardowego wyjścia procesom, do którego
          mogą one zapisywać swoje dane. Polecenie <em>cat</em> zawsze 
          wypisuje swoje
          dane na standardowe wyjście, które przez uruchomienie polecenia w
          terminalu jest do niego podłączone. Dzięki temu mogliśmy zobaczyć
          wypisywane przez polecenie dane.
        </p>
        <p>
          Standardowe wyjście oraz standardowe wejście możemy zapisać
          skrótowo <strong>stdout</strong> oraz <strong>stdin</strong>.
          Takich nazw również należy się spodziewać w wszelakiej dokumentacji.
        </p>
        <p>
          Prócz wspomanianych strumieni istnieje jeszcze trzeci strumień
          wejścia-wyjścia - <strong>standardowy strumień błędów</strong>.
          Opiszę go nieco później.
        </p>
        <p>
          Strumienie są dość elastycznym mechanizem, można je zmusić do
          odczytywania i zapisywania danych z innych miejsc niż terminal.
          O przekierowaniach strumienii będzie nieco poźniej w tym rozdziale.
        </p>
        <h2 id="2.3.basicscommands">2.3. Podstawowe polecenia</h2>
        <p>
          Poniżej znajduje się pogrupowane przedstawienie najbardziej
          podstawowych poleceń niezbędnych do pracy w powłoce systemu Linux.
        </p>
        <ul>
          <li>polecenie <strong>ls</strong> - wypisuje zawartość katalogu.
            Najważniejsze opcje:
            <ul>
              <li><strong>-a</strong> - powoduje wyświetlenie wszystkich
              elementów, łącznie z tzw. <em>dot-files</em> (plikami ukrytymi,
              plikami konfiguracyjnymi</li>
              <li><strong>-l</strong> - wyświetlenie zwartości katalogu w
              postaci kilku kolumnowej tabeli zawierającej m.in uprawnienia,
              czas ostatniej modyfikacji plików, wielkość czy przypisanie 
              pliku, katalogu do użytkownika oraz grupy.
            </ul></li>
          <li>polecenie <strong>cp</strong> - kopiujej pliki
            Najważniejsze opcje:
            <ul>
              <li><strong>-p</strong> - zachowuje atrybuty kopiowanych plików,
                na przykład takie jak uprawnienia czy przypisanego właściela i
                grupę</li>
              <li><strong>-r</strong> - kopiowanie rekurencyjne, kopiuje całe
                katalogi wraz z podkatalogami oraz ich zawartością.</li>
              <li><strong>-v</strong> - włącza komunikaty diagostyczne,
                polecenie wypisuje co, gdzie kopiuje. Normalnie program nie
                zwraca nic poza znakiem zachęty po zakończonym kopiowaniu.</li>
            </ul></li>
          <li>polecenie <strong>mv</strong> - w najprostszym przypadku
            polecenie służy do zmiany nazwy pliku, jednak gdy drugim
            argumentem będzie katalog, plik zostanie przeniesiony do tego
            katalogu. Najważniejsze opcje:
            <ul>
              <li><strong>-v</strong> - włącza komunikaty diagnostyczne,
                identycznie jak w przypadku <em>cp</em>.</li>
            </ul></li>
          <li>polecenie <strong>touch</strong> - aktualizuje czas modyfikacji
            pliku, jeśli plik nie istnieje to zostanie utworzony pusty plik o
            podanej w argumencie nazwie.</li>
          <li>polecenie <strong>rm</strong> - polecenie służy do kasowania
            plików. Kombinacja opcji <strong>-rf</strong> wykorzystywana jest
            kasowania całych katalogów z podkatalogami. Najważniejsze opcje:
            <ul>
              <li><strong>-r</strong> - umożliwia, kasowanie rekurencyjne,
                całych katalogów z podkatalogami.</li>
              <li><strong>-f</strong> - przed każdym kasowaniem pliku polecenie
                pyta czy jesteśmy pewni, że chcemy skasować ten plik. Ta opcja
                pomija to pytanie wymusząjąc tak jakby kasowanie.</li>
            </ul></li>
          <li>polecenie <strong>echo</strong> - polecenie wypisuje ciąg znaków
            podany jako argument na standardowe wyjście. Najważniejsze opcje:
            <ul>
              <li><strong>-n</strong> - ta opcja wyłącza przechodzenie
                do nowej linii, po wypisaniu ciągu znaków.</li> 
            </ul></li>  
        </ul>
        <h2 id="2.4.commandsworksondir">Polecenia działające na katalogach</h2>
        <p>
          Uniksy w tym i Linux, korzystają ze standardu hierarchi katalogów,
          aby utrzymać w porządku dane przestrzeni użytkownika. Za początkowy
          katalog uznaje się <strong>katalog główny</strong> oznaczany prawym 
          ukośnikiem lub
          slashem (<strong>/</strong>), wewnątrz tego katalogu znajdują się
          pod katalogi, przechowujące konkretny rodzaj czy typ plików zgodny
          z ich przeznaczeniem.
        </p>
        <p>
          Droga do konkretnego katalogu nosi nazwę <strong>ścieżki</strong>.
          Jeśli ścieżki zaczynają się od <em>/</em>, czyli od katalogu głównego
          mamy doczynienia ze <strong>ścieżką bezwzględną</strong>. Elementy 
          katalogów na
          ścieżkach katalogi mogą być również wyrażane z pomocą jednej lub 
          dwóch kropek.
          Dwie kropki (<strong>..</strong>) oznaczają katalog nadrzędny
          względem aktualnego katalogu, zaś jedna kropka oznacza
          (<strong>.</strong>) aktualny katalog. Ścieżki nie zawierające
          slasha na początku, czyli nie zaczynające się od katalogu głównego
          są wówczas określane mianem <strong>ścieżki względnej</strong>.
        </p>
        <ul>
          <li>polecenie <strong>cd</strong> - polecenie służy do zmiany
            aktualnego katalogu, jako argument przyjmuje katalog, do którego
            checemy przejść, równie dobrze możemy przenieść się w dowolne
            miejsce w systemie plików (w katalogu głównym) podając jako
            argument ścieżkę. Nie podanie argumentu spowowduje przejście do
            katalogu domowego użytkownika.</li>
          <li>polecenie <strong>mkdir</strong> - polecenie tworzy nowy katalog.
            Jako argument przyjmuje nazwę katalogu lub ścieżkę. Najważniejsze 
            opcje:
            <ul>
              <li><strong>-p</strong> - opcja tworzy katalogi nadrzędne podane
                w ścieżce o ile te nie istnieją. Za pomocą odpowiednich
                podstawień powłoki oraz tej opcji można tworzyć całe struktury
                katalogowe.</li>
            </ul></li>
          <li>polecenie <strong>rmdir</strong> - usuwa katalog po warunkiem, że
            jest on pusty. W przeciwnym razie polecenie zwróci błąd. Chcąc
            usuwać całe katalogi z danymi oraz podkatalogami należy użyć
            polecenia <em>rm -rf</em>.</li>
        </ul>
        <h3 id="2.4.1.globbing">2.4.1. Nazwy wieloznaczne.</h3>
        <p>
          Dzięki możliwością powłoki możemy porównywać proste wzorce z nazwami
          plików w obrębie aktualnego katalogu roboczego (katalogu w którym
          się znajdujemy) czynność ta nazywana jest rozwijaniem nazw lub
          <em>globbingiem</em>. Jednym z elementów biorących udział w 
          rozwiązywaniu nazw jest gwiazdka (<strong>*</strong>) oznaczająca
          dowolną ilość dowolnych znaków. Dla przykładu poniższe polecenie:
        </p>
<pre class="code-block">
$ echo *
</pre>
        <p>
          Zwróci nazwy wszystkich plików i katalogów  znajdujących się w 
          katalogu. Innym
          znakiem wykorzystywanym przy nazwach wieloznacznych jest
          znak zapytania (<strong>?</strong>) reprezentuje on jeden dowolny
          znak, dla wzorca <em>b?at</em> pasującymi nazwami mogą być
          <em>blat</em> oraz <em>brat</em>. Rozwinięcia nazw dokonuje powłoka
          przed uruchomieniem, więc jeśli chcemy aby, któreś ze znaków 
          wieloznacznych trafiło do polecnie to należy umieść je w pojedyńczych
          cudzysłowach.
        </p>
        <h2 id="2.5.proxycommands">2.5. Polecenia pośredniczące</h2>
        <ul>
          <li>polecenie <strong>grep</strong> - wyszukuje wzorzec
          w podanym pliku. Polecenie to korzysta z systemu wzorców nazwanych
          <strong>wyrażeniami regularnymi</strong>. Najważniejszymi opcjami:
          <ul>
            <li><strong>-i</strong> - wyłącza rozróżnianie małych i
            wielkich liter.</li>
            <li><strong>-v</strong> - podwoduje odwrócenie wyszukiwania,
            zwracane są wyniki nie pasujące do wzorca.</li>
            <li><strong>-e</strong> - wykorzystuje rozszerzony zestaw 
            instrukcji pozwalajacych na tworzenie wyrażeń regularnych.</li>
            <li><strong>-o</strong> - opcja powoduje zwrócenie dokładnie
            tylko tych znaków pasujących do wzorca. Normalnie polecenie zwraca
            linię z elementami pasującymi do wzorca, w przypadku wielu plików
            zwraca również nazwę pliku.</li>
          </ul>
          Tworzenie wyrażeń regularnych oraz więcej opcji tego polecenia
          znajduje się na stronie podręcznika uruchamianej poleceniem:
<pre class="code-block">
$ man grep
</pre>
          Do najważniejszych wyrażeń, które każdy powinien znać należą:
          <ul>
            <li><strong>.*</strong> - oznaczające dowolną ilość dowolnych
              znaków.</li>
            <li><strong>.</strong> - oznacza jeden dowolny znak.</li>
          </ul></li>
          <li>polecenie <strong>less</strong> - wypisuje dane z pliku, lub
            ze strumienia wykorzysując podział na strony. Jedna strona to jeden
            ekran. Następne strony są wyświetlane za naciśnięciem <em>spacji</em>
            stronę możemy cofnąć klawiszem <em>b</em>, zakończyć przeglądanie
            danych klawiszem <em>q</em>. Dane możemy przeglądać linia po linii
            używając strzałek. Możliwe jest również wyszukiwanie fraz w danych
            za pomocą <em>/</em> (wyszukiwanie w przód) lub za pomocą 
            <em>?</em> (wyszukiwanie w tył).</li>
          <li>polecenie <strong>pwd</strong> - wyświetla obecny katalog
            roboczy powłoki (świeżkę na której się znajdujemy). Polecenie
            niepozorne choć przydatne, ze względu na dowiązania symboliczne
            (będzie o nich w dalszej części materiału), które mogą przesłaniać
            ścieżkę wyświetlaną w znaku zachęty. Najważnejsza opcja jest
            uruchamiana, gdy nie ma żadnej opcji, więc jej opis pominę.
            Warto dodać, że obecne systemy posiadają polecenie <em>pwd</em>
            wbudowane w powłokę. Dlatego też opcja <strong>-P</strong>
            rozwijająca fizyczne ścieżki nie jest automatycznie uruchamiana
            w przypadku poprostu wydania polecenia <em>pwd</em>, prawdziwe
            polecenie <em>pwd</em> uruchamiamy:
<pre class="code-block">
$ /usr/bin/pwd
</pre>
          </li>
          <li>polecenie <strong>diff</strong> - wszukuje różnice pomiędzy
            dowoma plikami tekstowymi. Polecenie to posiada wiele różnych opcji
            formatowania danych wyjściowych, najbardziej czytelnym pozostaje
            chyba użycie opcji <strong>-u</strong>. Polecenie wykorzystywane
            programistów oraz system kontroli wersji git.</li>
          <li>polecenie <strong>file</strong> - polecenie zwraca format pliku
            podanego jako argument. W uniksach nie potrzeby stosowania
            rozszerzeń plików, więc to polecenie może pomóc nam dowiedzieć
            się co zawiera plik.</li>
          <li>polecenie <strong>find</strong> i <strong>locate</strong> -
            polecenia te służą do wyszukiwania plików w systemie. Polecenie
            <em>find</em> wymaga podania katalogu po nazwie polecenia, nazwy
            wyszukiwanego pliki po opcji <strong>-name</strong> oraz opcji
            <strong>-print</strong>, która powoduje wyświetlenie na strumieniu
            standardowego wyjścia nazw plików pasujących do wzorca podanego w
            opcji <em>-name</em>. Polecenie <strong>locate</strong> na podobne
            zastosowanie jak <em>find</em> działa jednak od niego szybciej
            ponieważ bazuje na indeksie przygotowywanym co jakiś czas przez
            system operacyjny. Może być ono bezużyteczne, kiedy szukamy nowych
            plików, gdyż mogą być one nie ujęte jeszcze w indeksie.</li>
          <li>polecenie <strong>head</strong> i <strong>tail</strong> -
            te polecenia służa do prezentowania wycinka danych czy to ze
            strumienia lub z pliku. W przypadku polecenia <em>head</em>
            prezentowane jest <em>n</em> pierwszych linii, domyslnie 10;
            z kolei polecenie tail prezentuje <em>n</em> koncowych linii.
            Liczbę linii podajemy bezpośrednio po znaku myślnika
            (<strong>-</strong>). Z tych dwóch poleceń polecenie <em>tail</em>
            ma nieco większe zastosowanie niż polecenie <em>head</em>. Mozemy
            wywołać to polecenie aby wyświetlić dane od linii, numer linii
            podajemy po znaku plusa (<strong>+</strong>), inna właściwością
            chyba najważniejszą jest wyświetlanie danych na żywo, używając
            opcji <strong>-f</strong>, a następnie nazwy pliku lub myślnika
            gdy dane pochodzą ze strumienia wyjściowego innego polecenia.</li>
          <li>polecenie <strong>sort</strong> - układa wiersze z pliku
            tekstowego w porządku alfabetycznym, jeśli na początku wierszy
            znajdują się liczby to aby je posortować należy użyć opcji
            <strong>-n</strong>, aby odwrócić sortowanie możemy użyć opcji
            <strong>-r</strong>.</li>
        </ul>
        <h2 id="2.6.passwdandchsh">2.6. Zmiana hasła i powłoki</h2>
        <p>
          W celu zmiany hasła należy użyć polecenia <strong>passwd</strong>.
          Polecenie poprosi o podanie obecnego hasła, po zatwierdzeniu go
          zostaniemy poproszeni o nowe hasło i jego potwierdzenie (wpisanie
          ponowne nowego hasła).
        </p>
        <p>
          Zmiana aktywnej powłoki odbywa się za pomocą polecenia
          <strong>chsh</strong>, albo użyć poleceń odpowiadających nazwom
          innych powłok, kolejno <strong>ksh</strong> - Korn SHell,
          <strong>tcsh</strong> - TENEX C SHell. Użycie tych poleceń w 
          aktywnej powłoce, spowoduje uruchomienie podpowłoki. Zamkniecie
          jej spowoduje powrót do pierwotnej powłoki.
        </p>
        <h2 id="2.7.dotfiles">2.7. Pliki z kropką</h2>
        <p>
          Przeglądając pliki nawet w własnym katalogu domowym możemy znaleźć
          pliki, których nazwa zaczyna się od kropki. Nie które źródła mówią
          tym o że te pliki są ukryte. Do takich wniosków może dojść,
          ponieważ te pliki nie są domyślnie wyświetlane przez polecenie
          <em>ls</em> bez opcji <em>-a</em> lub przez menedżery plików dostępne
          w desktopowych wersja Linuksa. Jednak te pliki nie różnia się niczym
          od inny plików, poza właśnie tym przypadkiem opisanym powyżej.
          Oprócz plików, nazwy katalogów również mogą zaczynać się od kropki.
          Za pomocą prostego wzorca możemy wyświetlić wszystkie <em>dot-files</em>,
          jeśli wsród nich trafi się katalog, wówczas zostanie wyświetlona jego
          nazwa a pod nią jego zawartość. 
        </p>
<pre class="code-block">
$ ls .??*
</pre>
        <h2 id="2.8.shellandenvvars">2.8. Zmienne środowiskowe i powłoki</h2>
        <p>
          Powłoka może przechowywać zmienne tymczasowe, które mogą przechowywać
          różne wartości, mogą one kontrolować zachowanie samej powłoki jedną
          z takich zmiennych jest zmienna <strong>PS1</strong> zawierająca
          znak zachęty. Takie zmienne najczęsćiej wykorzystywane są w 
          skryptach powłoki i nazywane są <strong>zmiennymi powłoki</strong>.
          Definicja zmiennych tego składa się z nazwy zmiennej, operatora
          przypisania (znaku równości <strong>=</strong>) oraz wartości samej
          zmiennej.
        </p>
<pre class="code-block">
$ zmienna=12
</pre>
        <p>
          Odwołać się do wartości zmiennej możemy w dowolnym momencie, podając
          jej nazwę poprzedzoną znakiem dolara (<strong>$</strong>).
        </p>
<pre class="code-block">
$ echo $zmienna
</pre>
        <p>
          <strong>Zmienna środowiskowa</strong> jest podobna do zmiennej
          powłoki, ale nie jest ściśle związana z powłoką, bowiem do pamięci
          zmiennych środowiskowych systemach uniksopodobnych mają wszystkie
          aplikacje, system operacyjny przezkazuje je do każdego programu
          uruchomionego w powłoce, programy te nie mają jednak dostępu do
          zmiennych powłoki. Zmienne środowiskowe definiuje się w ten sam 
          sposób
          jak zmienne powłoki, jedna aby taka zmienna stała się zmienną
          środowiskową musi zostać przeniesiona do pamięci tych zmiennych
          za pomocą polecenia <strong>export</strong>.
        </p>
<pre class="code-block">
$ zmienna=21
$ export zmienna
</pre>
        <p>
          Nie które programy mogą wykorzystywać zmienne środowiskowe do
          własnej konfiguracji. Dla przykładu niektóre programy uruchamiane
          w powłoce korzystają ze zmiennej środowiskowej <em>EDITOR</em>
          definiujące domyślny program do edycji plików tekstowych.
          Wykorzystanie zmiennych środowiskowych zapewne jest opisane w
          na stronie podręcznika programu.
        </p>
        <h2 id="2.9path">2.9. Ścieżka poleceń</h2>
        <p>
          Istnieje specjalna zmienna środowiskowa <strong>PATH</strong>,
          przechowywująca katalogi, w których to powłoka będzie szukać
          programów odpowiadających wpisanym poleceniom. Jeśli wśród
          przeszukiwanych katalogów znajduje się kilka programów o tej samej
          nazwie to powłoka uruchomi pierwszy przez nią znaleziony. Ścieżki
          katalogów w tej zmiennej odzielone są dwukropkiem (<strong>:</strong>).
          Posiadając swoje programy, możemy również umieść katalog z nim
          wewnątrz zmiennej <em>$PATH</em>. Opcje dodanie katalogu są dwie
          i mogą mieć wpływ na funkcjonowanie systemu. Możemy dodać nasz
          katalog na początku zmiennej, wówczas powłoka zacznie od niego
          poszukiwania, jednak należy pamiętąc przy tym, aby nazwy programów
          nie pokrywały się istniejącymi dotychczas poleceniami.
        </p>
<pre class="code-block">
$ PATH=kat:${PATH}
</pre>
        <p>
          Na powyższym przykładzie <code class="code-inline">kat</code>, to 
          nasz katalog z oprogramowaniem. Możemy jednak skorzystać
          bezpieczeniejszego rozwiązania - dopisać nasz katalog na końcu listy
          katalogów zmiennej <em>PATH</em>, wówczas nawet jeśli nasz program 
          będzie
          nazywać się jak jedno z instniejących już poleceń w systemie, nie
          będzie miało to wpływu na działanie systemu.
        </p>
<pre class="code-block">
$ PATH=${PATH}:kat
</pre>
        <p>
          Na powyższych przykładach użyłem znaku dolara wraz z nawiasami
          klamrowymi. Jest to sposób na separacje nazwy zmiennej od innych
          znaków, po to aby powłoka nie potraktowała jak w przykładzie powyżej
          ciągu znaków ":kat" jak części nazwy zmiennej. Przedstawione w
          przykładach polecenia są nie groźne, jeśli uszkodzimy zawartość
          zmiennej <em>PATH</em>, to należy zamknąć okno terminala i otworzyć
          nowe. 
        </p>
        <h2 id="2.10.specialchars">2.10. Znaki specjalne</h2>
        <p>
          W systemach uniksopodbnych wiele znaków ma szczególne znaczenie.
          Poniżej znajduje się tabela przedstawiająca wykorzystwane podczas
          używania systemu znaki specjalne.
        </p>
        <table border="1">
          <thead>
            <tr>
              <th>Znak</th>
              <th>Nazwa</th>
              <th>Opis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>*</strong></td>
              <td>gwiazdka</td>
              <td>Wyrażenie regularne, znak nazwy wieloznacznej</td>
            </tr>
            <tr>
              <td><strong>.</strong></td>
              <td>kropka</td>
              <td>Aktualny katalog, ogranicznik nazwy pliku lub hosta</td>
            </tr>
            <tr>
              <td><strong>!</strong></td>
              <td>wykrzyknik</td>
              <td>Negacja, historia poleceń</td>
            </tr>
            <tr>
              <td><strong>|</strong></td>
              <td>potok</td>
              <td>Potoki poleceń</td>
            </tr>
            <tr>
              <td><strong>/</strong></td>
              <td>slash</td>
              <td>Ogranicznik katalogów, polecenie szukania</td>
            </tr>
            <tr>
              <td><strong>\</strong></td>
              <td>backslash</td>
              <td>Literały, makra (nigdy katalogi)</td>
            </tr>
            <tr>
              <td><strong>$</strong></td>
              <td>dolar</td>
              <td>Oznaczenie zmiennych, koniec wiersza</td>
            </tr>
            <tr>
              <td><strong>'</strong></td>
              <td>pojedynczy cudzysłów</td>
              <td>Ciągi znaków literałów</td>
            </tr>
            <tr>
              <td><strong>`</strong></td>
              <td>lewy cudzysłów</td>
              <td>Podmiana polecenia</td>
            </tr>
            <tr>
              <td><strong>"</strong></td>
              <td>podwójny cudzysłów</td>
              <td>Ciągi znaków pseudoliterałów</td>
            </tr>
            <tr>
              <td><strong>^</strong></td>
              <td>daszek</td>
              <td>Negacja, początek wiersza</td>
            </tr>
            <tr>
              <td><strong>~</strong></td>
              <td>tylda</td>
              <td>Negacja, skrót katalogu</td>
            </tr>
            <tr>
              <td><strong>#</strong></td>
              <td>krzyżyk</td>
              <td>Komentarze, dyrektywy preprocesora, podmiany</td>
            </tr>
            <tr>
              <td><strong>[]</strong></td>
              <td>nawiasy kwadratowe</td>
              <td>Zakresy</td>
            </tr>
            <tr>
              <td><strong>{}</strong></td>
              <td>nawiasy klamrowe</td>
              <td>Bloki poleceń, zakresy</td>
            </tr>
            <tr>
              <td><strong>_</strong></td>
              <td>podkreślenie</td>
              <td>Prosty zamiennik spacji</td>
            </tr>
          </tbody>
        </table>
        <p>
          Często możemy napotkać symbol daszka (<strong>^</strong>) zastępujący
          klawisz <em>Control</em>, przez co zapis <em>^C</em> jest równe
          kombinacji klawiszy <em>Ctrl+C</em>.
        </p>
        <h2 id="2.11.commandlineedit">2.11. Edycja wiersza poleceń</h2>
        <p>
          Znak zachęty wskazuje wiersz polecenia, który możemy edytować
          przesuwając kursor za pomocą strzałek. Chcąc powtórzyć jakąś czynność
          nie musimy pisać na nowo tego polecenia, możemy wybrać je z historii
          poleceń za pomocą strzałek w góre i w dół. Warto jednak obsługę
          wiersza poleceń za pomocą strzałek odstawić na bok. Wykorzystując
          skróty z poniższej tabeli, możemy nimi śmiało zastąpić strzałki. 
          Istnieją ku temu dwa powody. 
        </p>
        <ul>
          <li>Nie wszystkie klawiatury posiadają strzałki, lub ich użycie jest
            strasznie nie konfortowe.</li>
          <li>Wiele programów uniksowych (w tym i linuksowych) obsługuje się
            za pomocą tzw. biblioteki <strong>GNU Readline</strong> (skróty
            klawiszowe w tabeli poniżej), a nie za pomocą strzałek.</li>
        </ul>
        <table border="1">
          <thead>
            <tr>
              <th>Klawisze</th>
              <th>Operacja</th>
            </tr>
          </thead>
          <tbody>
            <tr>
               <td><em>Ctrl+b</em></td>
               <td>Przesunięcie kursora w lewo</td>
            </tr>
            <tr>
              <td><em>Ctrl+f</em></td>
              <td>Przesunięcie kursora w prawo</td>
            </tr>
            <tr>
              <td><em>Ctrl+p</em></td>
              <td>Powrót do poprzedniego polecenia (lub przesunięcie kursora
                w górę)</td>
            </tr>
            <tr>
              <td><em>Ctrl+n</em></td>
              <td>Przejście do następnego polecenia (lub przesunięcie klawisza
                w dół)</td>
            </tr>
            <tr>
              <td><em>Ctrl+a</em></td>
              <td>Przesunięcie kursora na początek wiersza</td> 
            </tr>
            <tr>
              <td><em>Ctrl+e</em></td>
              <td>Przesunięcie kursora na koniec wiesza</td>
            </tr>
            <tr>
              <td><em>Ctrl+w</em></td>
              <td>Usunięcie słowa poprzedzjącego kursor</td>
            </tr>
            <tr>
              <td><em>Ctrl+u</em></td>
              <td>Usunięcie tekstu od kursora do początku wiersza</td>
            </tr>
            <tr>
              <td><em>Ctrl+k</em></td>
              <td>Usunięcie tekstu od kursora do końca wiersza</td>
            </tr>
            <tr>
              <td><em>Ctrl+Y</em></td>
              <td>Wyklejanie usuniętego tekstu (na przykłda usuniętego
                poleceniem <em>Ctrl+u</em>)</td>
            </tr>
            <tr>
              <td><em>Ctrl+h</em></td>
              <td>Substytut klawisza <em>Backspace</em></td> 
            </tr>
            <tr>
              <td><em>Ctrl+d</em></td>
              <td>Substytut klawisza <em>delete</em></td>
            </tr>
            <tr>
              <td><em>Ctrl+j, Ctrl+m</em></td>
              <td>Substytut klawisza <em>enter</em></td>
            </tr>
          </tbody>
        </table>
        <h2 id="2.12.texteditors">2.12. Edytory tekstu</h2>
        <p>
          Na Linuksie mamy podobną ilość edytorów tekstowych do wyboru jak w
          przypadku systemów MS Windows czy Apple macOS. Jak nie więcej.
          Co ciekawe macOS, również jest system uniksopodobnym. Więc to co
          zostało omówione w tym rozdziale również będzie kompatybilne z tym
          systemem. Wracając jednak do edytorów tekstu. Tak naprawdę to
          istnieją dwa, na które warto zwrócić uwagę, oba są standardem jeśli
          chodzi o edycje tekstu i oba wymagają nauki obsługi. Wybór
          pozostawiam do roztrzygniecia Tobie. 
        </p>
        <ul>
          <li><strong>GNU Emacs</strong> - edytor w którym można zrobić
            wszystko, od pisania tekstów do wykorzystania go jako menedżer
            okien. Jego obsługa nie jest zbyt szybka i często by się
            wydawało proste czynności wymagają użycia kliku poleceń. Wydaje
            mi się, że nie ma bardziej rozbudowanego uniksowego programu.
            Pomoc w obsłudze tego edytora, możemy uruchomić naciskając
            <em>Ctrl+H</em> następnie klawisz <em>t</em>.</li>
          <li><strong>VIm</strong> - szybki edytor uruchamiany w terminalu,
            choć można zainstalować wersję graficzną. Obsługuje się go trochę 
            jak grę. VIm, jest nieco bardziej intuicyjny od Emacsa. Warto
            dodać, że edytor ten bywa domyślnie doinstalowywany do wielu
            dystrybucji jak i innych systemów uniksowych, choć tam może
            występować w podstawowej wersji <strong>Vi</strong>. Chcąc
            nauczyć się edytora <em>Vim</em>, możemy skorzystać z
            z instalowanego wraz z edytorem tutoriala, uruchamianego poleceniem
            <strong>vimtutor</strong>.</li>
        </ul>
        <p>
          Jeśli potrzebujemy edytora, który jest wstanie zatąpić nam
          środowisko graficzne, wybierzmy edytor <em>Emacs</em>. Jeśli jednak 
          chcemy
          poprostu edytować pliki, w każdym możliwym środowisku wybierzmy
          edytor <em>Vim</em>. Osobiście jestem przyzwyczajony już do edytora
          <em>Vim</em>.
        </p>
        <h2 id="2.13.gettinghelp">2.13. Uzyskiwanie pomocy</h2>
        <p>
          Dystrybucje Linuksa są rozporowadzane z dużą ilością różnej
          dokumentacji. Informacje temat poleceń możemy znaleźć na stronach
          podręcznika, wydając polecenie <strong>man</strong> i podając jako
          argument interesujące nas polecenie. Na przykład:
        </p>
<pre class="code-block">
$ man ls
</pre>
        <p>
          W ten sposób uruchomimy stronę podręcznika polecenia <em>ls</em>.
          Większosć stron podręcznika podaje suche informacje na temat
          polecenia, nie ma co tam szukać jakiś samouczków. Opcje podawana są
          usystematyzowany sposób (najczęściej alfabetyczny), nie które
          strony podręcznika mogą zawierać przykłady.
        </p>
        <p>
          Strony podręcznika możemy przeszukać pod kątem słowa kluczowego, za
          pomocą opcji <strong>-k</strong>, polecenia <em>man</em>. Wynikiem
          tego polecenie jest lista poleceń, oraz krótki opis zawierający
          podane słowo kluczowe, ciekawa jest liczba podana w nawiasie obok
          nazwy polecenia, jest to <strong>numer rozdziału</strong>.
        </p>
        <p>
          Strony podręcznika są podzielone rozdziały oznaczone numerami, każdy
          z nich zawiera innego rodzaju strony podręcznika. Rozdziały
          zostały opisane w tabeli poniżej. 
        </p>
        <table border="1">
          <thead>
            <tr>
              <th>Rozdział</th>
              <th>Opis</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>1</strong></td>
              <td>Polecenia użytkownika</td>
            </tr>
            <tr>
              <td><strong>2</strong></td>
              <td>Niskopoziomowe wywołania systemowe</td>
            </tr>
            <tr>
              <td><strong>3</strong></td>
              <td>Dokunentacja wysokopoziomowych bibliotek Uniksa</td>
            </tr>
            <tr>
              <td><strong>4</strong></td>
              <td>Informacje o interfejsach urządzeń i sterownikach</td>
            </tr>
            <tr>
              <td><strong>5</strong></td>
              <td>Opisy plików (konfiguracji systemu)</td>
            </tr>
            <tr>
              <td><strong>6</strong></td>
              <td>Gry</td>
            </tr>
            <tr>
              <td><strong>7</strong></td>
              <td>Formaty plików, konwencje i kodowaniaa (ASCII, przyrostki itd)</td>
            </tr>
            <tr>
              <td><strong>8</strong></td>
              <td>Polecenia systemowe i serwery</td>
            </tr>
          </tbody>
        </table>
        <p>
          Jak uzupełnienie tego materiału świetnie sprawdzą się rodziały
          1,5,7 i 8. Wywołanie konkretnej strony a danego rozdziału wymaga
          podania jego numeru jak pierwszego argumentu, wówczas polecenie
          będzie wszukać informacji na temat podanego słowa w danym rodziale.
          Świetnym przykładem może być, chęć sprawdzenia na stronach
          podręcznika pliku <em>/etc/passwd</em>. Należy wydać polecenie:
        </p>
<pre class="code-block">
$ man 5 passwd
</pre>
        <p>
          Dość często wykorzystywanym sposóbem na uzyskanie informacji o
          poleceniach mogą być same polecenia, sprawdźmy czy możemy je
          uruchomić z opcją <strong>-h</strong> lub <strong>--help</strong>.
        </p>
        <p>
          Projekt GNU jakiś czas temu zadecydował, że będzie używać innego
          formatu plików pomocy niż strony podręcznika, format nazywana jest
          <strong>info</strong> lub <strong>texinfo</strong>. Format ten
          zawiera więcej informacji choć jest od niego bardziej skomplikowany.
          Przypomina prostą stronę internetowa, otworzoną w terminalowej
          przeglądarce. Tego typu pliki pomocy uruchamiane są za pomocą
          polecenia <strong>info</strong>, po czym podaje mu się jako argument
          interesujące nas polecenie. 
        </p>
        <p>
          Nie które z pakietów umieszczają swoją dokumentację w katalogu
          <em>/usr/share/doc</em> nie zwracając uwagi na format. Warto
          pamiętać o tych miejscach szukając pomocy, oczywiście pozostaje na
          do dyspozycji jeszcze internet.
        </p>
        <h2 id="2.14.shellio">2.14. Wejście i wyjście powłoki</h2>
        <p>
          Omawiając po krótce powłokę, wspomniałem o strumieniach standardowego
          wejścia i wyjścia. Wiele poleceń używa wyjścia aby wypisywać
          wyniki działa lub komunikaty diagonstyczne. Jeśli nie chcemy ich
          widzieć lub nie nadąrzymy ich analizować możemy je przekierować
          na przykład do pliku, za pomocą znaku przekierowania (<strong>&gt;</strong>).
        </p>
        <p>
          Używając tego znaku musimy omówić sobie jedną ważną rzecz, znak ten
          powoduje nadpisanie wszystkiego co znajduje się w pliku. Tego typu
          czynność nazywana jest <strong>wymazywaniem</strong>
          (ang. <em>clobbering</em>). Możemy jednak zablokwać to działanie
          za pomocą odpowiednich ustawień powłoki, dla BASH wystarczy użyć
          polecenia <code class="code-inline">set -C</code>. Poza blokowaniem
          wymazywania, istnieje jeszcze jeden znak przekierowania, który
          powoduje dopisanie przekierowanego wyjścia do pliku:
          <strong>&gt;&gt;</strong>.
        </p>
        <p>
          Za pomocą przekierowań możemy w prosty sposób połączyć wyjście
          jednego polecenia z wejściem innego. Służy temu znak <strong>potoku</strong>
          (<strong>|</strong>). Postawienie ponowej kreski, pomiędzy
          poleceniami w wierszu polecenia połączy wyjście pierwszego z wejściem
          drugiego.
        </p>
        <h3 id="2.14.1.stderr">2.14.1 Standardowy strumień błędów</h3>
        <p>
          Korzystając powyższych znaków przekierowania polecenia, dane
          wyjściowe programów zostaną przekierowane np. do pliku. Ale
          komunikaty diagnostyczne nadal są wyświetlane. Dzieje się to dlatego
          iż komunikaty diagnostyczny wykorzystują trzeci dodatkowy strumień
          <strong>standardowy strumień błędów</strong> zapisywany skrótowo
          <strong>stderr</strong>, który podobnie do <em>stdout</em> jest
          podłączony do terminala.
        </p>
        <p>
          Do przekierowania tego strumienia musimy użyć identyfikatorów
          strumienii jest to liczba, którą posługuje się jądro do rozrózniania
          strumieni. W fachowej
          literaturze bądź dokumentacji możemy natknąć się na termin
          <strong>deskryptor pliku</strong>. Taki identyfikator dla <em>stderr</em>
          ma wartość <strong>2</strong>, a dla <em>stdout</em> <strong>1</strong>.
          Chcąc przekierować <em>stderr</em> do innego pliku musimy podać jego
          identyfikator przed znakiem przekierowania. Innym przypadkiem jest
          przekierowanie <em>stderr</em> do tego samego pliku co <em>stdout</em>,
          wówczas najprostszym sposób jest podłączenie strumienia błedów do
          standardowego wyjścia za pomocą znaku <strong>&gt;&amp;</strong>
          podając przekierowywany strumień po lewej stronie znaku (przed nim)
          a strumień docelowy po prawej (za nim).
        </p>
<pre class="code-block">
$ ls /ffffffff &gt;p 2&gt;&amp;1
</pre>
        <h3 id="2.14.2.stdin">2.14.2. Przekierowanie standardowego wejścia</h3>
        <p>
          Przekierowanie standardowego wejścia występuję dość rzadko ponieważ
          większość poleceń przyjmuje plik jako argument, jednak może zdarzyć
          się potrzeba przekierowania wejścia do polecenia. Służy temu
          <strong>znak przekierowania wejścia</strong> <strong>&lt;</strong>.
        </p>
        <h2 id="2.15.readingerrors">2.15. Odczytywanie komunikatów o błędach</h2>
        <p>
          Prędzej czy później gdzieś podczas naszej pracy z powłoką zdarzy
          się błąd. Ważne jest aby umieć go odczytać i prawidłowo z
          interpretować.
        </p>
        <p>
          Sam komunikat składa się przeważnie z nazwy polecenia oraz
          komunikatu błędu, w nie których przypadkach w komunikacie
          znajduje się nazwa pliku, jednak dotyczy specyficznych komunikatów
          o błędach. Poniżej znajduje się
          lista, błędów z którym będziemy się spotykać podczas pracy z systemem 
          Linux. 
        </p>
        <ul>
          <li><strong>No such file or directory</strong>
            (<em>nie ma takiego pliku lub katalogu</em>) - występuje gdy
            plik lub katalog podany jak argument nie istnieje. Innym powodem
            występowania takiego błędu może być błędnie zapisana nazwa
            polecenia w skrypcie.</li>
          <li><strong>File exists</strong> (<em>plik istnieje</em>) - ten
            problem występuje w momencie gdy próbujemy stworzyć katalog o
            nazwie pliku, który już istnieje.</li>
          <li><strong>Not a directory</strong> (<em>nie jest katalogiem</em>),
            <strong>Is a directory</strong> (<em>jest katalogiem</em>) - błąd
            występuje w momencie gdy probujemy użycie pliku jak katalogu lub
            katalogu jak pliku.</li>
          <li><strong>No space left on device</strong> (<em>brak miejsca w 
            urządzeniu</em>) - Na pamięci masowej, której próbujemy zapisać
            dane brakuje wolnego miejsca.</li>
          <li><strong>Permission denied</strong> 
            (<em>niewystarczające uprawnienia</em>) - pojawienie się tego błędu
            może mieć dwa powody, pierwszy to zapis lub odczyt informacji z
            pliku, do którego nie mamy żadnych uprawnień; drugim jest próba
            uruchomienia pliku/programu bez ustawionego bitu wykonania. O
            uprawnieniach będzie w dalszej części tego rodziału.</li>
          <li><strong>Operation not permitted</strong> (<em>brak zezwolenia
            na wykonanie operacji</em>) - błąd występuje w momencie gdy
            spróbujemy zakończyć proces nie należący do nas.</li>
          <li><strong>Segmentation fault</strong> (<em>błąd segmentacji</em>) - 
            błąd programisty. Program, który uruchomiliśmy próbował
            użyskać dostęp do wycinka pamięci, którego nie miał żadnych
            uprawnień i jego działanie zostało przerwane przez jądro. 
            Najczęsciej polskie tłumaczenie tego błędu to
            <em>Naruszenie ochrony pamięci</em>.</li>
          <li><strong>Bus Error</strong></li>  (<em>błąd magistrali</em>) błąd
            podobny do <em>Naruszenia ochrony pamięci</em>, jednak w tym
            przypadku chodzi o dostęp do pamięci w sposób niewłaściwy, a nie
            dostęp do innego obszaru pamięci.</li>
        </ul>
        <p>
          Jeśli natrafimy na jeden z dwóch ostatnich błędów, to przyczyną mogą
          być dane przekazane do programu, których on się nie spodziewał.
        </p>
        <h2 id="2.16.manipulatingprocesses">2.16. Przeglądanie procesów i
          manipulowanie nimi</h2>
        <p>
          Każdy proces jest programem. Jądro pododobnie jak użytkowników 
          procesy widzi za pomocą liczbowych identyfikator - 
          <strong>process ID</strong> - <strong>PID</strong>. Za pomocą
          polecenia <strong>ps</strong> możemy wylistować wszystkie procesy
          uruchomione w powłoce. Domyślnie wynik polecenia podzielony jest na
          cztery kolumny.
        </p>
        <ul>
          <li><strong>PID</strong> - identyfikator procesu</li>
          <li><strong>TTY</strong> - urządzenie terminala, na którym działa
            dany proces.</li>
          <li><strong>STAT</strong> - stan procesu, np. <strong>S</strong>
            oznacza uśpieje procesu, zaś <strong>R</strong> - jego dzialanie.
            Wszystkie oznaczenia znajdują się na stronie podręcznika 
            polecenia.</li>
          <li><strong>CMD</strong> - treść polecenia, warto jednak zaznaczyć,
            że procesy mogą ją zmieniać.</li>
             
        </ul>
        <p>
          Polecenie <em>ps</em>, możemy obsługiwać za pomocą opcji zapisanych w
          trzech stylach, jednak najbardziej powszechnym jest styl BSD, i to
          zapis opcji w tym stylu przedstawie.
        </p>
        <ul>
          <li><strong>ps x</strong> - wyświetla wszystkie procesy uruchomione
            przez aktualnego użytkownika.</li>
          <li><strong>ps ax</strong> - wyświetla wszystkie procesy działące
            w systemie.</li>
          <li><strong>ps u</strong> - wyświetla bardziej szczegółowe informacje
            o procesach.</li>
          <li><strong>ps w</strong> - podaje pełne nazwy poleceń, nie
            ograniczając się do pojedyńczego wiersza.</li>
        </ul>
        <p>
          Tak jak w przypadku innych poleceń, w poleceniu <em>ps</em>, również
          możemy łączyć opcje, dla przykładu chcąc wyświetlić wszystkie
          procesy w systemie wraz ze szczegółami należy wydać polecenie
          <code class="code-inline">ps aux</code>.
        </p>
        <p>
          Wyświetlenie informacji na temat, konkertnych procesów polega na
          podaniu po opcjach identyfikatora procesu. 
        </p>
        <h3 id="2.16.1.processkilling">2.16.1. Przerywanie działania procesów</h3>
        <p>
          Możemy zakończyć działanie procesu poprzez wysłanie do niego
          <strong>sygnału</strong> za pomocą polecenia <strong>kill</strong>.
          Wykorzystują to polecenie, jądro systemu proszone jest wysłanie 
          sygnału do wybranego procesu. Domyślnie wysyłanym sygnałem jest 
          <strong>TERM</strong>, a polecenie do swojego działania potrzebuje
          tylko identyfikatora <em>PID</em>. 
        </p>
        <p>
          Proces możemy zatrzymać wysyłając do niego sygnał <strong>STOP</strong>.
          po nazwie sygnału podajemy <em>PID</em>, tak zatrzymany proces da się
          wznowić za pomocą sygnału <strong>CONT</strong>. Nazwy sygnałów
          podajemy po myślniku (<strong>-</strong>).
        </p>
        <p>
          Naciśnięcie kombinacji <em>Ctrl+c</em> podczas działania programu w
          powłoce, jest równoznaczne z wysłaniem sygnału <strong>INT</strong>
          (ang. <em>Interrupt</em> - przerwanie).
        </p>
        <p>
          Jedną z metod zakończenia procesu jest natychmiastowe zakończenie
          jego pracy oraz usunięcie go siłą z pamięci, jest to osiągalne
          poprzez wysłanie do niego sygnału <strong>KILL</strong>. Jest to
          ostateczność, gdy dany proces nie odpowiada na inne sygnały. Inne
          sygnały dają procesom możliwość poprzątania po sobie.
        </p>
        <p>
          Oczywiście nie należy przerywać pracy dowolnym procesom, kiedy nie
          wiemy co robią.
        </p>
        <h3 id="2.16.2.jobcontol">2.16.2. Kontrola zadań</h3>
        <p>
          Powłoki posiadają mechanizm dzięki, któremu możemy zatrzymywać oraz
          wznawiać prace procesów za pomocą kombinacji <em>Ctrl+z</em> oraz
          poleceniami <strong>fg</strong>, <strong>bg</strong>. Ten mechanizm
          nazywa się <strong>kontolą zadań</strong>. Podczas działania procesu
          w powłoce, możemy wysłać sygnał <strong>TSTP</strong> (podobny do
          sygnału STOP), a następnie kiedy zechcemy do niego wrócić to
          wystarczy wydać polecenie <em>fg</em>, które wznowi działanie
          polecenia w terminalu, lub polecenia <em>bg</em> wznawiającego
          działanie procesu w tle.
        </p>
        <p>
          Podobne działanie ma program <em>GNU Screen</em>, który jest
          multiplekserem terminala, a co najlepsze jesteśmy wstanie odłączyć
          sesję programu od pierwszego planu i pozostanie ona w
          niezmienionej postaci, tak długo jak włączony jest komputer.
        </p>
        <h3 id="2.16.3.processinbg">2.16.3. Procesy działające w tle</h3>
        <p>
          Uruchamiając polecenie w powłoce dostęp do znaku zachęty, a co za tym
          idzie wolnego wiersza polecenia otrzymujemy dopiero po zakończeniu
          działania programu. Jednak możemy odłożyć wykonanie polecenia do tła,
          poczym od razu uzyskamy dostęp znaku zachęty. Jest to przydatna
          funkcją, gdy uruchamiamy polecenie, którego wykonanie może
          zająć trochę czasu. Wykonanie odkładamy do tła dopisując
          ampersand (<strong>&amp;</strong>) na końcu polecenia (jako ostatni
          argument). Działanie takiego programu
          może trwać nawet po naszym wylogowaniu. Jeśli proces zakończy
          działanie zostaniemy o tym poinformowani.
        </p>
        <p>
          Problem związanym z procesami działającymi w tle jest, możliwe
          pobieranie informacji z standardowego wejścia. Jeśli nie
          przewidzieliśmy takiego zachowania programu, to wówczas może zostać
          on zatrzymany lub zakończony. Można go wznowić za pomocą polecenia
          <em>fg</em> o ile został zatrzymany. Innym problemem jest wypisywanie
          danych przez proces w tle na standardowe wyjście oraz strumień błędów.
          Przed uruchomieniem takiego polecenia należy przekierować te
          strumienie, ponieważ podczas pracy w terminalu z innymi aplikacjami
          dane ze strumieni mogą zaburzać ich wyświetlanie. Jeśli powłoka 
          będzie dziwnie się zachowywać, wystarczy wydać polecenie 
          <strong>reset</strong> i wszystko wróci do normy.
        </p>
        <h2 id="2.17.filemodandpermissions">2.17. Tryb pliku i uprawnienia</h2>
        <p>
          Każdy plik na Uniksie (więc na Linuksie też), posiada komplet
          <strong>uprawnień</strong> określajacy czy można go odczytać, 
          zapisać do niego lub go
          uruchomić. Pierwsza kolumna wyniku polecenia <code class="code-inline">ls -l</code>
          zawiera tryb pliku. Dane trybu możemy podzielić na cztery części
          <strong>Typ</strong>, <strong>Uprawnienia użytkownika (właściciela)</strong>,
          <strong>Uprawnienia grupy</strong>, <strong>Uprawnienia pozostałych
          użytkowników.</strong>.
        </p>
        <p>
          Pierwszy znak to typ pliku, jesli występuję w nim myślnik (<strong>-</strong>),
          to mamy doczynienia ze zwykłym plikiem, innym typem pliku może być
          litera <strong>d</strong> oznaczająca katalog.
        </p>
        <p>
          Pozostałe znaki, definiują uprawnienia. Dzieli się je na trzy grupy
          wypisane powyżej, po trzy znaki na każdą z nich. W grupie (zestawie
          uprawnień, przeznaczonym dla konkretnej grupy lub osoby) mogą
          wystąpić 4 rodzaje znaków.
        </p>
        <ul>
          <li><strong>r</strong> - oznacza, że plik można czytać.</li>
          <li><strong>w</strong> - oznacza, że do pliku można pisać.</li>
          <li><strong>x</strong> - oznacza, że plik można uruchomić.</li>
          <li><strong>-</strong> - oznacza, brak uprawnienia.</li>
        </ul>
        <p>
          Mówiąc o użytkowniku w pierwszym rodziale, wspomniałem że może być
          on właścicielem pliku i do niego należy pierwszy zestaw uprawnień.
          Drugi zestaw określa uprawnienia dla grupy, jaka została przypisana
          temu plikowi, z tych uprawnień będzie korzystać każdy użytkownik tej
          grupy, próbujący uzyskać dostęp do pliku. Trzeci grupa, należy do
          pozostałych użytkowników systemu. Użytkownika <em>root</em> nie
          obejmują żadne z powyższych grup, choć to może zależć od konfiguracji
          systemu, mimo to superużytkownik może sobie zmieniać dowolnie
          uprawnienia.
        </p>
        <p>
          Nie wymieniony na powyższej liście dodatkowym bitem (o uprawnieniach
          możemy mówić jak o bitach, np. "potrzebuje bitu odczytu aby odczytać
          dane z pliku") jest bit <strong>s</strong> - wybierz identyfikator
          użytkownika. Pojawia się on zamiast bitu wykonywania <em>x</em> i
          tyczy się wyłącznie plików wykonywalnych. Programy z ustawionym tym
          bitem zawsze uruchamiają się z uprawnieniami ich właściciela bez
          znaczenia, kto uruchamia ten program. Wiele programów korzysta z tego
          rozwiązania, aby uzyskać uprawnienia superużytkownika i móc zapisywać
          dane w różnych plikach systemowych.
        </p>
        <h3 id="2.17.1.modifypermissions">2.17.1. Modyfikacja uprawnień</h3>
        <p>
          Do zamiany uprawnień wykorzystamy polecenie <strong>chmod</strong>,
          jako pierwszy podaje się zbiór uprawnień, a następnie bit uprawnienia
          ze znakiem "+" jeśli chcemy dodać ten bit lub "-" jeśli chcemy ten 
          bit
          usunąć. Zbiór uprawnień podajemy za pomocą pierwszych liter 
          angielskich
          nazw <strong>u</strong> (ang. <em>user</em>)- użytkownika/właściciel,
          <strong>g</strong> (ang. <em>group</em>) - grupa, 
          <strong>o</strong> (ang. <em>others</em>)- pozostali użytkownicy 
          systemu.
        </p>
<pre class="code-block">
$ chmod go+r test.sh
</pre>
        <p>
          Zbiory uprawnień można łączyć ze sobą, tak jak na powyższym
          przykładzie lub jeśli chcemy dodać bit do wszystkich zbiorów to
          możemy je pominąć jak na poniższym przykładzie.
        </p>
<pre class="code-block">
-rw-r--r-- 1 xf0r3m xf0r3m 26 03-08 13:13 test.sh
$ chmod +x test.sh
-rwxr-xr-x 1 xf0r3m xf0r3m 26 03-08 13:13 test.sh
</pre>
        <p>
          Przy plikach osobistych, nie warto dawać za dużych oprawnień
          pozostałym użytkownikom. Chociaż obecnie może mieć to jedynie
          znaczenie, gdy z serwera korzysta wielu wyspecjalizowanych 
          użytkowników.
        </p>
        <p>
          Innym sposobem na zmianę uprawnień jest użycie liczb, gdzie każda
          z trzech liczb określa uprawnienia dla jednego zbioru. Liczby te są
          sumami bitów, które reprezentowane są przez poszczególne wartości.
        </p>
        <ul>
          <li><em>r</em> - <strong>4</strong></li>
          <li><em>w</em> - <strong>2</strong></li>
          <li><em>x</em> - <strong>1</strong></li>
          <li><em>-</em> - <strong>0</strong></li>
        </ul>
<pre class="code-block">
$ chmod 644 test.sh 
</pre>
        <p>
          Uprawnienia właściciela mają wartość <code class="code-inline">6</code>.
          co jest równe <em>4+2</em> - <em>u+rw</em>, grupa oraz pozostali mają
          <code class="code-inline">4</code> co jest identyczne z zapisem
          <em>go+r</em>. Liczby wykorzysywane tutaj pochodzą z oktalnego 
          systemu liczbowego. 
        </p>
        <p>
          Zmiana uprawnień nosi nazwę <strong>bezwzględnej</strong>, ponieważ
          zmieniane są uprawnienia wszystkich grup.
        </p>
        <p>
          Odnośnie uprawnień to istnieje bardzo ważna zależność pomiędzy bitami
          odczytu oraz wykonania. Nadając katalogowi domowemu uprawnienia
          <em>rwxr--r--</em> czy <em>744</em>. Pozostali użytkownicy będą
          mogli odczytać zawartości katalog, ale nie uzyskają dostępu do pliku
          podając go w jakimś poleceniu na ścieżce, do tego potrzebny jest 
          jeszcze bit wykonania. 
        </p>
        <p>
          Za pomocą polecenia <strong>umask</strong>, możemy zdefiniować
          domyślne uprawnienia dla plików. Polecenie to przyjmuje jako 
          argument te uprawnienia w postaci bezwględnej, które mają zostać
          usunięte z nowoutworzonych plików i katalogów. Wydanie polecenia
          umask:
        </p>
<pre class="code-block">
$ umask 022
</pre>
        <p>
          Spowoduje, że nowoutworzone pliki i katalogi będą mięc uprawnienia
          w postaci <em>rwxr-xr-x</em> lub <em>755</em>. Może wydawać się zbyt
          liberalne, więc możemy ustawić argument polecenia nas <em>077</em>, 
          wówczas
          wszystkie utworzone pliki i katalogi będą wyłącznie dla nas. 
          Polecenie
          <em>umask</em>, czesto występuje w plikach konfiguracyjnych powłoki.
        </p>
        <h3 id="2.17.2.symlinks">2.17.2. Dowiązania symboliczne</h3>
        <p>
          Dowiązanie syboliczne to jest alias będący plikiem wskazującym na
          inny pliki lub katalog. Można uciec się do jednego słowa, że
          dowiązanie symboliczne jest poprostu skrótem.
        </p>
        <p>
          Jeśli dowiązanie wskazuje na katalog, to przejście do dowiązania
          przeniesie nas w miejsce, na które wskazuje. Cel dowiązania nie
          musi nawet istnieć, jeśli jednak spróbuje przejść pod takie
          dowiązanie wówczas uzyskamy typowy błąd, o tym że katalog nie
          istnieje. Dowiązania uniemożliwają również sprawdzenie 
          charakterystyki
          wskazywanego elementu, nie będzie wiadomo czy jest to plik, katalog
          czy inne dowiązanie. Wiele połączonych ze sobą dowiązań symbolicznych
          nazywane jest <strong>łańcuchem dowiązań</strong>
        </p>
        <p>
          Dowiązania symboliczne tworzone są za pomocą polecenia <strong>ln</strong>
          z opcją <strong>-s</strong> (<strong>Ważne, aby użyć tej opcji</strong>).
          Argumentami jest na początku <strong>cel</strong> a poźniej nazwa
          dowiązania. Zachowanie kolejności argumentów jest ważne, ponieważ
          możemy utworzyć dowiązanie, które prowadzi do nikąd i wprowadza
          bałagan (być może w plikach systemowych).
        </p>
        <p>
          Mimo swoich wad dowiązanią są wygodną metodą na współdzielenie plików
          oraz dodatkowo rozwiązują kilka drobnych problemów.
        </p>
        <h2 id="2.18.archivesandcompression">2.18. Archiwizowanie i
        kompresowanie danych</h2>
        <p>
          Przesyłając duża ilość małych plików przez sieć czy tez na pamięć
          masową, możemy odczuć że trwa to wieki, na pewno trwa to dłużej niż
          przesłanie jednego dużego pliku. Tutaj przedstawię sposoby na
          stworzenie
          jednego większego pliku z całego katalogu, przy czym użyjemy jeszcze
          kilku algorytmów kompresii, przez co zaoszczędzimy na czasie i trochę
          na zajmowanym miejscu. 
        </p>
        <h3 id="2.18.1.tarprogram">2.18.1. Program tar</h3>
        <p>
          Pierwsze narzędzie będzie służyć do tworzenia archiwum. Archiwa
          łączą pliki i katalogi w jeden plik. <strong>Tar</strong> jest 
          standardowym program do archiwizacji na uniksach. 
          Tworzenie archwium za pomocą <em>tar</em> wymaga kilku
          opcji. Natomiast składania polecenia jest następująca:
        </p>
<pre class="code-block">
$ tar -cvf archiwum.tar plik1 plik2...
</pre>
        <p>
          Opcja <code class="code-inline">-c</code> mówi programowi, że
          tworzone będzie nowe archiwum, opcja <code class="code-inline">-v</code>
          włącza komunikaty diagnostyczne wyświetlać one będą po kolei pakowane
          do archiwum pliki; opcja <code class="code-inline">-f</code>
          przekazuje programowi informacje o tym, że archwium będzie plikiem.
          Domyślnie <em>tar</em> tworzył archiwa na taśmach. Obecnie pominięcie
          tej opcji kończy pracę programu z komunikatem o błędzie. Możemy 
          natomiast użyć <em>stdout</em> podajac zamiast nazwy archiwum
          myślnik (<strong>-</strong>). Póki co to archiwum nie jest jeszcze 
          skompresowane.
        </p>
        <h4>Rozpakowywanie pliku</h4>
        <p>
          Rozpakowawanie różni się tylko jedną opcją - zamiast <em>-c</em> jest
          <strong>-x</strong>. Następnie podajemy pozostałe opcje, a na końcu
          nazwę pliku archiwum.
        </p>
        <h4>Wyświetlenie zawartości archiwum</h4>
        <p>
          Wypakowanie całego archiwum może nie być do końca porządane, załóżmy
          że potrzebujemy tylko jednego pliki. Za pomocą polecenia <em>tar</em>
          z odpowiednim przełącznikiem możemy wyświetlić listę plików w 
          archiwum. Zamiast <em>-x</em>, używamy
          <strong>-t</strong> reszta pozostaje taka sama, jeśli archiwum jest
          duże to możemy podłączyć wyjście <em>tar</em> potokiem do polecenia
          <em>less</em>. Samego wypakowania dokonujemy podając wypakowywanego
          pliku za nazwą archiwum.
        <p>
        <p>
          Ostanią dość istotną opcję jest <strong>-p</strong>, która powoduje
          zachowanie oryginalnych atrybutów plików, jakie miały podczas
          pakowania. Kiedy superużytkownika używa <em>tar</em>, ta opcja jest
          domyślnie włączona.
        </p>
        <h3 id="2.18.2.gzipprogram">2.18.2. Program gzip</h3>
        <p>
          Program <strong>gzip</strong> (<em>GNU zip</em>) jest standardowym 
          narzędziem kompresującym w systemach uniksowych. Pliki skompresowane
          za jego pomocą otrzymują rozszerzenie <strong>.gz</strong>.
          Dekompresuje się je za pomocą polecenia <strong>gunzip</strong>, jako
          argument podaje się nazwę pliku. Natomiast kompresji dokonuje za
          pomocą polecenia <strong>gzip</strong>, podając plik do 
          skompresowania jako argument. 
        </p>
        <h3 id="2.18.3.compressedarchives">2.18.3. Skompresowane archiwa
          <em>tar.gz</em></h3>
        <p>
          Obsługę skompresowanych archwów przy użyciu <em>gzip</em>,
          rozpoczniemy od rozpakowania takiego archiwum. Nie ma sensu używania
          do tego dwóch osobnych poleceń, jest to z resztą marnowanie zasobów.
          Chcąc rozpakować skompresowane <em>gzip</em> archiwum, należy użyć
          polecenia <em>tar</em> a po opcji
          <em>-x</em> dodać, opcję <em>-z</em> następnie pozostałe czyli
          <em>-vf</em> i na końcu podać nazwę archiwum. Tak jak na przykładzie: 
        </p>
<pre class="code-block">
$ tar -xzvf archiwum.tar.gz
</pre>
        <p>
          Przy tego typu archiwach, możemy spodziewać się rozszerzenia
          <strong>.tgz</strong>. Są to te same archiwa, jak te mające 
          rozszerzenie <em>tar.gz</em>.
        </p>
        <p>
          Przy wyświetlaniu zawartości takiego archiwum, zamieniamy opcję
          <strong>-x</strong> na <strong>-t</strong>. A chcąc takie archwiwum
          utworzyć to opcję <strong>-x</strong> na opcję <strong>-c</strong>
          oraz podać katalog lub listę plików, która ma zostać umieszczona w
          archiwum po jego nazwie.
        </p>
        <h3 id="2.18.4.othercompression">2.18.4. Inne metody kompresji</h3>
        <p>
          Poza archiwami spakowanymi za pomocą <em>gzip</em>, możemy też
          spotkać archiwa spakowane za pomocą <strong>bzip2</strong> oraz
          <strong>xz</strong>. W przypadku <em>bzip2</em>, to programem
          dekompresującym jest <strong>bunzip2</strong>, a opcją programu
          <em>tar</em> jest <strong>-j</strong> (mała litera j). Jeśli
          natrafimy na archiwum skompresowane <em>xz</em>, to programem
          dekompresującym jest <strong>unxz</strong>, a opcją programu
          <em>tar</em> jest <strong>-J</strong> (wielka litera j). 
        </p>
        <p>
          Część dystrybucji wyposażona jest w program <em>unzip</em>
          pozwalający na rozpakowanie plików <em>.zip</em> przygotowanych
          pod systemem MS Windows, jak i samo rozpakowywujących się plików
          <em>.exe</em>. 
        </p>
        <h2 id="2.19.filesystemhierarchy">2.19. Hierarchia katalogów</h2>
        <p>
          Struktura katalogów głównego, jest utworzona na
          podstawie <strong>standardu hierarchii systemu plików</strong>,
          określającego jakie podkatalogi ma zawierać katalog główny, oraz
          co te podkatalogi mają przechowywać. Poniżej opisano na ten czas
          najważniejsze z nich.
        </p>
        <ul>
          <li><strong>/bin</strong> - przechowuje pliki binarne przygotowane
            przez kompilator języka C, w nowocześniejszych systemach mogą to 
            być
            skrypty powłoki. W nim przechowywane są te najprostsze polecenia
            jak <em>cp</em>.</li>
          <li><strong>/dev</strong> - przechowuje pliku urządzeń.</li>
          <li><strong>/etc</strong> - katalog zawierający najważniejsze pliki
            konfiguracji systemu. Znajdują się tutaj pliki haseł, konfiguracji
            uruchamiania systemu, urządzeń, sieci i innych elementów systemu.</li>
          <li><strong>/home</strong> - zbiorczy katalog, katalogów domowych
            użytkowników. Standard wśród wszystkich nowoczesnych uniksów.</li>
          <li><strong>/lib</strong> - katalog przechowywujący biblioteki.
            Te pliki przechowują kod, który może być wykorzystywany przez 
            pliki wykonywalne. Biblioteki możemy podzielić na statyczne lub
            współdzielone. Tylko biblioteki współdzielone powinny znajdować
            się w tym katalogu, pozostałe pliki tego typu znajdują się
            w katalogu <em>/usr/lib</em>.</li>
          <li><strong>/proc</strong> - udostępnia statystyki o systemie w 
            postaci interfejsu plików i katalogów.
          </li>
          <li><strong>/sys</strong> - ten katalog jest podobny do katalogu
            <em>/proc</em>, z tym, że tworzy interfejs dla urządzeń oraz
            systemu. Wiecej informacji na ten temat, znajduje się w następnym
            rozdziale.
          </li>
          <li><strong>/sbin</strong> - w tym katalogu zapisane są systemowe
            pliki wykonywalne. Programy znajdujące się w katalogach
            <em>/sbin</em> przeznaczone są do zarządzania systemem, dlatego
            ten katalog nie występuje na ścieżce zwykłego użytkownika a wiele
            narzędzi będzie działać tylko z kontem <em>root</em>.
          </li>
          <li><strong>/tmp</strong> - w tym katalogu możemy umieszczać pliki
            tymczasowe, którymi nikt się nie będzie przejmować. Każdy
            użytkownik może zapisywać i odczytywać pliki z katalogu w tym
            katalogu, ale nikt nie ma dostępu do plików zapisanych przez innych
            użytkowników. Nie które programy wykorzystują, ten katalog jako
            przestrzeń roboczą. Nie należy zapisywać ważnych danych do tego
            katalogu, gdyż jego zawartość jest przez wiekszość dystrybucji 
            czyszczona podczas uruchamiania systemu, inne mogą usuwać 
            starsze pliki co jakiś czas.</li>
          <li><strong>/usr</strong> - W tym katalogu znajdziemy rozbudowaną,
            strukturę katalogów, bardzo podobną to katalogu głównego. W tym
            katalogu zapisana jest większa części systemu Linux.</li>
          <li><strong>/var</strong> - podkatalog zawierający "zmienne" dane
            zapisywane przez programy w czasie swojego działania. Tutaj 
            znajdują się m.in. pliki dzienników systemowych.</li>
        </ul>
        <h3 id="2.19.1.othermainsubdirs">2.19.1. Pozostałe katalogi główne</h3>
        <ul>
          <li><strong>/boot</strong> - przechowuje plik ładujące jądro systemu
          w czasie uruchamiania komputera. W większości dystrybucji w tym
          katalogu przechowywane są właściwe pliki jądra oraz początkowego
          systemu plików w pamięci RAM. Początkowy system plików pamięci RAM
          zostanie omówiony w dalszej materiału.</li>
          <li><strong>/media</strong> - w wielu dystrybucjach jest to główny
          punkt przyłączania wszystkich mediów wymiennych, takich jak
          karty pamięci Flash.</li>
          <li><strong>/opt</strong> - może przechowywać dodatkowe
          oprogramowanie firm trzecich. W wielu systemach katalog <em>/opt</em>
          nie jest wykorzystywany.</li>
        </ul>
        <h3 id="2.19.2.usrdirectory">2.19.2. Katalog /usr</h3>
        <p>
          To właśnie w katalogu <em>/usr</em> znajduje się większość programów
          i danych przestrzeni użytkownika, a są one rozlokowane po jego
          podkatalogach. Poniżej znajduje się opis co znajduje się w 
          poszczególnych podkatalogach tego katalogu:
        </p>
        <ul>
          <li><strong>bin</strong> - większość, jak nie wszystkie
            ogólnodostępne programy w systemie.</li>
          <li><strong>include</strong> - przechowuje pliki nagłówkowe
            wykorzystywane przez kompilator języka C.</li>
          <li><strong>info</strong> - zawierają strony dokumentacji
            <em>GNU</em> info.</li>
          <li><strong>local</strong> - miejsce gdzie administratorzy mogą
            mogą instalować swoje oprogramowanie, katalog ten może zawierać
            podobną identyczną strukturę, jak katalog <em>/usr</em> lub
            katalog główny.</li>
          <li><strong>man</strong> - przechowuje strony podręcznika
            systemowego.</li>
          <li><strong>share</strong> - kiedyś ten katalog był katalogiem
            współdzielonym między komputerami, obecnie stracił na znaczeniu.
            Mimo to dalej przechwouje informacje, przeważnie są to pliki ikon, 
            pliki zawierające znaki
            towarowe dystrybucji oraz inne dane z których może korzystać wiele
            programów. Ten katalog może zawierać podkatalogi takie jak
            <em>man</em> oraz <em>info</em>.</li>
        </ul>
        <h3 id="2.19.3.kernelplace">2.19.3. Umiejscowanie jądra w systemie</h3>
        <p>
          Wspomniałem już że plik jądra znajduje się w katalogu <em>/boot</em>,
          plik ten rozpoczyna się od nazwy <strong>vmlinuz</strong>, po tych
          znakach
          mogą wystąpić inne inforamcje oznaczające jego wersje. Po załadowaniu
          jądra przez program rozruchowy, sam plik przestaje być
          potrzebny. W trakcie pracy systemu operacyjnego jądro wykorzystuje
          najróżniejsze ładowane i usuwane dodatkowo modułu. <strong>Ładowane
          moduły jądra</strong> umieszczane są w katalogu <em>/lib/modules</em>.
        </p>
        <h2 id="2.20runitasroot">2.20. Uruchamianie poleceń przez superużytkownika</h2>
        <p>
          Korzystając z linuksa na naszym osobistym komputerze, przyjdzie taki
          moment że będziemy musieli skorzystać z konta użytkownika 
          <em>root</em>. Aby to zrobić możemy przelogować się na jego konto
          wykonać potrzebne czynności a następnie się wylogować. Ta czyność
          przyniosła by zamierzony efekt ale nie jest bez wad. Dlatego też
          możemy skorzystać z polecenia <strong>sudo</strong>, które
          pozwoli, na uruchomienie polecenia podanego jako arugment 
          z uprawnieniami
          superużytkownika. Jeśli polecenie nie występuje w systemie, to jest
          dobry czas aby przelogować się na użytkownika <em>root</em>, i je
          zainstalować. Polecenie po zainstalowaniu nie zadziała samo w sobie
          potrzebne jest jeszcze określenie, którzy użytkownicy mogą używać
          tego polecenia i co za jego pomocą mogą zrobić. Za to odpowiada
          pliki <strong>/etc/sudoers</strong>.
        </p>
        <h3 id="2.20.1.sudoersfile">2.20.1. Plik /etc/sudoers</h3>
        <p>
          Samo polecenie sudo ma bardzo duża ilość opcji, jednak na tym
          etapie nie skorzystamy z większości z nich. Najprostszym sposobem
          na konfiguracje pliku <em>/etc/sudoers</em> jest odnalezienie w pliku
          linii rozpoczynającej się pod słowa <em>root</em> a następnie
          pod tą linią wpisać linię rozpoczynjącą się nazwy użytkownika oraz
          dopisaniu kilku opcji, tak jak na poniższym przykładzie.
        </p>
<pre class="code-block">
user ALL=(ALL) ALL
</pre>
        <p>
          Pierwsze <code class="code-inline">ALL</code>, oznaczna dowolny
          komputer. Drugie
          <code class="code-inline">(ALL)</code> w nawiasach oznacza, że możemy
          wydać polecenie jako dowolny użytkownik, być może spotkamy się
          z takim zapisem w nawiasie (<em>ALL:ALL</em>), oznacza ono dowolnego
          użytkownika i dowolną grupę. Trzecie <code class="code-inline">ALL</code>
          oznacza dowolne polecenie.
        </p>
        <p>
          Jeśli drażnić nas będzie ciągłe wpisywanie haseł, to możemy przed
          trzecim <em>ALL</em> w konfiguracji umieścić opcję 
          <strong>NOPASSWD</strong>, pamiętając aby pomiędzy te opcje wstawić
          dwukropek (<strong>:</strong>) bo tak naprawdę określamy jakie
          polecenia mają być uruchamiane bez podawania hasła.
        </p>
        <h2 id="2.21.summary">2.21. Podsumowanie</h2>
        <p>
          Po przeczytaniu tego rodziały wydaje mi się, że każdy ma solidne
          podstawy obsługi systemu Linux z poziomu powłoki. Powłoka jest
          jednym ze stałych komponentów dystrybucji, a wiele z nich dalej
          obstaje przy BASH-u, jako domyślnej powłoce.
        </p>
        <h1 id="3.devices">3. Urządzenia</h1>
        <p>
          Odkąd powstał system Linux, w sposobach prezentowania urządzeń
          użytkownikowi zachodziło wiele zmian. Na początku tego rozdziału
          omówimy sobie tradycjny system <strong>sysfs</strong>. Aby potem
          zająć się omówieniem systemu <strong>udev</strong>, pozwalającego 
          programom przestrzeni użytkownika automatycznie konfigurować oraz
          używać nowych urządzeń. Podczas normalnego użytkowania systemu
          rzadko będziemy mieć okazję do zarządzania urządzeniami. Nasza
          interakcja z urządzeniami będzie ograniczać się do obsługi pamięci
          masowych i korzystania najstarszego i naprostszego interfejsu jakim
          jest katalog <em>/dev</em>. Mimo to, warto jednak wiedzieć w systemie
          co jest od czego. 
        </p>
        <h2 id="3.1.devicefiles">3.1. Pliki urządzeń</h2>
        <p>
          Jądro udostępnia wiele urządzeń pod postacią plików, co daje nam
          możliwość prostej manipulacji nimi. Te pliki są często nazywane
          <strong>węzłami urządzeń</strong>. Korzystać z urządzeń możemy
          za pomocą zwykłych operacji na plikach. Tego typu rozwiązanie nie
          jest bez wad dlatego też nie wszystkie urządzenia lub ich funkcje
          są udostępnianie w ten sposób.
        </p>
        <p>
          Pliki urządzeń są przechowywane w katalogu <strong>/dev</strong>.
          A najprostszym sposobem interakcji z urządziem jest przekierowanie
          wyniku jakiegoś polecenia do urządzenia <strong>/dev/null</strong>.
          Urządzenie to jest miejscem na nie potrzebne nam dane ze strumieni,
          ponieważ cokolwiek trafi do tego urządzenia, jest przez jądro
          poprostu ignorowane.
        </p>
        <p>
          Wyświetlając sobie zawartość katalogu w bardziej szczegółowej liście
          może zauważyć dziwne oznaczenia w trybie pliku. Litery te określają
          rodzaje urządzeń a wśród nich możemy wyszczególnić:
        </p>
        <ul>
          <li><strong>Urządzenia blokowe - b</strong> - Procesy mogą odczytywać
            dane z urządzeń blokowych przy użyciu bloków o stałej wielkości.
            Pamięci masowe są przykładem urządzeń blokowych. Łatwo dzieli się 
            je na bloki, a ogólna wielkość
            takiego urządzenia jest stała i można ją zindeskować, co daje
            możliwość jądru na dostępu do dowolnego bloku danych.</li>
          <li><strong>Urządzenia znakowe - c</strong> - Urządzenia znakowe
            działają w oparciu o strumienie danych. Do takich urządzeń można
            zapisywać i odczytywać pojedyńcze znaki. Jądro zazwyczaj wykonuje
            operacje odczytu i zapisu na fizycznym urządzeniu. Drukarki są 
            przykładami urządzeń znakowych. Warto wspomnieć, że jądro nie
            jest w stanie ponownie odczytać danych ze strumienia po przekazaniu
            ich dalej do procesu.</li>
          <li><strong>Urządzenia potokowe - p </strong> - tzw.
            <strong>nazwane potoki</strong> są to urządzenia podobne do
            urządzeń znakowych z tą jednak różnicą, że na drugim końcu
            strumienia wejścia-wyjścia nie znajduje się fizyczne urządzenia ale
            inny proces.</li>
          <li><strong>Urządzenia gniazdkowe - s</strong> - tzw. <strong>gniazda</strong>
            są interfejsami specjalnego przeznaczenia i służa komunikacji
            międzyprocesowej. Mogą występować poza katalogiem <em>/dev</em>.</li>
        </ul>
        <p>
          Inną dość rzucającą się w oczy informacją na listingu katalogu, są
          dwie liczy odzielone przecinkiem zamiast rozmiaru pliku, jest
          <strong>numer główny</strong> i <strong>numer poboczny</strong>.
          Te numer ułatwiają jądru identyfikacje urządzeń. Dla przykładu
          partycje tego samego dysku mają ten sam <em>numer główny</em> ale
          inny <em>numer poboczny</em>.  
        </p>
        <p>
          Nie wszystkie urządzenia mają swoje pliki, takim przykładem są
          interfejsy sieciowe. Jądro wykorzystuje dla nich inny interfejs
          wejścia-wyjścia.
        </p>
        <h2 id="3.2.sysfsdevicepath">3.2. Ścieżka urządzeń sysfs</h2>
        <p>
          Ze względu na uproszczoną interakcje z urządzeniami poprzez 
          odwołowywanie się do pliku w katalogu <em>/dev</em> oraz fakt, że
          jądro systemu nadaje plikom z tego katalogu nazwy na podstawie
          koleności wykrywania urządzeń podczas uruchamiania systemu,
          wewnątrz jądra zaimplementowano interfejs <strong>sysfs</strong>.
          <em>Sysfs</em> jest ujednoliconym sposobem prezentacji urządzeń 
          bazującym
          na atrybutach sprzętowych, mający formę struktury katalogów i plików.
          Główny katalogiem tego systemu jest katalog <strong>/sys/devices</strong>.
          Przykładowa ścieżka dla pierwszego dysku SATA mającego swój plik
          <em>/dev/sda</em> może wyglądać następująco:
        </p>
<pre class="code-block">
/sys/devices/pci0000:00/0000:00:1f:2/host0/target0:0:0/0:0:0:0/block/sda
</pre>
        <p>
          Warto tutaj zaznaczyć iż, scieżki systemu <em>sysfs</em> nie służą 
          uzyskaniu dostępu do urządzeń, umożliwają przeglądanie informacji
          oraz zarządzanie urządzeniami. Dane zawarte na plikach na ścieżkach
          <em>sysfs</em> powinny być odczytywane przez programy nie przez
          ludzi.
        </p>
        <p>
          Chcąc sprawdzić scieżkę <em>sysfs</em> dla dowolnego urządzenia z
          katalogu <em>/dev</em> należało by uzyć programu systemu <em>udev</em>
          <strong>udevadm</strong>.
        </p>
<pre class="code-block">
$ udevadm info --query=all --name=/dev/sda
</pre>
        <p>
          Wykonując to polecenie dowiemy się przy okazji ile danych można 
          uzyskać informacji z systemu <em>udev</em>.
        </p> 
        <h2 id="3.3.ddcommand">3.3. Polecenie dd</h2>
        <p>
          Polecenie <strong>dd</strong> jest dość prostym, aczkolwiek 
          przydatnym narzędziem jeśli
          choodzi o prace z urządzeniami znakowymi czy blokowymi. Jedyną
          rzeczą, którą robi to polecenie jest odczyt danych z pliku 
          wejściowego lub ze strumienia i zapisanie go do wyjściowego pliku
          lub strumienia, przy okazji dokonując pewnych konwersji. Najczęsciej
          używane przeze mnie polecenie znajduje się poniżej. 
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=/dev/sdX count=1
</pre>
        <p>
          Polecenie wykorzystuje uprawnienia superużytkownika, aby uzyskać
          dostęp do urządzenia blokowego. Samo polecenie zapisuje jeden
          blok o wielkości 1M za pomocą zer z pliku <em>/dev/zero</em> 
          (nieskończony strumień zer), co powoduje usunięcie tablicy partycji
          (o której będzie w następnym rodziale).
        </p>
        <p>
          Poniżej zostaną opisane najważniejsze opcje programu <em>dd</em>,
          ich format różni się od innych programów uniksowych. Do przypisania
          wartości opcją używa się tutaj znaku równości (<strong>=</strong>).
        </p>
        <ul>
          <li><strong>if=plik</strong> - plik wejściowy. Domyślnie stosowane
            jest standardowe wejście.</li>
          <li><strong>of=plik</strong> - plik wyjściowy. Domyślnie stosowane
            jest standardowe wyjście.</li>
          <li><strong>bs=rozmiar</strong> - rozmiar bloku danych. Polecenie
            przesyła wiele bloków naraz, więc możemy użyć wielokrotności 
            takich jak: bajt - <em>B</em>, kilobajt - <em>K</em>, megabajt -
            <em>M</em>, gigabajt - <em>G</em> i tak dalej.</li>
          <li><strong>ibs=rozmiar</strong>, <strong>obs=rozmiar</strong> - 
            rozmiar blok wejściowego oraz bloku wyjściowego, jeśli nie możliwe
            jest stosowanie dla plików wejściowych oraz wyjściowych tego
            samego rozmiaru bloku.</li>
          <li><strong>count=liczba</strong> - liczba kopiowanych bloków.</li>
          <li><strong>skip=liczba</strong> - powoduje pominięcie pierwszych
            <em>liczba</em> bloków danych. Nie są one kopiowane do pliku
            wyjściowego.</li>
        </ul>
        <p>
          Przy korzystaniu z <em>dd</em>, należy uważać gdyż literówka w 
          poleceniu wystarczy, aby uszkodzić system lub spowodować utratę
          ważnych dla nas danych.
        </p>
        <h2 id="3.4.namingsummary">3.4. Podsumowanie nazewnictwa urządzeń</h2>
        <p>
          Do pracy z urządzeniami potrzebujemy jego nazwy. W systemie istnieje
          kilka metod pozwalających na ustalenia nazwy urządzenia.
        </p>
        <ul>
          <li>Odpytanie systemu <em>udev</em>, za pomocą polecenia <em>udevadm</em>.</li>
          <li>Przeszukanie katalogu <em>/sys</em>.</li>
          <li>Wyświetlenie plików dziennika jądra za pomcą polecenia <em>dmesg</em>,
              w plikach dziennika znajdują się jego ostatnie komunikaty w tym
              informacje o znalezionych urządzenia i nadanych im nazwach.</li> 
          <li>Jeśli to dysk i jest on widoczny w systemie to możemy skorzystać
              z polecenia <em>mount</em>, chyba że nasz system nie montuje
              samodzielnie partycji, to w tym przypadku możemy skorzystać z
              polecenia <strong>fdisk</strong> z opcją <strong>-l</strong>.</li>
          <li>Ostatni sposób działa tylko dla urządzeń blokowych oraz znakowych.
              W katalogu <em>/proc/devices</em> znajduje się zestawienie 
              urządzeń reprezentowanych przez <em>numer główny</em> oraz przez
              przypisany im sterownik. Wystarczy użyć <em>numeru głównego</em>
              jako wyrażenia regulanego i zastosować go na listingu katalogu
              <em>/dev</em>.</li>
        </ul>
        <p>
          Dzisiaj praca z urządzeniami na Linuksie sprowadza się głównie do
          partycjonowania dysku, więc aby znależć właściwe urządzenie wystarczy
          użyć polecenia <em>fdisk -l</em>.
        </p>
        <p>
          Na poniższej liście znajdują się najczęściej wykorzystywane na
          Linkusie konwencje nazwenicze.
        </p>
        <ul>
          <li><strong>Dyski twarde SATA - /dev/sd*</strong> - Nazewnictwo
            dysków pochodzi od protokołu SCSI, mimo iż same urządzenia SCSI
            wyszły z użycia. To protokół mający świetne zdolności adaptacyjne
            cały czas działa we współczesnych systemach. Nazwa np. <em>/dev/sda</em>
            odnosi się do całego dysku. Partycje oznaczne są dodatkowo liczbą
            np. <em>/dev/sda1</em>. Pamięci masowe ze złączem USB również 
            wykorzysują podsystem SCSI do komunikacji z komputerem dla tego też
            dyski tego typu również mogą występować jak <em>/dev/sd*</em>.</li>
          <li><strong>Napędy CD i DVD - /dev/sr*</strong> - Napędy optyczne
            tak samo jak dyski korzystają z SCSI. Jednak te urządzenia są tylko
            do odczytu. Jeśli chcielibyśmy skasować zawartość płyty, lub na
            niej coś nagrać, to należało by się odwołać do ogólnego urządzenia
            którego nazwa może byc na przykład taka: <em>/dev/sg0</em>. Raczej
            jednak do nagrywania płyt będziemy wykorzystywać specjalne 
            oprogramowanie.</li>
          <li><strong>Dyski twarde PATA - /dev/hd*</strong> - w starszych
            wersjach jądra, dyski były przedstawione za pomocą innych nazw.
            Obecnie dyski PATA również wykorzystują SCSI, więc ich nazwy nie
            będą się różnić od dysków SATA.</li>
          <li><strong>Terminale - /dev/tty1, /dev/pts/*, /dev/tty</strong> -
            Terminale są urządzeniami przeznaczonymi do przesyłania znaków
            pomiędzy system a urządzeniem wejscia-wyjścia, co najczęściej
            ma celu wyświetlanie tekstu na ekranie terminala. Pseudoterminale
            posiadają wyszystkie funkcję fizycznych terminali, jednak jądro
            nie komunikuje się z fizycznym urządzniem, a z programowym 
            interfejsem wejscia-wyjścia takim jak okno powłoki. Urządzenie
            <em>/dev/tty1</em> to pierwsza wirtualna konsola, a
            <em>/dev/pts/0</em> to pierwsze okno powłoki. Linux do działania
            nie potrzebuje klasycznego interfejsu użytkownika, jaki znamy
            z innych systemów operacyjnych. Nie potrzebuje okien, paska zadań,
            menu "Start" i innych elementów graficznych. Równie dobrze może
            działać jak system 'DOS' w tzw. <strong>trybie tekstowym</strong>.
            Praca w tym trybie pozwala na wykorzystanie komputera znacznym
            stopniu.
            Jedyne czego nie będziemy w stanie zrobić to skorzystać z czego
            kolwiek co wymaga wyświetlania graficznego wymagającego pokazania
            na ekranie czegoś więcej niż teskt i 8 podstawowych kolorów. 
            <strong>Tryb graficzny</strong>
            zawiera wszystkie te rzeczy znane z innych systemów operacyjnych a
            wymienione zostały one powyżej, choć to wszystko zależy od
            uruchomionego menadżera okien. Pierwsza wirtualna
            konsola jest pierwszym ekranem powłoki w trybie tesktowym, okna
            powłoki mogą wystąpić w środowisku graficznym po uruchomieniu
            odpowiedniego programu <em>Terminal</em> lub w przypadku trybu 
            tesktowego multipleksera terminala. Multipleksery są powielaczami, 
            pozwalającymi
            podzielić konsolę na kilka mniejszych "okien", w których możemy
            uruchomić kolejną powłokę. Zaś urządzenie <em>/dev/tty</em>, jest
            odniesienie procesu do właściwego terminala, jeżeli program
            odczytuje i zapisuje dane do terminala.</li>
          <li><strong>Porty szeregowe - /dev/ttyS*</strong> - są specjalnymi
            urządzeniami terminalowymi pozwalającymi na komunikację z różnej
            maści sprzętem wykorzystując do tego oprogramowanie, które pozwoli
            skonfigurowanie komunikacji. Porty szeregowe otrzymują w systemie
            nazwy kolejno: <em>/dev/ttyS0</em> itd. w zależności od tego ile
            mamy portów zainstalowanych w komputerze. Do połączenia za pomocą
            portu szeregowego można wykorzystać adaptery USB, te urządzenia 
            mogą posiadać następujące nazwy: /dev/ttyUSB* lub /dev/ttyAMC*.
            Modemy sieci komórkowych mogą występować w systemie pod postacią
            adapterów USB portów szeregowych.</li>
          <li><strong>Porty równoległe - /dev/lp0, /dev/lp1</strong> - służyły
            do podłączenia drukarek wykorzystujących port LPT. Obecenie
            zostały zastąpione przez porty USB. Drukarki mogą wymagać
            dodatkowych znaków sterujących, dlatego też do drukowania lepiej
            wykorzystać serwer druku CUPS, niż pisanie bezpośrednio do tego
            portu.</li>
          <li><strong>Urządzenia audio - /dev/dsp, /dev/audio, /dev/snd/*</strong> -
            Na Linuksie dostępne są dwa zestawy urządzeń odpowiadająych za
            dźwiek. Starszy, rzadziej spotykany system <em>OSS</em>
            korzystający z urządzeń <em>/dev/dsp</em> oraz <em>/dev/audio</em> 
            i nowszysz spotykany w większości dystrybucji <em>ALSA</em>
            używający urządzeń w katalogu <em>/dev/snd</em>. System dzwięku
            na Linuksie może być dwuwartstwowy, ponieważ do dyspozycji mamy
            serwer pośredniczący <em>PulseAudio</em>, główną jego zaletą jest
            łatwa możliwość przełącznia wyjść dzwięku oraz proste zarządzanie
            całym podsystem dźwięku z poziomu jednego panelu. Wykorzystanie
            samego systemu <em>ALSA</em> jest wystarczające, jednak
            nie zbyt wygodne, ale oczywiście co kto lubi.</li>
        </ul>
        <h3 id="3.4.1.makedev">3.4.1. Tworzenie plików urządzeń</h3>
        <p>
          We współczesnych systemach nie ma potrzeby samodzielnego tworzenia
          urządzeń, jednak czasami w specyficznych konfiguracjach może dość
          do potrzeby utworzenia urządzenia. Osobiście spotkałem się z takim
          przypadkiem konfigurując VPN na dystrybucji Alpine Linux, należało
          osobiście utworzyć urządzęnie znakowe TUN. 
        </p>
        <p>
          Urządzenie tworzymy za pomocą polecenia <strong>mknod</strong>,
          podając nazwę urządzenia, jego rodzaj i w zależności od rodzaju
          <em>numer główny</em> oraz <em>numer poboczny</em> (w przypadku
          nazwanych potoków, nie trzeba podawać <em>numery głównego</em> i
          <em>numeru pobocznego</em>.
        </p>
        <h2 id="3.5.udev">3.5 System udev</h2>
        <p>  
          Zarządzanie plikami urządzeń jest jedną z cech jądra, która
          mogła działać w przestrzeni użytkownika. Jądro tylko gdyby wykryło
          nowe urządzenie wysłało by powiadomienie do procesu
          <em>udevd</em>. Proces ten zbadał by charakterystykę urządzenia,
          utworzył dla niego odpowiedni plik, a na koniec przewprowadził 
          jego inicjację. Niestety to tylko teoria. 
        </p>
        <p>
          Rozwiązanie tego typu nie uwzględnia kilku problemów. Pliki urządzeń
          są potrzebne już na wszczesnych etapach uruchamiania, zatem proces
          <em>udev</em> musiał by zostać uruchomiony bardzo wcześnie, nie może
          mieć żadnych zależności wobec plików urządzeń i uruchomić się
          błyskawicznie, aby nie spowalniać procedury rozruchu systemu.
        </p>
        <h3 id="3.5.1.devtmpfs">3.5.1. System plików devtmpfs</h3>
        <p>
          System plików (będzie o tym w dalszej części materiału)
          <strong>devtmpfs</strong>, został opracowany w celu rozwiąznia
          problemów z dostęp do urządzeń w czasie uruchamiania systemu. W razie
          gdy jądro będzie potrzebować pliku urządzenia to utworzy je oraz
          powiadamia o tym fakcie system <em>udev</em>, który zamiast zajmować
          się tworzeniem pliku przystępuje do inicjacji urządzenia i informuje
          o tym pozostałe procesy. Po za tym proces <em>udev</em> tworzy kilka
          dowiązań symbolicznych w katalogu <em>/dev</em>, które bardziej
          szczegółowo identyfikują urządzenie, wyniki tego działania możemy
          obejrzeć w katalogu <em>/dev/disk/by-id</em>.
        </p>
        <p>
          System <em>udev</em>, tworzy nazwy dowiązań bazdując na typie
          interfejsu, nazwie producenta, informacji o modelu, numerze seryjnym
          oraz partycji. Proces pobiera te informacji na podstawie reguł
          systemu <em>udev</em>, jednak nie będziemy się tym tutaj zajmować.
        </p>
        <h1 id="4.disksandfs">4. Dyski i systemy plików</h1>
        <p>
          Dyski w systemach Linux przedstawiane są jako urządzenia blokowe z
          nazwami pochodzącymi od podsystemu SCSI - <em>/dev/sdX</em>. Z punktu
          widzenia systemu na dysku znajduje się wiele warstw oraz 
          komponentów. Wybrane częsci dysku możemu zaalokować na partycje,
          które system prezentuje w taki sam sposób jak dyski, dodają liczbę
          na końcu nazwy dysku. Wystąpienia partycji na dysku przechowywane
          są w <strong>tablicy partycji</strong>.
        </p>
        <p>
          Jądro systemu umożliwia dostęp do całego urządzenia (dysku) oraz do
          partycji dzięki osobnym plikom urządzeń.
        </p>
        <p>
          Każdy dysk musi posiadać chociażby jedną partycję, aby był użyteczny
          w systemie, z kolei taka partycja musi zostać sformatowana pod
          wybrany system plików, aby mogła przez chowywać jakie kolwiek dane.
          <strong>System plików</strong> możemy określić mianem bazy danych
          przechowywującej informacje na temat plików i katalogów.
        </p>
        <h2 id="4.1.partitioning">4.1. Partycjonowanie dysków</h2>
        <p>
          Partycjonowanie dysku, odbywa się w oparciu o schematy. <strong>
          Schematy partycjonowania</strong> okreslają ilość możliwych do
          utworzenia na dysku partycji oraz ewentualne dodatkowe informacje
          przechowywane w tablicy partycji. Wśród obecnie stosowanych możemy
          wyróżnić takie schematy jak <strong>MBR</strong> oraz <strong>GPT</strong>.      
        </p>
        <p>
          Na Linuksie dostępnych jest wiele narzędzi partycjonujących dysk,
          jedne są obsługiwane jak z poziomu środowiska graficznego inne
          zaś z poziomu terminala. Osobiście używam programu <strong>fdisk</strong>
          i to na nim skupię się jeśli chodzi o partycjonowanie. Program ten
          ma dwie istotne zalety. Po pierwsze nic nie zostanie zapisane do
          momentu gdy nie wydamy polecenia (Tak, w <em>fdisk</em> wydaje się
          polecenia, ale są one ograniczone do wpisania jednej litery i
          naciśnięcia klawisza <em>enter</em>); po drugie w pakiecie <em>fdisk</em>
          zawarty jest również program <strong>sfdisk</strong> (co prawda z
          nieco dziwną składnią), ktory umożliwia manipulowanie dyski z poziomu
          pojedynczych polecenie (w przypadku <em>fdisk</em> wykorzystywany 
          jest tryb interaktywny), przez co możemy użyć <em>sfdisk</em> w 
          skrypcie.
        </p>
        <h3 id="4.1.1.listingpartitiontable">4.1.1. Przeglądanie tablicy partycji</h3>
        <p>
          Przy użyciu polecenia:
        </p>
<pre class="code-block">
$ sudo fdisk -l
</pre>
        <p>
          możemy wyświetlić zawartość tablicy partycji wszystkich dysków w
          systemie, Jeśli zaś interesuje nas wybrane urządzenie możemy wpisać
          jego nazwę po opcji <code class="code-inline">-l</code>. Informacja
          zwracana przez polecenie zawiera informacje o schemacie
          partycjonowania w polu <em>Disklabel type:</em> oraz tabele
          przedstawiającą nazwę urządzenia, informacje o ustwionej fladze
          rozruchu, początku, końcu i rozmiarze podanym w sektorach (informacja
          ile wynosi sektor znajduje się w linii <em>Sector size</em>) oraz 
          identyfikatorze i nazwie typu partycji. Identyfikatory można wypisać
          podczas nadawania typu. 
        </p>
        <p>
          Schemat partycjonowania MBR nazwany jest <em>fdisk</em> <strong>dos</strong>.
          Identyfikator dysk jest krótszy. W przypadku tablicy partycji
          <em>GPT</em> identyfikator dysku zawiera ciągu znaków odzielone
          spacjami, nie występują w tabeli identyfikatory typów partycji
          ponieważ są tak duże jak identyfikator dysku (podczas ustalania
          wybierane są z wyświetlonej listy) oraz może wystąpić dodatkowa
          kolumna przechowywująca etykietę partycji. Jednak główną różnicą
          wśród tych schematów jest zarządzanie miejscem na dysku. Dyski z
          tablicami MBR mogą mieć maksymalną pojemność do 2TB, jeśli użyjemy
          wiekszego, to stosując tego typu partycję pozbędziemy się pozostałej
          części dysku, kolejny minus dla tego rodzaju to możlwość tworzenie
          maksymalnie czterech <strong>partycji podstawowych</strong>
          (zwykłych partycji na dane), jeśli 
          chcielibyśmy
          więcej owszem możemy jednak, musimy użyć jedno miejsce na 
          <strong>partycję rozszerzoną</strong>
          bedącą kontenerem dla dysków logicznych. W przypadku
          GPT raczej maksymalna wielkość dysku nie jest póki co osiąglna 
          (9,4 mld TB) a partycji podstawowych możemy utworzyć, aż 128. To są
          tak naprawę za i przeciw, które decydują o użytym schemacie.
        </p>
        <h3 id="4.1.2.modifypartition">4.1.2. Modyfikowanie tablicy partycji</h3>
        <p>
          Modyfikowanie tablicy partycji należy rozpocząć, od zastanowienia się
          na temat przydatności danych, które znajduja się obecnie na dysku.
          Ponieważ modyfikowanie tablicy partycji, często będzie wiązać się z
          potrzebą reformatowania modyfikowanej partycji. W stopniu podstawowym
          skupimy się tworzeniu oraz usuwaniu partycji. Modyfikowanie tablicy
          za pomocą <em>fdisk</em>, jest dość łatwe, polega na interaktywnym
          wydawaniu poleceń oraz odpowiadniu na pytania programu, dlatego też
          dla urozmaicenia użyjemy <strong>sfdisk</strong> zamiast wymienionego
          wcześniej programu. Dla przykładu stworzymy dysk do klasycznej
          instalacji systemu Linux z tablicą partycji typu MBR. Za dysk testowy
          może posłużyć nam pendrive, karta pamięci lub plik na dysku. Ja
          skorzystam z pliku. 
        </p>
        <p>
          Plik przygotowuje za pomocą polecenia <em>dd</em> poznanego w
          poprzednim rozdziale.
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=vhd.img count=8192
</pre>
        <p>
          Zapisanie 8GB zer może chwilę potrwać. Po utworzeniu pliku przechodzę
          do jego inicjalizacji.
        </p>
<pre class="code-block">
$ echo "label:dos" | sudo sfdisk vhd.img
</pre>
        <p>
          Polecenia <em>sfdisk</em> muszą pochodzić ze strumienia lub z
          wcześniej przygotowanego skryptu. Polecenie tworzy na dysku
          tablice partycji typu MBR. Kolejne polcenie będą już poleceniami
          właściwymi tworzącymi partycje na naszym dysku.
        </p>
        <p>
          Polecenia <em>sfdisk</em> składają się z czterech pól:
        </p>
        <ul>
          <li><strong>początkowy sektor</strong> - w pierwszym polu wskazujemy
            od którego sektora na dysku ma zaczynia się partycja. Pierwsza
            partycja zawsze zaczyna się od drugiego megabajtu dysku. Wartość
            ta jest najczęściej pomijana i pozostawiana do decyzji programowi.</li>
          <li><strong>wielkość partycji</strong> - wielkość partycji podajemy
            zapisując na początku znak plusa (<strong>+</strong>) następnie
            podając jej wielkość w wygodnej dla nas wielkrotności bajtu,
            pamiętając że zapisując jednostkę, używamy tylko pierwszej litery
            (dla GB nie jest GB tylko G).</li>
          <li><strong>typ partycji</strong> - typ partycji określany jest za 
            pomocą pojedyńczej litery dla zywkłej partycji na dane Linuksa
            jest to <strong>L</strong>, dla przestrzeni wymiany (będzie o niej
            za chwilę) jest <strong>S</strong>, a dla partycji rozszerzonej
            jest to <strong>E</strong>.</li>
          <li><strong>flaga rozruchowa</strong> - flaga rozruchowa była
            stosowana dawniej, obecnie straciła na znaczeniu. I jej obecność
            może służyć zaznaczeniu partycji przechowywującej podkatalog
            <em>/boot</em> katalogu głównego.</li> 
        </ul>
        <p>
          Po utworzeniu pierwszej partycji, każda kolejna będzie wymagać 
          podania podania opcji <strong>-a</strong>,  która spowoduje
          wykorzystanie wcześniej utworzonej tablicy partycji oraz jej numeru 
          po opcji <strong>-N</strong> przed wskazaniem
          poleceniu urządzenia. Zatem pierwszą partycję tworzymy za pomocą
          poniższego polecenia:
        </p>
<pre class="code-block">
$ echo ",+7G,L,*" | sudo sfdisk vhd.img
</pre>
        <p>
          Pierwszej partycji przydzielono większość miejsca na dysku, będzie
          ona przechowywać katalog główny. Resztę miejsca wykorzystamy na
          partycję rozszerzoną, a wewnątrz niej utworzymy dysk logiczny będący
          partycją wymiany.
        </p>
<pre class="code-block">
$ echo ",,E," | sudo sfdisk -a -N 2 vhd.img
$ echo ",,S," | sudo sfdisk -a -N 5 vhd.img
</pre>
        <p>
         Teraz możemy wyświetlić sobie tablice dysku, który partycjonowaliśmy.
         Zwróćmy uwagę na to, że wystarczy odpowiedni numer partycji aby
         utworzyć dysk logiczny. Pominięcie rozmiaru spowoduje zaalokowanie
         pozostałego wolnego miejsca. Tak przygotowane partycje są gotowe do
         sformatowania pod wybrany system plików. 
        </p>
        <h4>Usuwanie partycji</h4>
        <p>
          Eksperymentując poraz pierwszy z <em>sfdisk</em> może nam coś nie
          wyjść dlatego też zamiast rozpoczynać partycjonowanie od nowa możemy
          źle przygotowaną partycję usunąć. Wydając polecenie <em>sfdisk</em>
          opcję <strong>--delete</strong> następnie nazwę urządzenia oraz
          numer partycji, którą chcemy usunąć.
        </p>
        <p>
          Korzystając z <em>sfdisk</em> pozbawiamy się bufora, ponieważ 
          program ten zmienia tablicę partycji z każdą modyfikacją. Jeśli
          chcemy tylko sprawdzić jak będą wyglądać pewne zmiany to lepiej
          użyć polecenia <em>fdisk</em>. Pomoc uruchamiana jest
          za pomocą polecenia <strong>m</strong> po uruchomieniu programu.
        </p>
        <h2 id="4.2.filesystems">4.2. Systemy plików</h2>
        <p>
          Systemy plików umożliwiają zamianę prostego urządzenia blokowego
          w sktrukturę plików i katalogów zarozumiałą dla końcowego użytkownika.
          Dawniej służyły głównie przchowywaniu plików jednak obecne ich
          funkcje umożliwiają wykorzystanie ich jako interfejsów systemowych
          w takich katalogach jak <em>/proc</em> czy <em>/sys</em>.
        </p>
        <p>
          Normalnie systemy plików są implementowane w jądrze systemu, jednak
          rozwiązana zastosowane w następcach Uniksa, takich jak <em>Plan 9</em>.
          umożliwiły stworzenie systemów plików działających w przestrzeni
          użytkownika, tzw. <strong>FUSE</strong>. Dzięki tej funkcji możemy
          zapisywać dane na nośnikach z takim system plików jak NTFS.
        </p>
        <p>
          Istotną funkcję jeśli chodzi o sposób działania systemów plików, jest
          wykorzystanie <strong>VFS</strong>, który standaryzuje dostęp do
          plików i katalogów dla aplikacji użytkownika, dlatego też Linux 
          obsługuje tak wiele systemów plików.
        </p>
        <h3 id="4.2.1.fstypes">4.2.1. Typy systemów plików</h3>
        <p>
          Mimo iż Linux, może obsługiwać chyba wszystkie możliwe systemy plików,
          to większość z nich wymaga dodatkowego oprogramowania. Natywnie 
          obsługiwane systemy plików Linuksa znajduje się na liście poniżej.
        </p>
        <ul>
          <li><strong>EXT4</strong> (<em>Czwarty rozszerzony system plików</em>)
              - domyślny i najpopularniejszy system plików dla linuksa, 
              wyposarzony w pliki dziennika, znane z <em>ext3</em> oraz
              zwiększone limity związane z wielkością plików oraz ilością
              podkatalogów w katalogu względem wersji trzeciej. W przyszłości
              może zostać zastąpiony przez <em>btrfs</em> lub <em>xfs</em>.</li>
          <li><strong>iso9660</strong> - standardowy system plików stosowany na
              płytach CD-ROM.</li>
          <li><strong>FAT</strong> - rodzina systemów plików znan z wczesnych
              wersji systemu MS Windows, obecnie wykorzystywana przez pamięci
              flash, jak pendrive oraz karty pamięci.</li>
          <li><strong>HFS+</strong> - system plików stosowany w starszych
              wersjach systemu Apple macOS. Zastąpiony prze APFS. Wykorzystanie
              partycji system HFS+, jest jedyną możliwością przenaszalności
              plików pomiędzy współczesnymi Macami a Linuksem.</li> 
        </ul>
        <h3 id="4.2.2.createfs">4.2.2. Tworzenie systemu plików</h3>
        <p>
          Tworząc partycje w poprzednim punkcie pozostało jeszcze sformatować
          pod konkretny system plików, aby można było przechowywać na nich
          informacje. System plików tworzony jest za pomocą polecenia
          <strong>mkfs</strong>. Polecenie ma inną nieco inna składnię,
          ponieważ żądany system plików podaje się po kropce w nazwie polecenia
          np. <strong>mkfs.ext4</strong>. Jako argument podajemy nazwę
          urządzenia partycji.
        </p>
<pre class="code-block">
$ sudo mkfs.ext4 /dev/sda1
</pre>
        <p>
          Podczas formatowania partycji program wyświetla komunikaty
          diagnostyczne. Wśród nich znajdują się liczby oddzielone do siebie
          przecinkami. Te liczby to kopie zapasowe <em>superbloku</em>.
          <strong>Superblok</strong> to najwyższy poziom bazy danych systemu
          plików, jest on na tyle ważny że program tworzy kilka jego kopii.
          Numery bloków zawierających kopie <em>superbloku</em> należy zachować
          ponieważ może być ona potrzebna do ewentualnego odzyskiwania danych.
        </p>
        <p>
          Przyglądając się samemu programowi <em>mkfs</em> dojedziemy do 
          wniosku, że jest to swojego rodzaju interfejs do całego zbioru 
          programów tworzących systemy plików. Nie które wystąpienia tego
          interfejsu są dowiązaniami sybolicznymi do innych programów.
          np <code class="code-inline">mkfs.ext4</code> wskazuje na 
          program <strong>mke2fs</strong>, będący głównym programem do służącym
          do tworzenia systemów plików z rodziny EXT, warto o tym pamiętać
          ponieważ możemy natknąć się na systemy bez polecenia <em>mkfs</em>.
        </p>
        <h3 id="4.2.3.mountfs">4.2.3. Montowanie systemów plików</h3>
        <p>
          Proces dołączania systemu plików w uniksach nazywany jest
          <strong>montowaniem</strong>. Aby zamontować w systemie jakiś system
          plików należy użyć polecenia <strong>mount</strong>, użyć tego
          polecnia bez żadnej opcji spowoduje wyświetlenie podmonotowanych
          systemów plików. Montowanie jak i późniejsze odmontowywanie wymagają
          uprawnień superużytkownika.
        </p>
        <p>
          Każdy wpis to jedno montowanie systemu plików, wpisy zwierają kolejno
          nazwę urządzenia, docelowe miejsce montowania, typ systemu
          oraz opcje specyficzne dla systemu.
        </p>
        <p> 
          Montowanie systemu plików odbywa się za pomocą tego samego polecenia,
          jednak wymaga podania kilku argumentów, kolejno: 
        </p>
        <ul>
          <li><strong>nazwy urządzenia</strong></li>
          <li><strong>typ systemu plików</strong></li>
          <li><strong>punktu montowania</strong> - katalogu docelowego dla
            montowanego systemu plików.</li>
          <li><strong>opcje specyficzne dla systemu plików</strong> - opcje
            są podawane jak wartość opcji <strong>-o</strong> polecenia. Nie
            zawsze trzeba podawać opcje systemu plików.</li>
        </ul>
        <p>
          Montując systemy takie jak EXT, czy któryś z FAT możemy pominąć 
          rodzaj podczas montowania, program sam to ustali. Jednak montowanie
          udziałów sieciowych <strong>CIFS</strong>, wymaga podania typu aby
          program <em>mount</em> mógł rozpoznać wartości zapisane w
          argumentach.
        </p>
        <p>
          Po skończeniu prac z system plików, możemy go odmontować za pomocą
          polecenia <strong>umount</strong>. Polecenie wymaga podania albo
          urządzenia albo punktu montowania jako argumentu.
        </p>
        <h3 id="4.2.4.uuid">4.2.4. Identyfikator UUID systemu plików</h3>
        <p>
          Montowanie systemu plików wymaga podania nazyw urządzenia. Pliki
          konfiguracyjne odpowiedzialne za automatyczne montowanie systemów
          plików w systemie podczas jego startu, nie mogą polegać na tych 
          samych nazwach urządzeń co użytkownicy, ponieważ są one ustalane
          pod czas startu systemu, i ich nazwy zależą od kolejności
          wykrycia ich przez jądro. W takich plikach używa się
          <strong>identyfikatorów UUID</strong> swoistych numerów seryjnych
          systemów plików nadawanych podczas formatowania. Listę urządzeń
          wraz z UUID-ami, możemy wywołać za pomocą polecenia:
        </p>
<pre class="code-block">
$ sudo blkid
</pre>
        <p>
          Identyfikatorów możemy używać nie tylko z plikami konfiguracyjnymi
          jak <em>/etc/fstab</em>, ale równie przy polecniu mount zamiast
          klasycznej nazwy urządzenia. Jednak posługiwanie się tak długim i
          skomplikowanym ciągiem znaków nie jest za wygodne.
        </p>
        <p>
          Polecenie <em>blkid</em> może zwracać w polu <em>UUID</em> numery
          identyfikacyjne innych systemów plików takich jak na przykład FAT,
          gdzie UUID-em jest numer seryjny woluminu FAT. Oczywiście takie
          identyfikatory możemy używać podczas konfiguracji pliku
          <em>/etc/fstab</em>.
        </p>
        <p>
          UUID musi być unikatowy, dlatego też jeśli zasła potrzeba skopiowania
          całego systemu plików, to należy zmienić ten identyfikator aby
          odróżnić kopię od oryginału.
        </p>
        <h3 id="4.2.5.diskcache">4.2.5. Buforowanie dysku i systemu plików</h3>
        <p>
          Uniksy w tym i Linux nie zapisują wszysktkich zmian w systemie
          plików po otrzymaniu takiego żądania. Zmiany przechowywane są w
          pamięci RAM od momentu kiedy jądro będzie mogło swobodnie zapisać
          je na dysku.
        </p>
        <p>
          W momencie odmontowywania systemu plików jądro automatycznie
          synchronizuje zawartość dysku. Jeśli z jakiego powodu nie będziemy
          mogli odmontować systemu plików to wówczas możemy wydać polecenie
          <strong>sync</strong>, które wymusza zapisanie na dysku wszyskich
          zmian w systemie plików. Oczywiście w wiekszej liczbie przypadku
          problemów z odmonotowaniem systemu plików jest proces używający
          któregoś z plików na dysku.
        </p>
        <p>
          Jądro dysponują całą serią mechanizmów wykorzystujących pamięć RAM
          do buforowania danych odczytywanych z dysków, przez co jeśli proces
          wielokrotnie będzie odczytywać dane z tego samego pliku, jądro nie
          będzie musiało odwoływać się do danych na dysku przez każde dane do
          procesu z bufora, oszczędzając tym samym czas i zasoby.
        </p>
        <h3 id="4.2.6.mountoptions">4.2.6. Opcje montowania</h3>
        <p>
          Polecenie <em>mount</em> posiada dużą ilość opcji. Jest ona tak duża
          że wprowadzenie opcji długich wynikało z obowiązku aniżeli wygody,
          ponieważ nazwyczajniej zaczynało tych liter w alfabecie brakować.
          Z posród opcji krótkich - jedno literowych możemy wyróżnić
          najważniejsze:
        </p>
        <ul>
          <li><strong>-r</strong> - powoduje zamontowanie systemu plików w
            trybie tylko do odczytu.</li>
          <li><strong>-n</strong> - powoduje nie modyfikowanie pliku
            <em>/etc/mtab</em> (plik zawiera zamontowane obecnie systemy plików,
            wydanie polecenia <em>mount</em> bez żadnych opcji powoduje
            wyświetlenie zawartości tego pliku). Opcja ta pozwala na 
            zamontowanie systemu plików w momencie gdy system plików zawierjący
            katalog główny, a co za tym idzie plik <em>/etc/mtab</em> jest
            zamknotowany w trybie tylko do odczytu, bowiem nie zapisanie zmian
            w tym pliku spowoduje niepowodzenie montowania.</li>
          <li><strong>-t</strong> - umożliwia podanie systemu plików.</li>
        </ul>
        <p>
          Opcje długie podawane wraz z opcjami specyficznymi dla systemu plików
          po opcji <em>-o</em>. Z opcji długich możemy wyróżnić takie jak:
        </p>
        <ul>
          <li><strong>exec, noexec</strong> - włącza i wyłącza możliwość
            uruchamiania programów w danym systemie plików.</li>
          <li><strong>suid, nosuid</strong> - włącza i wyłącza możliwość
            korzystania z bitu <em>suid</em> przez programy.</li>
          <li><strong>ro</strong> - montuje system plików w trybie tylko do
            odczytu.</li>
          <li><strong>rw</strong> - mountuje system plików w trybie pełnego
            dostępu.</li>
        </ul>
        <h3 id="4.2.7.remount">4.2.7. Pownowne montowanie systemu plików</h3>
        <p>
          W trakcie odzyskiwania danych może zajść potrzeba ponownego
          zamontowania systemu plików w celu zmiany opcji montowania.
          Najczęściej chodzi o przełączenie systemu plików zawierającego
          katalog główny z trybu tylko do odczytu w tryb pełnego dostępu.
          Ponownemu montowaniu służy opcja <strong>remount</strong>.
        </p>
        <h3 id="4.2.8.fstabfile">4.2.8. Tablica systemów plików /etc/fstab</h3>
        <p>
          Plik <strong>/etc/fstab</strong> przechowuje informacje o systemach
          plików oraz ich punktach montowania, dzięki czemu montuje te systemy
          podczas uruchamiania systemu. Każdy wiersz tego pliku przechowuje
          informacje o jednym systemie plików i jest podzielony na sześć pól.
        </p>
        <ul>
          <li><strong>Nazwa urządzenia lub UUID</strong> - dla dysków stosowane
            są identyfikatory UUID, jednak napęd optyczny w
            tym pliku, zapisywany jest nazwą urządzenia. Urządzeniem tylko do 
            odczytu napędu optycznego zazwyczja będzie <em>/dev/sr0</em>.</li>
          <li><strong>Punkt monotowania</strong> - katalog docelowy dla
            montowanego systemu plików.</li>
          <li><strong>Typ systemu plików</strong></li>
          <li><strong>Opcje</strong> - list długich opcji rodzielonych
            przecinkami.</li>
          <li><strong>Informacje o kopiach bezpieczeństwa dla programu 
              <em>dump</em></strong> - w tym polu zawsze należy podawać 0.</li>
          <li><strong>Kolejność sprawdzania spójność systemów plików</strong> -
              systemowi plików zawierającemu katalogów zawsze podajemy wartość
              1. Oznacza to sprawdzenie tego systemu w pierwszej kolejności.
              Pozostałym możemy podać wartość 2 lub 0, gdzie 2 oznacza 
              sprawdzenie tych systemów po systemie oznaczonym wartością 1.
              Każdy kolejny system przychowywujący jakieś dane oznacza się
              2. Po sprawdzeniu systemu z jedynką, program będzie sprawdzać
              po kolei systemy z dwójką. Natomiast 0 oznacza pominięcie 
              sprawdzania systemu przez program <em>fsck</em>.</li> 
        </ul>
        <p>
          Posiadając odpowiednie wpisy w plik <em>/etc/fstab</em>, możemy
          montować system plików podając poleceniu mount tylko punkty
          montowania co może być wygodne podczas montowania systemów plików
          dużą ilością opcji.
        </p>
        <p>
          Istnieje kilka opcji które mają zastosowanie tylko w omawianym przez
          nas pliku.
        </p>
        <ul>
          <li><strong>defaults</strong> - włącza domyślne ustawienie polecenia
            <em>mount</em> dając tym samym największe uprawenienia.</li>
          <li><strong>errors</strong> - ta opcja ma zastosowanie tylko dla
            systemów z rodziny EXT, pozwala na ustalenia zachowania systemu
            w momencie problemów z montowaniem systemu plików. Do wyboru mamy
            takie możliwości jak: <em>continue</em> - wygeneruj kod błędu i 
            kontynuuj pracę; <em>remount-ro</em> - zamontuj ponownie w trybie
            tylko do odczytu; <em>panic</em> - zatrzymaj system.</li>
          <li><strong>noauto</strong> - opcja nakazuje pominąć wpis podczas
            automatycznego montowania systemów plików.</li>
          <li><strong>user</strong> - pozwala na podmontowanie tego systemu
            za pomocą polecenia <em>mount</em> bez potrzeby uprawnień 
            superużytkownika - podmontować ten system plików może każdy
            użytkownik.</li>
        </ul>
        <h3 id="4.2.9.fscapacity">4.2.9 Pojemność systemu plików</h3>
        <p>
          Sprawdzenia zajętości systemu plików możemy dokonać za pomocą
          polecenia <strong>df</strong>. Polecenie to domyślnie zwraca
          wszelkie wartość w postaci kilobajtów, które nie są zbyt czytelne dla
          człowieka. Aby przeskalować jednostki możemy posłużyć się opcją
          <strong>-h</strong>. Polecenie wyświetla wynik swojego działania
          w postaci pięciu kolumn przedstawiających kolejno system plików,
          jego rozmiar, użyte miejsce, dostępne miejsce, stopień użycia w
          procentach oraz punkt montowania. W przypadku użycia programu bez
          podanej opcji rozmiar systemu nosi nazwę <em>1K-bl</em> jest to
          wielkość systemu plikach w jednokilobajtowych blokach.
        </p>
<pre class="code-block">
$ df -h
</pre>
        <p>
          Jeśli przjrzymy się na chwilę wynikom działania tego polecenia,
          możemy dość do wniosku, że albo mamy doczynienia z błędem albo
          tolerancja błędu przybliżenia jest bardzo. Otóż nie. Kilku gigabajtów
          brakuje ze względu na to, że zostały <strong>zarezerwowane</strong>
          i są do dyspozycji superużytkownika w momencie wyczerpania się
          miejsca na danym systemie plików, aby zapewnić systemówi dalsze
          funkcjonowanie oraz umożliwić administratorowi odzyskanie chociaż
          części miejsca na dysku.
        </p>
        <h3 id="4.2.10.fsrescue">4.2.10. Sprawdzanie i naprawnia systemu plików</h3>
        <p>
          Jądro do pracy systemu musi mieć pewność, że zamontowane systemy
          plików są pozbawione błędów. Błędy systemów plików mogą powodować
          utratę danych lub załamanie systemu. Najczęstszym powodem
          występowania błędów w systemie plików, są zaniki zasialania
          komputera spowodowane ludzką niewiedzą lub czynnikami środowiskowymi.
          Najnowszej generacji systemy plików wykorzystują pliki dziennika,
          dzięki, przerwanie działania systemu w wyniku różnych czynników
          nie doprowadza do katastrofy to są przypadki gdzie i one zawodzą.
        </p>
        <p>
          Narzędzie przeznaczone do sprawdzania oraz naprawy systemu plików 
          nazywa się <strong>fsck</strong>. <em>Fsck</em> podobobnie do
          <em>mkfs</em> uruchamia odpowiedni dla użytego na partycji systemu
          plików. Program w trybie interaktywnym uruchamiamy wydając polecenie
          <em>fsck</em> następnie podając nazwę urządzenia.
        </p>
<pre class="code-block">
$ fsck /dev/sdb1
</pre>
        <p>
          Nie wolno uruchamiać programu na zamontowanym systemie plików, gdyż
          grozi to utratą danych oraz załamaniem systemu. Inaczej sprawa ma się
          gdy system plików jest w trybie tylko do odczytu.
        </p>
        <p>
          W trybie interaktywnym program będzie zwracać raport z kolejnych
          etapów, jeśli napotka jakiś problem program zapytanie o usunięcie
          błędu. W wyniku błedów w systemie plików może zdarzyć się, że
          pewne pliki zostaną pozbawione nazwy (nazwy plików są w uniksach
          elementami systemu plików). Program kiedy napotka na taki to zostanie
          on przeniesiony do katalogu <strong>lost+found</strong> z nazwą 
          odpowiadającą numerowi identyfikacyjnemu z systemu plików (węzła
          <em>i-node</em>). Rzeczywistą nazwę musimy ustalić samodzielnie
          na podstawie analizy jego zawartości.
        </p>
        <p>
          Program <strong>e2fsck</strong> - właściwy program <em>fsck</em> dla
          rodziny systemów plików EXT, posiada opcję <strong>-p</strong>
          zajmującą się naprawą drobnych błędów. Program zatrzyma się wówczas
          tylko wtedy gdy napotka poważny błąd. Jeśli mamy podejrzenie, że coś
          się dzieje z system plików, to możemy sprawdzić system plików bez
          dokonywania w nim żadnych modyfikacji, korzystając z opcji
          <strong>-n</strong>. Co w przypadku uszkodzenia <em>superbloku</em>?
          Podstawową bazę danych możemy odbudować za pomocą opcji
          <strong>-b</strong> po opcji należy podać lokalizację kopii 
          superbloku (numer sektora podawany przez <em>mkfs</em> podczas
          tworzenia systemu plików). W przypadku gdy zapomnieliśmy spisać te
          numery, możemy spróbować je odzyskać wydając polecenie <em>mke2fs</em>
          wraz z opcją <strong>-n</strong> dla urządzenia. Należy upewnić się, 
          że na pewno użyliśmy tej opcji jej pominięcie sformatuje partycję. 
        </p>
        <p>
          Istnieją przypadki uszkodzeń, które wykraczają po za sferę programową
          program <em>fsck</em>, nie jednokrotnie pokazał mi, że by się
          wydawało katastrofę, naprawiał pojedyńczym domyślnym uruchomieniem.
          Jeśli nasze systemy dyskowe przechowują ważne informacje, to
          najlepszą ochroną jest <strong>kopia zapasowa</strong> warto je
          robić. Lepiej jest wymieć dysk, zainicjalizować dysk i przegrać dane
          niż liczyć na to, że może coś się uda odzyskać. Może się uda, jakieś
          szanse istnieją. Jeśli posiadamy kopię, to szanse przekraczają 90%
          reszta to ich aktualność.
        </p>
        <h3 id="4.2.11.specialfs">4.2.11. Systemy plików o specjalnym znaczeniu</h3>
        <p>
          Nie wszyskie systemy plików służą zapisywaniu informacji na
          fizycznych nośnikach, nie które z nich mogą służyć jako intefejsy
          systemowe lub przezentować informacje systemowe. Takimi systemami
          są:
        </p>
        <ul>
          <li><strong>proc</strong> - system montowany w katalogu <em>/proc</em>,
            Zawiera katalogi odpowiadające każdemu z procesów w systemie ich
            nazwy pochodzą od <em>PID</em>-u procesu. Pliki opisują różne
            aspekty procesów. Na Linuksach katalog ten przechowuje wiele
            dodatkowych informacji o jądrze systemu i sprzecie.</li>
          <li><strong>sysfs</strong> - system montowany w katalogu <em>/sys</em>.
            Omawiany był w poprzednim rozdziale.</li>
          <li><strong>tmpfs</strong> - montowany w katalogu <em>/run</em> oraz
            innych miejsach. Za pomocą tego systemu możemy przekształcić pamięć
            systemową w coś w rodzaju przestrzeni dyskowej, za pomocą dwóch
            paramerów (<em>size</em> oraz <em>nr_block</em>) możemy określić
            jego wielkość podczas montowania. Nie należy przesadzać z zapisem 
            danych do tego systemu, możemy doprowadzić do braku pamięci i 
            załamania systemu.</li>
        </ul>
        <h2 id="4.3.swapspace">4.3. Przestrzeń wymiany</h2>
        <p>
          Za pomocą przestrzeni na dysku jesteśmy wstanie powiększyć ilość
          użytkowej pamięci operacyjnej. System będzie automatycznie przenosić
          strony pamięci (obszary) na dysk i z dysku, wykorzystująca tzw.
          pamięć wirtualną. Operacja przenoszenia stron pamięci na dysk i
          z powrotem nosi nazwę <strong>wymiany</strong> 
          (ang. <em>swapping</em>), ponieważ polega na wymianie nieaktywnych
          stron w pamięci z aktywowany zanajdującymi się aktualnie na dysku.
          Przestrzeń, w której zapisywane są strony pamięci nazywa się
          przestrzenią wymiany.
        </p>
        <h3 id="4.3.1.swappartition">4.3.1. Wykorzystanie partycji jako 
          przestrzeni wymiany.</h3>
        <p>
          Wykorzystanie partycji jako przestrzeni wymiany jest standardową
          procedurą wykonywaną podczas instalacji systemu. Wiele dystrybucji
          zwraca uwagę na to, gdy brakuje <strong>partycji wymiany</strong>.
          Partycja wymiany może nie być nigdy wykorzystana, jednak chroni
          system przed załamianiem gdy zaczyna brakować pamięci RAM. 
        </p>
        <p>
          Podczas modyfikowania tablicy partycji, utworzyliśmy dysk logiczny,
          który posłuży jako przestrzeń wymiany. Przestrzeń wymiany należy
          sformatować, tak jak każdą partycje, jednak już nie za pomocą
          polecenia <em>mkfs</em>, ale <strong>mkswap</strong> podając 
          nazwę urządzenia jako parametr.
        </p>
<pre class="code-block">
$ sudo mkswap /dev/sda5
</pre>
        <p>
          Partycję wymiany możemy montować automatycznie w systemie za pomocą
          wpisu w pliku <em>/etc/fstab</em>. Poniżej znajduje się wpis, który
          można wykorzystać w instalacji. Zgaduje jednak, ża zainstalowana
          przez nas dystrybucja Linuksa do Mint, Ubuntu lub Kali więc raczej
          taki wpis znajduje się już tym pliku.
        </p>
<pre class="code-block">
UUID="..."  none  swap  sw  0 0
</pre>
        <p>
          Przestrzeń wymiany możemy włączać oraz wyłączać na żądanie za pomocą
          poleceń <strong>swapon</strong> oraz <strong>swapoff</strong> 
          podając urządzenie lub plik jako argument.
        </p>
        <h3 id="4.3.2.swapfile">4.3.2. Wykorzystanie pliku jako przestrzeni
          wymiany</h3>
        <p>
          Jeśli nie mamy dostępnego wolnego miejsca na dysku, możemy wówczas
          stworzyć plik, który będzie służyć nam za przestrzeń wymiany.
          Aktywujemy go, wówczas gdy ilość wolnej pamięci RAM, będzie
          niebezpieczenie niska. Aby utworzyć taki plik, musi on posiadać
          żądaną przez nas wielkość. Najprościej zapisać do niego określoną 
          liczbę zer z strumienia. 
        </p>
<pre class="code-block">
$ sudo dd if=/dev/zero bs=1M of=swap.img count=2048
</pre>
        <p>
          Polecenie to zapisze dwa gigabajty zer do pliku
          <code class="code-inline">swap.img</code>. Taki plik będziemy mogli 
          potraktować jak dysk lub partycję. Chciałbym tutaj również zaznaczyć,
          że w tym momencie spotykamy się w praktyce z jedną z fundamentalnych
          zasad Uniksów otóż <strong>"Wszystko jest plikiem"</strong>.
          Taki plik pozostaje jeszcze sformatować jako partycję wymiany.
        </p>
<pre class="code-block">
$ sudo mkswap swap.img
</pre>
        <p>
          Przygotowaną w ten sposób przestrzeń możemy uruchomić za
          pomocą polecenia <em>swapon</em>.
        </p>
        <h3 id="4.3.3.swapsize">4.3.3. Jak dużej przestrzeni wymiany potrzeuje?</h3>
        <p>
          Odpowiedź na to pytanie nie jest trudna do sformułowania. Otóż
          powszechnie przyjeło się, że przestrzeń wymiany powinna mieć wielkość
          dwukrotności zainstalowanej pamięci RAM. Biorąc pod uwagę to, że
          obecnie jesteśmy w posiadaniu dysków o bardzo dużej pojemności to
          jest to nawet śmieszna wartość, jednakże to przekonanie poważnie
          podważyło upowszechnienie się dysków SSD, które już dużych wartości
          nie muszą mieć. Weźmy sprzęt wbudowany (tzw. <em>embedded</em>) lub
          sprzęt mobilny, nie mówię tu o telefonach, ale np. chrombookach czy
          rozwiązaniach typu HP Stream. To tym przypadku przestrzeni dyskowej
          może być za mało jak na 8GB swapu. Weźmy również pod uwagę fakt iż
          prawdopodbnie nie skorzystamy z przestrzeni wymiany używając
          Linuksa na współczesnym sprzęcie. Więc wydaje mi się, że najbardziej
          optymalną wielkości swapu będzie <strong>1GB</strong>. Na poparcie 
          dodam że wiele
          instalatorów właśnie tyle alokuje podczas automatycznego 
          partycjonowania. 
        </p>
        <h2 id="4.4.fsfuture">4.4. Przyszłość systemów plików</h2>
        <p>
          Jedną z zauważalnych zmian w komputerach jest odejście powoli od
          dysków talerzowych na rzecz dysków SSD, więc możemy spodziewać się
          systemów domyślnie zoptymalizowanych pod kątem ich pełnego, 
          właściwego
          wykorzystania. Zauważymy lub już jesteśmy świadkami odchodzenia od
          rodziny systemu plików EXT, na rzecz takich systemów jak 
          <em>brtfs</em>, który obecnie jest domyślnym systemem dla takich
          dystrybucji jak Fedora. Alternatywą dla tego systemu będzie
          system plików <em>xfs</em>. Ich porównanie możemy znaleźć w
          internecie.
        </p>
        <h1 id="5.startingkernel">5. Uruchamianie jądra Linux</h1>
        <p>
          W tym rodziale rozpoczeniemy przyglądanie się procedurze uruchamiania
          systemu operacyjnego, z czego ten fragment materiału poświęcimy na
          procedurę uruchamiania jądra, programy rozruchowe oraz praktyczną
          konfigurację najpopularniejszego programu rozruchowego jakim nie
          wątpliwie jest GRUB.
        </p>
        <p>
          Procedura uruchamiania systemu wygląda w następujący sposób:
        </p>
        <ol>
          <li>System BIOS lub firmware (w przypadku UEFI) ładuje program
            rozruchowy z dysku i uruchamia go.</li>
          <li>Program rozruchowy szuka na dysku obrazu jądra, następnie ładuje
            go do pamięci i uruchamia.</li>
          <li>Jądro inicjuje wszystkie urządzenia wraz ze sterownikami</li>
          <li>Jądro montuje partycję z katalogiem głównym.</li>
          <li>Jądro uruchamia program o nazwie <em>init</em>, proces tego
            programu zawsze ma <em>PID</em> o wartości 1. Od momentu startu
            procesu typu init, rozpoczyna się uruchamianie przestrzeni
            użytkownika.</li>
          <li>Za pomocą programu <em>init</em> uruchamiane są pozostałe
            elementy systemu (różnego rodzaju usługi).</li>
          <li>Na koniec uruchamiany jest proces pozwalający się zalogować do
            systemu.</li>
        </ol>
        <p>
          W tym rozdziale skupimy się na punktach tej listy od 2 do 4.
          Pozostałe z nich, po za pierwszym (pierwszy wykracza po za ramy
          merytoryczne, tego materiału) omówimy w następnym rozdziale.
        <p>
        <p>
          Niestety możliwość identyfikowania poszczególnych etapów uruchamiania
          systemu jest osiągalna w zależności od dystrybucji. Te przeznaczone
          na desktopy, ukrywają wiele informacji na temat pierwszych etapów
          rozruchu systemu pod graficznymi ekranami, zawierającymi logo
          dystrybucji oraz pasek postępu. Jeśli spotkamy się z takim ekranem,
          to wówczas możemy naciśnać klawisz <em>ESC</em>, aby wyświetlić
          komunikaty wypisywane podczas uruchamiania systemu. Umiejętość
          identyfikacji poszczególnych etapów może pomoć w ewentualnych
          problemach podczas rozruchu.
        </p>
        <h2 id="5.1.dmesg">5.1. Komunikaty rozruchowe</h2>
        <p>
          Większość systemów uniksopodobnych generuje wiele komunikatów
          diagnostycznych. Część z nich pochodzi o samego jądra, pożniej
          pojawiają się komunikaty z poźniejszych etapów uruchamiania.
          Komunikaty te nie są zbyt przyjazne zwykłemu użytkownikowi, a
          dystrybuje dążą do tego aby być jak najbardzie przyjazne dla
          użytkownikowi nietechnicznemu, dlatego też ukrywają je za wyżej
          wspomnianymi ekranami, drugą ważną rzeczą jest ciągły rozwój
          jądra oraz sprzętu przez to systemy uruchamiają się tak szybko, że
          nawet mając te komunikaty przed oczami zdołalibyśmy za nimi
          nadąrzyć.
        </p>
        <p>
          Na szczęście są one zapisywane w plikach dziennika w katalogu
          <em>/var/log</em> oraz nie tylko, poniżej znajduje się lista miejsc,
          w których możemy szukać komunikatów rozruchowych.
        </p>
        <ul>
          <li>Pliki dziennika systemu, takie jak: <strong>/var/log/kern.log</strong>,
            oraz <strong>/var/log/messages</strong> rownież zawierają 
            komunikaty
            diagnostyczne jądra oraz nie których usług systemowych.</li>
          <li>Polecenie <strong>dmesg</strong> przyczym należy pamiętać, że
            trzeba przepuścić jego wyście przez polecenie
            <em>less</em>. Danych na pewno będzie więcej niż może pomieścić
            jeden ekran. Polecenie ty wykorzystuje <em>bufor cykliczny</em>
            jądra mający ograniczoną wielkość, jednak w nowoczesnych jądrach
            jest on na tyle duży, że może przechowywać komunikaty rozruchowe
            przez dłuższy czas.</li>
        </ul>
        <p>
          Nie wszystkie etapy są uwzględnione w wyżej wymienionych miejscach,
          część z nich może być wypisywana jedynie na konsole przez co przepada
          bezpowrotnie. Programy typu init nowszej generacji mogą
          przechwytywać te komunikaty a następnie zapisywać je za pomocą swoich
          rozwiązań protokołowania (prowadzenia plików dziennika).
        </p> 
        <h2 id="5.2.kernelinitandbootoptions">5.2. Inicjowanie jądra i opcje rozruchu</h2>
        <p>
          Podczas rozruchu systemu jądro uruchamiane jest następującej 
          kolejności.
        </p>
        <ul>
          <li>Sprawdzenie procesora</li>
          <li>Sprawdzenie pamięci</li>
          <li>Rozpoznawanie magistrali urządzeń</li>
          <li>Rozpoznawanie urządzeń</li>
          <li>Konfigurowanie uzupełniających podsystemów jądra (sieci itp.)</li>
          <li>Montowanie partycji z katalogiem głównym</li>
          <li>Uruchomienie przestrzeni użytkownika</li>
        </ul>
        <p>
          Jednym z etapów inicjacji jądra jest montowanie katalogu głównego.
          Generalnie to nic w tym nazwyczajnego oczywiście gdy potrzebne do 
          tego komponenty są wbudowane w jądro. Jeśli jednak te modułu
          są w postaci odrębnych modułów, może wówczas zajść potrzeba
          załadowania ich przed zamontowaniem głównego katalogu. Tym właśnie
          zajmuje się <strong>początkowych system plików w pamięci RAM - initramfs</strong>.
        </p>
        <p>
          Zakończenie inicjacji i przekazanie uruchamiania procesu <em>init</em>
          możemy zaobserować w komunikatach diagnstycznych szukając poniższej
          linii.
        </p>
<pre class="code-block">
Freeing unused kernel memory: ... freed
</pre>
        <p>
          W tym momencie jądro zwalnia zaalokowaną nie używaną pamięć.
        </p>
        <h2 id="5.3.kernelparameters">5.3. Parametry jądra</h2>
        <p>
          Parametry jądra pozwajają na określenie jego zachowania, na przykład
          ilość komunikatów diagnostycznych lub podają opcje właściwe dla
          sterowników urządzeń. Parametry jądra użyte przy jego uruchamianiu
          dostępne są pliku  <strong>/proc/cmdline</strong>.
        </p>
<pre class="code-block">
BOOT_IMAGE=/vmlinuz-4.19.0-19-amd64 root=UUID=59382884-accb-4106-9d25-44d1ba914530 ro quiet
</pre>
        <p>
          Na parametry mogą składać się pojedyńcze słowa jak np.
          <code class="code-inline">ro</code> czy <code class="code-inline">quiet</code>
          lub opcje w formacje <em>klucz=wartość</em>. Opcja <strong>root</strong>
          jest najważniejszą opcją, ponieważ bez niej jądro nie będzie mogło
          odnaleźć plików programu typu <em>init</em> i uruchomić go. W
          większości dystrybucji będzie UUID systemu plików zawierającego 
          katalog główny.
        </p>
        <p>
          Warto zwrócić uwagę również na opcję <code class="code-inline">ro</code>,
          która nakazuje jądru zamontować system plików w trybie tylko do
          odczytu. Ta czynność umożliwi bezpieczene sprawdzenie systemu plików
          przez program <em>fsck</em>.
        </p>
        <p>
          Jeśli jądro nie rozumie jakiegoś parametru to zostanie on 
          przezkazany do programu <em>init</em>. Przykładem jest wartość
          <em>-s</em>, który nakaże uruchomić przestrzeń użytkownika w trybie
          pojedyńczego użytkownika.
        </p>
        <h2 id="5.4.bootloaders">5.4. Programy rozruchowe</h2>
        <p>
          Zadaniem <strong>programu rozruchowego</strong> jest załadowanie
          jądra do pamięci i uruchomienie go z odpowiednimi parametrami. Dla 
          linuksa dostępnych jest
          wiele bootloaderów, poniżej znajduje się przedstawiająca je lista.
        </p>
        <ul>
          <li><strong>GRUB</strong> - standardowy program rozruchowy większości
            dystrybucji Linuksa.</li>
          <li><strong>LILO</strong> - jeden z pierwszych programów, obecnie
            został zastąpiony GRUB-em, jednak dalej są dystrybucje takie
            jak <strong>Slackware</strong> (trzecia najstarsza, funkcjonująca
            do tej pory dystrybucja), które go używają.</li>
          <li><strong>SYSLINUX</strong> - można go skonfigurować, tak aby
            współpracował z wieloma różnymi systemami. Można go spotkać w
            systemach wbudowanych, a jego pochodna ISOLINUX występuje na
            obrazach płyt.</li>
          <li><strong>coreboot</strong> - zamiennik systemu BIOS komputera,
            coreboot charkteryzuje się wysoką wydajnością. Stosowany jest
            w odblokowanych chromebookach.</li>
          <li><strong>Linux Kernel EFISTUB</strong> - moduł jądra pozwalający
            na załadowanie jądra bezpośrednio z partycji systemowej EFI/UEFI.</li>
        </ul>
        <p>
          Z racji tego iż, duża liczba dystrybucji, korzysta z GRUB. To jego
          omówimy sobie pod względem praktycznym. <em>Coreboot</em> stosuje
          się jako zamiennik BIOS-u. A SYSLINUX raczej ma zastosowanie
          specjalistyczne wykraczające po za ramy tego materiału.
        </p>
        <p>
          Aby program rozruchowy mógł załadować do pamięci jądro systemu, musi
          uzyskać dostęp do dysku. Nie posiadając żadnych sterowników
          program rozruchowy uzyskuje dostęp do dysku na poziomie BIOS-u, za
          pomocą adresowania <strong>Linear Block Addressing</strong> mimo
          bardzo niskiej wydajności zapewnia ono uniwersalny dostęp do dysku.
        </p>
        <h3 id=5.4.1.linuxandsecureboot">5.4.1. Linux i Secure Boot</h3>
        <p>
          Na nowych komputerach korzystających z UEFI, mogliśmy spotkać się
          przypadkiem, gdy komputer odmówił uruchomienia z płyty czy też z
          pamięci flash. Wiele z nich wyświetlało monit o tym, że włączona
          jest opcja <strong>bezpiecznego rozruchu</strong>. Opcja ta wymaga
          podpisu przez zaufaną organizację programu rozruchowego, aby mógł
          on być uruchomiony. Microsoft w ramach dystrybucji systemu Windows 8
          wymógł na producentach sprzętu domyślne włącznie tej opcji.
          Przyczyny nie są mi znane, chciaż podejrzewam chęć utrudnienia
          instalacji innego systemu nawet Windows 7. Oczywiście tę opcję możemy
          wyłączyć odszukując opcję w panelu sterowania fimwarem (w BIOSie). 
          Jeśli obawiamy się o nasze bezpieczeństwo, to wyłączenie tej opcji
          potrzebne jest wyłącznie na czas instalacji, ponieważ najnowsze
          wersje programów rozruchowych są już podpisane, więc będą zostaną
          zaaprobowane przez tę opcję. 
        </p>
        <h2 id="5.5.practicalusagegrub">5.5. Praktyczne użycie programu rozruchowego GRUB</h2>
        <p>
          GRUB jest obecnie najszerzej wykorzystywanym <em>bootloaderem</em>, 
          dlatego też
          warto poznać podstawy jego obsługi, bez owijania w bawełnę, bez
          wertowania kolejnych kart książek z teorią na temat tego programu
          rozruchowego. 
        </p>
        <h3 id="5.5.1.firstcontactwithgrub">5.5.1. Pierwszy kontakt z GRUBm</h3>
        <p>
          Po przejściu procedur testowych firmware naszego komputera bez
          znaczenia czy jest to BIOS czy UEFI, pokaże nam się tabela z której
          będziemy mogli wybrać jedną z opcji. Podobna do tej na poniższym
          rysunku.
        </p>
        <p>
          <img src="https://i.ibb.co/89wFqZ6/grub-boot-manager.png" alt="grub-boot-manager" border="0">
        </p>
        <p>
          Przedstawiona na rysunku tabela może różnić się wyglądem ale
          funkcjonalność pozostaje taka sama. Na samym dole jest napisane
          <code class="code-inline">Wyróżniony wpis zostanie wykonany
          automatycznie za 5s.</code>. Wyróżniony wpis to ten zaznaczony
          na biało, a po pięciu sekundach zostanie on uruchomiony, ładując
          system przy standardowych ustawieniach. Za pomocą strzałek możemy
          poruszać się pod tabeli dokonując wyboru interesującego nas wpisu.
          Wpis zawierający napis 
          <code class="code-inline">Opcje zaawansowane dla systemu...</code>
          jest podmenu zwierającym (najczęściej) wpisy ładujące system z
          poprzednimi wersjami jądra. Wpis w tabeli możemy edytować
          wybierając go strzałką następnie naciskając klawisz <em>e</em>. GRUB
          daje nam możliwość załadowani systemu z własnego wiersz poleceń. Ta
          opcja przeznaczona jest bardziej zaawansowanych czynności, takich
          jak na przykład diagnostyka konfiguracji GRUB-a. W tym materiale
          nie będziemy się jednak zajmować wierszem polecenia. Jeśli ruszymy 
          się chociaż w menu
          to odliczanie zostanie przerwane, więc aby załadować system trzeba
          wybrać wpis. Naciśnięcie jakiego kolwiek klawisza w menu spowoduje
          przerwanie odliczania. 
        </p>
        <h3 id="5.5.2.grubinstallationinbiosmode">5.5.2. Instalacja GRUB w trybie BIOS</h3>
        <p>
          Instalacja GRUB w tryb BIOS, jest banalnie prosta. Wystarczy użyć
          dwóch poleceń. Zazwyczaj korzystając z mainstreamowych dystrybucji
          przeznaczonych dla użytkowników desktopowowych, nigdy nie będziemy
          musieli tego robić, ponieważ zrobi to za nas instalator. Natomiast
          są dwa scenariusze, kiedy niezbędna będzie ponowna instalacja
          programu GRUB.
        </p>
        <ul>
          <li>Instalacja bardziej zaawansowanych dystrybucji takich jak Gentoo
            czy Arch Linux</li>
          <li>Przenoszenie systemu z jednego komputera na drugi za pomocą
            programów do obrazowania, jak Norton Ghost czy Paragon Backup.</li>
        </ul>
        <p>
          Pierwsze polecenie jest takie same dla każdej dystrybucji. Jako 
          argument podajemy dysk (urządzenie główne - np. sda, sdb itp.).
          Polecenie musi zapisać dane bezpośrednio na urządzeniu, więc
          niezbędne będą uprawnienia administratora.
        <p>
<pre class="code-block">
# grub-install /dev/sdX
</pre>
        <p>
          Drugie polecenie zależy już od dystrybucji. Możemy wówczas
          spotkać takie polecenie jak:
        </p>
<pre class="code-block">
Debian / Ubuntu i pochodne:
# update-grub
Arch Linux i pochodne:
# grub-mkconfig -o /boot/grub/grub.cfg
</pre>
        <p>
          Drugie polecenie jest odpowiedzialne za wygenerowanie pliku
          konfiguracyjnego. W przypadku GRUB jest to normalne, ponieważ
          ze względu na jego skomplikowanie przygotowanie plików składowych
          (będzie o tym później) spoczywa w rękach twórców samego GRUB-a lub
          twórców dystrybucji. Użytkownik końcowy otrzymuje gotowe polecenie,
          które stworzy taki plik konfiguracyjny za niego.
          Polecenie z Arch Linux, jest dłuższe ale pochodzi bezpośrednio z
          pakietu. Natomiast w przypadku Debiana i pochodnych mamy dostępne
          narzędzie przygotowane przez dystrybucję, jest ono bez obsługowe
          i uruchamia program do poszukiwania innych systemów operacyjnych na
          innych dyskach podłączonych do komputera. Na Debianie i pochodnych
          na pewno dostępne jest również to drugie polecenie, jednak lepiej
          skorzystać z polecenia dedykowanego dla naszej dystrybucji. Ponieważ
          to tak naprawdę jej twórcy zajmują się przygotowanie GRUB-a do użycia
          co nie jest takie proste.
        </p>
        <h3 id="5.5.3.grubinstallationinefimode">5.5.3. Instalacja GRUB w trybie UEFI</h3>
        <p>
          Instalacja w trybie UEFI również składa się dwóch poleceń jednak
          samo polecenie instalacyjne jest cieco dłuższe od tego z trybu BIOS.
          Wymaga ona również więcej zachodu niż w trybie BIOS oraz może
          zakończyć się niepowodzeniem. Tak się zdarza to, przy nie których
          specyficznych sprzętach.
        </p>
        <p>
          Polecenie instalacyjne wygląda w następująco:
        <p>
<pre class="code-block">
# grub-install --target=x86_64-efi --efi-directory=/efi --bootloader-id=debian
</pre>
        <p>
          Instalacja GRUB w trybie uefi wymaga, aby podać docelowy system,
          w tym przypadku jest <code class="code-inline">x86_64-efi</code>,
          w trybie BIOS, nie trzeba było podawać docelowego systemu gdyż
          w przypadku BIOS cel <em>i386-pc</em> jest celem domyślnym, kolejny
          argumentem jest podanie punktu montowania partycji <em>efi</em>.
          Taka partycja jest zazwyczaj montowana albo bezpośrednio w głównym
          katalogu - <em>/efi</em> lub wewnątrz katalogu <em>/boot</em> -
          <em>/boot/efi</em>. Ostatnim argumentem jest
          <code class="code-inline">--bootload-id</code> i tutaj panuje pewnego
          rodzaju niewiadoma. Bo jeśli korzystamy instalujemy program 
          rozruchowy
          pod Arch Linuxem, to <em>bootloader-id</em> to <strong>GRUB</strong>.
          z kolei pod Debianem musi być to <strong>debian</strong>. Te nazwy
          wynikają z faktu potrzeby podpisania programu rozruchowego aby
          mógł on być uruchamiany z włączoną opcją bezpiecznego rozruchu. Warto
          dodać, że to co podamy w tej opcji będzie wyświetlane w
          <em>boot menu</em> komputera. Jeśli chcemy użyć jakiejś
          niestandardowej nazwy i nie za bardzo przejmujemy się 
          <em>secure bootem</em>,
          to wówczas możemy użyć opcji <em>--no-uefi-secure-boot</em>.
        </p>
        <p>
          Do w pełni zainstalowanego GRUB-a potrzebujemy tylko pliku
          konfiguracyjnego. Do tego celu możemy wykorzystać polecenia podane
          w punkcie odnośnie instalacji GRUB w trybie BIOS.
        </p>
        <h3 id="5.5.4.changegruborder">5.5.4. Zmiana koleności w menu GRUB</h3>
        <p>
          Aby zamknąć już temat GRUB-a, przjedziemy do ostatniego zagadnienia.
          Rozważmy taki przypadek. Mamy jeden komputer w domu, z którego nie
          korzystamy tylko my. Mamy pozwolenie na wydzielenie pozostałej wolnej
          części dysku (w duży uproszczemiu) i obok Windows 10 chcemy
          zainstalować jakąś dystrybucje Linuksa. Załóżmy, że instalacja się
          powiodła. Niestety mamy problem, gdyż współużytkownicy komputera
          narzekają, że jak uruchamia się komputer to uruchamia się Linux a nie
          Windows. Uruchamiając komputer widzisz, że początkowym i domyślnym
          wyborem w menu GRUB-a jest Linux, a Windows z kolei znajduje się na
          samym końcu listy.
        </p>
        <p>
          Pierwsza myśl jest przychodzi nam do głowy to ręczna edycja pliku
          GRUB-a. Na pewno jest jakieś rozwiązanie. Zatem wyedytowaliśmy plik
          zapisaliśmy zmiany i póki co jest spokój. Wszyscy zadowoleni,
          korzystają z komputera. Któregoś dnia siedząc przy komputerze i
          korzystając z naszej dystrybucji, zostajemy poinformowani o tym, że
          są nowe aktualizacje. Instalujemy je zatem. Aktualizacje się 
          zainstalowały, zauważyliśmy że była również aktualizacja jądra.
          Dobra, wyłączamy komputer. Następnego dnia gdy nasz współużytkownik
          komputera chce skorzystać z niego, znów mu się uruchamia Linux a
          nie Windows. Jaki z tego morał? Instalacja nowego jądra wymaga 
          z aktualizowania pliku konfiguracjnego GRUB-a, aby można było
          korzystać ze świerzo zainstalowanego jądra automatycznie po ponownym
          uruchomieniu komputera, więc nie należy ręcznie zmieniać ręcznie
          pliku konfiguracjnego GRUB-a ponieważ aktualizacja czy to jądra
          czy samego programu rozruchowego nadpisze te zmiany.
        </p>
        <p>
          Sposobów wykonania tej czynności jest kilka, ja znam jedną. Jak wiemy
          plik konfiguracjny jest tworzony z plików składowych. Pliki te 
          znajdują się w katalogu <em>/etc/grub.d</em>, oto listing tych plików
          z mojego komputera:
        </p>
<pre class="code-block">
00_header
05_debian_theme
10_linux
20_linux_xen
30_os-prober
30_uefi-firmware
40_custom
41_custom
README
</pre>
        <p>
          Jeśli obserwowaliśmy generowanie pliku konfiguracjnego GRUB-a, to już
          powinniśmy znaleźć potrzebny nam plik. A jeśli nie to przyjrzyjmy się
          nazwom tych plików. Mamy
          <code class="code-inline">header, debian_theme, linux, linux-xen</code>
          i <code class="code-inline">os-prober</code>. <em>OS</em> to akronim
          od <em>Operating System</em>, z kolei <em>prober</em> oznacza to 
          samo co <em>der Untersucher</em> po niemiecku, czyli kontroler/badacz.
          Czyli chodzi o kontrolera systemów operacyjnych. Jeśli wpiszemy
          <em>os-p</em> w wierszu polecenia i naciśniemy tab, dowiemy się, że
          istnieje nawet takie polecenie, wyszukaniu strony podręcznika dla
          wiem że jest narzędzie odpowiedzialne za poszukiwanie innych systemów
          operacyjnych na wszystkich dyskach komputera. Więc znamy już część
          konfiguracji GRUB-a odpowiedzialną za Windows. Teraz jak zmienić
          kolejność? Otóż przed każdą z tych nazw stoi liczba, wystarczy
          zmienić nazwę, tak aby ten plik znajdował się przed plikiem
          <code class="code-inline">10_linux</code>. 
        </p>
<pre class="code-block">
$ sudo mv /etc/grub.d/30_os-prober /etc/grub.d/09_os-prober
</pre>
        <p>
          Teraz trzeba już tylko wygenerować nowy plik GRUB-a. Rozwiązanie
          powinno być odporne aktualizacje. Nie jest to może najpopularniejsze
          rozwiązanie, ale działa.
        </p>
        <h2 id="5.6.usagerefindasbootmanager">5.6. Wykorzystanie rEFInd jako menedżera rozruchu</h2>
        <p>
          Instalacja GRUB-a w trybie UEFI może się nie powieść, gdyż jednym z
          jego etapów jest zapisanie w pamięci firmware-u informacji o nowym
          programie rozruchowym o nazwie podanej podanej w parametrze
          <em>bootloader-id</em>. Z błedem jak ja się spotkałem by: 
        </p>
<pre class="code-block">
Could not prepare boot variable: No space left on device
</pre>
        <p>
          Nie które firmware mają ograniczoną ilość pamięci przechowywującej
          wskazania programów rozruchowych. Mimo usunięcia jednej ze zmiennych
          problem dalej występował. Usunięcie wszystkich spowodowało tak
          jakby uziemienie komputera, ponieważ nie był on wstanie uruchomić
          się z żadnego podpiętego dysku. Przełączenie trybu na BIOS, na tym
          sprzęcie nie było możliwe. Na sprzęcie tej samej klasy oraz tego
          samego producenta, ale nowszym spotkałem się z problemem z takim
          problemem, iż system zainstalował się poprawnie nawet GRUB w trybi
          UEFI, ale system nie był wstanie wystartować z wbudowanej pamięci,
          ani z system zainstalowanym w trybie UEFI ani w trybie BIOS.
        </p>
        <p>
          Rozwiązanie może i jest proste, niestety może nie za bardzo
          estetyczne oraz wymaga użycia dodatkowego pendrive-a. Pamięć USB nie
          musi być duża, wystarczy 1GB. Polega ono na użyciu odrębnego
          mendżera rozruchu jakim jest <strong>rEFInd</strong>. Program ten
          przeszukuje dyski w poszukiwaniu systemów operacyjnych i
          uruchamia je.
        </p>
        <p>
          Sama dystrybucja przy wykorzystaniu programu <em>rEFInd</em> może
          być zainstalowana trybie BIOS.
          W środowisku LiveCD instalujemy pakiet <strong>refind</strong>. 
          Podczas instalacji zostanie nam wyświetlony monit z pytaniem czy
          zainstalować <em>rEFInd</em> na partycji ESP. Wybieramy opcję
          <strong>No</strong>.
        </p>
<pre class="code-block">
# apt update
# apt install refind
</pre>
        <p>
          Po zainstalowaniu, tworzymy na dysku USB 1 jedną partycję pod system
          plików FAT32, następnie należy ją sformatować.
        </p> 
<pre class="code-block">
# dd if=/dev/zero bs=1M of=/dev/sdX count=1
# echo ',,b,' | sfdisk /dev/sdX
# mkfs.vfat -F32 /dev/sdXY
</pre>
        <p>
          W powyższym przykładzie <code class="code-inline">X</code> to litera
          porządkowa dysku, z kolei <code class="code-inline">Y</code> to 
          liczba partycji. Partycji nie musimy montować. Poniższe polecenie
          zainstaluje na przygotowanym dysku program <em>rEFInd</em>. 
        </p>
<pre class="code-block">
# refind-install --usedefault /dev/sdXY --alldrivers
</pre>
        <p>
          Po zainstalowaniu programu, możemy zrestartować komputer a następnie
          w ustawienia UEFI, ustawić kolejkę rozruchu tak, aby komputer
          startował z pendrive-a, na którym zainstalowaliśmy <em>rEFInd</em>.
          W menu powinien pojawić się wpis z Linuksem zainstalowanym naszym
          dysku. 
        </p>
        <h1 id="6.startinguserspace">6. Uruchamianie przestrzeni użytkownika</h1>
        <p>
          Istotnym momentem podczas startu systemu operacjnego jest
          uruchomienie przez jądro procesu <em>init</em> oznacza to, że pamięć
          oraz procesor są gotowe normalnej pracy. Po za tym uruchomie tego
          programu może przynieść również korzyść dydaktyczną, pozwalając
          obserwować montowanie różnych komponentów w gotowy do pracy system.
          Budowa programów typu <em>init</em> jest bardzie modułowa, więc jeśli
          chcielibyśmy zmienić coś w tym procesie (uruchamiania przestrzeni
          użytkownika) nie potrzebujemy umiejętności niskopoziomowego
          programowania oraz trzymania się ściśle określonej ścieżki, jak ma to
          miejsce w przypadku jądra. Uruchamianie przestrzeni użytkownika 
          zostało przedstawione na poniższej liście kroków: 
        </p>
        <ol>
          <li>Jądro uruchamia program typu <em>init</em>.</li>
          <li>Uruchamiane są usługi niskiego poziomu takie jak <em>udevd</em> 
              czy <em>syslogd</em>.</li>
          <li>Sieć zostaje skonfigurowana.</li>
          <li>Uruchamiane zostają pozostałe usługi jak (<em>cron</em>, 
              <em>cups</em>, itp.)</li>
          <li>Startują aplikacje wyskokiego poziomu, ekrany logowania oraz
              środowiska graficzne.</li>
        </ol>
        <h2 id="6.1.initprocess">6.1. Proces init</h2>
        <p>
          Głównym zadaniem procesu typu <strong>init</strong> jest uruchamianie,
          zatrzymywanie i ponowne uruchamianie procesów istotnych dla pracy 
          całego systemu, chciaż jego najnowsze implementacje mają o wiele
          więcej zadań, to jest to program jak każdy inny. Możemy go znaleźć
          w katalogu /sbin. W dystrybucja Linuksa ma zastosowanie kilka różnych
          implementacji procesu <em>init</em>. Na poniższej liście znajdują się
          te wciąż używane.
        </p>
        <ul> 
          <li><strong>System V init</strong> - tradycyjna wersja tego procesu
            obecnie została wyparta z użycia w dystrybucjach głównego nurtu, co
            przez nie których uznane za zły zabieg. Dalej rozwiajane są
            dystrybucje, które są forkami tych głównych, ale opierają się, nie
            tylko o <em>sysvinit</em> ale dają możliwość wyboru innego procesu
            typu <em>init</em> niż <em>systemd</em>.</li>
          <li><strong>systemd</strong> - najnowsza implementacja tego procesu,
            wykorzystywana w głównych dystrybucjach.</li>
          <li><strong>runit</strong> - alternatywa dla <em>systemd</em>, ma
            zastoswanie nie tylko dla dystrybucji Linuksa ale innych systemów
            zgodnych ze standardem POSIX. Jego działanie opiera się o 3 etapy.
            Wykorzystywany jest w dystrybucjach, takich jak AntiX oraz Void
            Linux.</li>
          <li><strong>OpenRC</strong> - alternatywa dla <em>systemd</em>,
            stosowana przez takie dystrybucje jak Gentoo oraz Alpine Linux. 
            Ma on podobne możliwości do <em>systemd</em>.</li>
        </ul>
        <h2 id="6.2.runlevels">6.2. Poziomy uruchomienia</h2>
        <p>
          <strong>Poziomem uruchomienia</strong> nazywamy stan maszyny, w
          którym na dany moment uruchomione są wybrane komponenty. Są one
          oznaczne liczbą od 0 do 6. Podczas pracy systemu, większość czasu
          spędzamy na tylko na jednym poziomie uruchomienia, z momencie 
          zamykania systemu lub uruchamiania go ponownie przełączamy się na
          inny poziom odpowiedzialny za zatrzymanie pracy jądra oraz poprawne
          zakończenie pracy usług. Na poziomach uruchomienia bazuje tradycjny 
          <em>sysvinit</em>.
        </p>
        <p>
          Za pomocą poniższego polecenia możemy, sprawdzić na jakim poziomie
          uruchomienia się znajdujemy:
        </p>
<pre class="code-block">
$ who -r
</pre>
        <p>
          Polecenie zwraca również moment załączenia wyświetlanego poziomu.
        </p>
        <p>
          Poziomy uruchomienia służą okreslaniu stanu systemu operacyjnego.
          Może on być stanie uruchamiania, zamykania, trybie konsoli
          (serwery, instalacje bez środowiska graficznego), trybie awaryjny
          (tryb pojedyńczego użytkownika, będzie o tym pod koniec rozdziału).
          5 poziom uruchomienia oznacza najczęściej w pełnii uruchomiony system
          wraz z trybem graficznym.
        </p>
        <p>
          Dzisiaj poziomy uruchomienia są domeną programu <em>sysvinit</em>.
          Dystrybucje z <em>systemd</em> wykorzystują je, aby zapewnić
          obsługę z usług, które nadal korzystają ze skryptów <em>sysvinit</em>.
        </p>
        <h2 id="6.3.initidentify">6.3. Rozpoznawanie programu typu init.</h2>
        <p>
          Identyfikacja programu typu init polega, na przeczytaniu
          oprogramowania oferowanego przez dystrybucje. Jeśli program typu
          <em>init</em> nie jest wyszczególniony, możemy przyjąć ze jest to
          <em>systemd</em>. Wiele dystrybucji posiada w swoich cechach 
          wymienioną informacje o tym że używa innego programu typu 
          <em>init</em> niż <em>systemd</em>.
        </p>
        <h2 id="6.4.introductiontochoosedinitprograms">6.4. Wprowadzenie do wybranych programów typu init</h2>
        <p>
          Ze względu na fakt, jak ograniczonych ram tego materiału. Nie będę
          szczegółowo zagłebiał się w tematykę omawianych tutaj programów typu
          <em>init</em>. Opisze ich zalety, na czym opiera się ich
          działanie, jakich plików używają oraz co najważniejsze dla nas na
          tym etapie w jaki sposób możemy zarządzać usługami przy użyciu tych
          programów. Pierwszym jaki procesem typu <em>init</em> jaki poruszę
          z racji popularności jest <em>systemd</em>. 
        </p>
        <h3 id="6.4.1.systemd">6.4.1. Systemd</h3>
        <p>
          <strong>Systemd</strong> wykonując swoje zadania osiąga
          <strong>cel</strong>. Cel jest defiowany przez nas wraz z wszystkimi
          zależnościami (wymaganiami) oraz z góry ustalonym momentem
          realizacji tego celu. Następnie system rozwiązuje wszystkie
          zależności oraz wykonuje postawione przed nim zadanie. Wynika z tego
          jedna z jego cech, możemy opoźnić np. start usługi do momentu gdy
          będzie ona niezbędna. 
        </p>
        <p>
          Poza obsługą usług, której wszyscy oczekują od programu <em>init</em>,
          <em>systemd</em> stara się z integrować ze sobą wiele klasycznych
          usług takich jak <em>cron</em> czy <em>inetd</em>.
        </p>
        <p>
          Podczas uruchamiania usług <em>systemd</em> nie kieruje się żadną
          kolejnością, co więcej większość jego konfiguracji stara unikać
          jakiej kolwiek sekwencyjności, nawet pod czas spełniania zależności. 
          Takie działanie pozwala na zachowanie
          dużej dozy elastyczności w procesie uruchamiania systemu.
        </p>
        <p>
          W zanadrzu swoich możliwości <em>systemd</em> może: montować systemy
          plików, monitorować gniazda sieciowe czy uruchamiać zegary. Takie
          rodzaju funkcje w tej impementacji programu typu <em>init</em>
          nazywane są <strong>jednostkami</strong> (ang. <em>units</em>). A
          operacja uruchomienia takiej jednostki nazywana jest
          <strong>aktywowanie</strong>. Typ jednostek <em>systemd</em> dostępne
          są na stronie podręcznika: <em>systemd(1)</em> (1 w nawiasie to numer
          rozdziału).
        </p>
        <p>
          Każda jednostka może mieć zależności wobec innej jednostki. Może
          wymagać lub chcieć jej działania na potrzeby zadania, które sama
          realizuje. Zależności są definiowane w plikach jednostek dostępnych
          w dwóch miejscach, w konfiguracji globalnej skierowanej do całego
          systemu - <strong>/usr/lib/systemd/system</strong> oraz w definicjach
          lokalnych - <strong>/etc/systemd/system</strong>. Jeśli będziemy
          musieli wprowadzić jakieś zmiany w konfiguracji to zalecanym miejscem
          jest katalog definicji lokalnych. Rozwiązywanie zależności 
          najczęściej polega na uruchomieniu samej jednostki, wobec której
          ważna dla nas jednostka jest zależna. Liczy się czy natomiast czy
          daną jednostkę udało się aktywować lub czy jednostka jest już
          uruchomiona w trakcie uruchamiania naszej jednostki, tego typu
          uwarunkowania definiowane przez typy zależności. Poza zależnościami
          wobec innych jednostek, mogą występować również zależności bazujące
          na stanie (istnieje, nie istnieje, jest niepusty) elementów takich
          jak ścieżka, katalog czy plik.
        </p>
        <p>
          Uruchomienie jednostki nazywane jest aktywowaniem. Dlaczego nie
          włączeniem? Otóż, aby uruchomić należy ją aktywować poniższym
          poleceniem:
        </p>
<pre class="code-block">
$ sudo systemctl start unit.service
</pre>
        <p>
          To czy każdą jednostkę możemy tak sobie uruchomić zależy od jej
          zależności. Zależności można definiować na odwrót, użwając sekcji
          <em>[Install]</em>, a wewnątrz niej typów zależności:
          <strong>RequiredBy</strong> oraz <strong>WantedBy</strong>,
          najczęściej wykorzystywana jest ta druga opcja. Za pomocą tej sekcji
          oraz wymienionych zależności, jednostki instalowane są w celach.
          Większość usług wykorzystywanych w linuksach, posiadają zależność
          <em>WantedBy</em> ustawioną na cel <em>multi-user.target</em>. Jest
          to spowodowane tym, że samo istnienie pliku jednostki może powodować
          jej aktywacje, co w przypadku usług sieciowych nie jest porządane.
          Zatem włączenie jednostki, jest w przypadku <em>systemd</em>
          równoznaczne z włączeniem jej do zależności jednostki zapisanej w
          zależności odwrotnej (cele w <em>systemd</em>, też są jednostkami ale 
          ich rola raczej ogranicza się do grupowanie różnego rodzaju innych
          jednostek). Wydaje mi się, że wszystko rozjaśni się gdy zobaczymy
          polecenie służące do włączania.
        </p>
<pre class="code-block">
$ sudo systemctl enable unit.service
</pre>
        <p>
          Dezaktywacja oraz wyłaczenie jednostki to kolejno:
        </p>
<pre class="code-block">
#Dezaktywacja:
$ sudo systemctl stop unit.service

#Wyłączenie:
$ sudo systemctl disable unit.service
</pre>
        <p>
          Do obsługi <em>systemd</em> używamy pojedyńczego polecenia
          <code class="code-inline">systemctl</code>, ma ono bardzo wiele opcji
          jednak na poziomie podstawowym wystarczym to co napisałem powyżej
          oraz sprawdzenie stanu jednostki poleceniem:
        </p>
<pre class="code-block">
$ sudo systemctl status unit.service
</pre>
        <p>
          Dawniej w czasch powszechnego panowania <em>sysvinit</em> oraz
          obecnie w dystrybucja wykorzystujących ten rodzaj programu
          typu <em>init</em>, gdy usługa definiowała zasób, z którego
          korzystały inne usługi, to musiały one zostać opóźnione do momentu
          uruchomienia usługi macierzytej oraz udostępnienia przez nią
          zasobu. Za pomocą <em>systemd</em> możemy na podstawie dokumentacji
          usługi utworzyć jednostkę zasobu. Taka jednostka zostanie uruchomiona
          w momencie aktywowania jednostki macierzystej usługi. Dzięki temu
          inne usługi korzystające z tego zasobu będą mogły zostać aktywowane
          w tym samym czasie co ta usługa. Usługi nie zrócą żadnego błędu,
          ponieważ zasób jest dostępny. W gdy coś spróbuje uzyskać dostęp do
          tego zasobu, to zostanie zablokowane przez <em>systemd</em> do
          momentu pełnego uruchomienia usługi i przekazania jej kontroli nad
          zasobem. Jeśli podczas próby dostępu do zasobu napłyną jakieś dane
          to zostaną one zbuforowane i przekazne do usługi, gdy przejmie ona
          pieczę na zasobem. Cała ta procedura pozwala na znaczne
          przyspieszenie uruchamiania systemu.
        </p>
        <p>
          <em>Systemd</em> zapewnia pewien stopień zgodności z tradycyjnym
          <em>sysvinit</em>, dla usług nie wspierających plików jednostek.
          Ta funkcjonalność jest na tyle rozwinięta, że pozwala na podobne
          zarządzanie taką usługą, jakoby miała ona plik jednostki.
        </p>
        <p>
          Implementacja procesu typu <em>init</em> jaką jest <em>systemd</em>
          jest na prawdę dość sporym tematem. Więc zostanie on poruszony
          ponownie na tej stronie.
        </p>
        <h3 id="6.4.2.sysvinit">6.4.2. Proces typu init w stylu System V</h3>
        <p>
          Klasyczny proces typu <em>init</em> jakim jest 
          <strong>sysvinit</strong>, opiera się o poziomy uruchomienia oraz
          wykonywane w nich polecenia. Polecenia te opierają się na
          sekwencyjny wykonywaniu skryptów umieszczanych w odpowiednich
          katalogach. Najważniejszym plikem jest w tym przypadku plik
          <em>/etc/inittab</em>, w jego zawrtości znajdują się wspomniane już
          polecenia, rozpisane dla poszczególnych poziomów uruchomienia.
          Polecenie dla 5 poziomu uruchomienia może wyglądać w następujący
          sposób:
        </p>
<pre class="code-block">
l5:5:wait:/etc/rc.d/rc 5
</pre>
        <p>
          To polecenie przy wejściu na 5 poziom uruchomi wszystkie skrypty w
          katologu <em>/etc/rc5.d</em>, o ile będą miały odpowiednią nazwę.
          Słowo <code class="code-inline">wait</code> spowoduje, że proces
          <em>init</em> nie przejdzie na kolejny poziom uruchomieniowy do
          momentu zakończenia pracy tego polecenia. Inne <strong>akcje</strong>
          niż <code class="code-inline">wait</code> mogą
          uruchamiać ponownie polecenie po jego zakończeniu czy definiować
          co należy zrobić po naciśnięciu kombinacji klawiszy
          <em>Ctrl+Alt+Delete</em>, z kolei akcja <strong>initdefault</strong>
          określa domyślny poziom uruchomieniowy dla przestrzeniu użytkownika.
        </p>
        <p>
          Skrypt zawarte w katalogu <em>rc5.d</em>, który jest akronimem od
          polecenia <em>run command</em>. Posiadają dość specyficzne nazwy,
          zaczynają się one od wielkiej litery <em>S</em> lub <em>K</em>.
          Następny jest numer, na końcu zaś znajduje się nazwa własna. Jeśli
          wylistujemy ten katalog bardziej szczegółowo, to zauważymy, że te
          skrypty to tak naprawdę dowiązania symboliczne. Wiele dowiązań w
          jednym katalogu nazywane jest <strong>farmą dowiązań</strong>.
          Te dowiązania zawarte w katalogach <em>rc</em> wskazują 
          na właściwe
          skrypty znajdujące się w katalogu <em>/etc/init.d</em>.
        </p>
        <p>
          Wielkie litery na początku nazw dowiązań oznaczają operację
          podejmowaną na usłudze czy ma ona zostać uruchomiony - <em>S</em>
          (ang. <em>start</em>), czy jej działanie ma zostać zakończone
          - <em>K</em> (ang. <em>kill</em>). Te czynności wykonywane są
          poprzez uruchomienie skryptu z argumentem <em>start</em> lub 
          <em>stop</em>.  Numery w nazwach
          określają miejsce tej czynności w sekwencji uruchomieniowej
          <em>sysvinit</em>. Usługi niskiego poziomu jak np. <em>syslogd</em>
          uruchamiane są bardzo wcześnie (mają niskie numery), demony
          świadczące użytkownikom jakieś usługi zazwyczaj mają numery powyżej
          90. Nazwa wskazuje na uruchamianego daemona.
        </p>
        <p>
          Zatem jeśli nie chcemy, aby jakaś usługa startowała należy wówczas
          zmienić nazwę dowiązania. Warto jednak pozostawić sobie późniejszą
          możliwość jej włączenia. Powiedzmy że chcemy wyłączyć daemona
          <em>httpd</em> jego nazwa to <em>S99httpd</em>, więc najlepiej
          postawić na początku nazwy znak podkreślenia:
        </p>
<pre class="code-block">
$ mv /etc/rc5.d/S99httpd /etc/rc5.d/_S99httpd
</pre>
        <p>
          W ten sposób daemon zostanie wyłączony z sekwencji uruchomieniowej.
          Jeśli chcemy uruchomić/zatrzymać usługę na żądanie, należy 
          uruchomić
          skrypt z katalogu <em>/etc/init.d</em> z argumentem <em>start</em>
          lub <em>stop</em>.
        </p>
<pre class="code-block">
#Uruchomienie:
$ sudo /etc/init.d/httpd start

#Zatrzymanie:
$ sudo /etc/init.d/httpd 
</pre>
        <p>
          Wraz z <em>sysvinit</em> i nie tylko, rozprowadzane jest narzędzie, 
          które działa w systemach nie używających już <em>sysvinit</em>.
          <strong>Run-parts</strong>, jest to bardzo proste na rzędzie, które
          uruchamia wszystkie pliki wykonywalne w danym katalogu 
          według ściśle określonego porządku.
          Implementacja tego narzędzia zależy od dystrybucji. Te bardziej
          złożone pozwalają na użycie wyrażenia regularnego do określenia
          porządku ich uruchamiania. Na potrzeby tego materiału wystarczy
          wiedzieć, że takie narzędzie w ogóle istnieje.
        </p>
        <p>
          Wspomnieniem o <em>run-parts</em> kończymy wprowadzenie do programów
          typu <em>init</em>. Omówiłem tylko te dwa, gdyż są w
          najpowszechniejszym użyciu. Poznając podstawy Linuksa, nie ma co
          zniechęcać się obszernymi szczegółami. Najważniejsze dla nas na ten
          moment jest uruchamienia/zatrzymywanie usług oraz włączanie i
          wyłączanie ich z sekwencji uruchomieniowej. W ramach ćwiczeń możemy
          wydedukować jak należy włączyć usługę, do sekwencji uruchomieniowej
          przy procesie <em>init</em> w stylu <em>System V</em>, chociaż nie
          powinno to zająć więcej niż 30 sekund.
        </p>
        <h2 id="6.5.shutdownthesystem">6.5. Wyłączanie systemu</h2>
        <p>
          Jedynym prawidłowym sposobem na wyłącznie systemu, jest użycie
          polecenia <strong>shutdown</strong>. Wyłączyć system możemy na
          dwa różne sposoby. Pierwszym z nich jest jego 
          <strong>programowe zamknięcie systemu oraz wyłącznie zasilania</strong>
          osiągane przez poniższe polecenie. 
        </p>
<pre class="code-block">
$ sudo shutdown -h now
</pre>
        <p>
          Do wyżej wymienionego celu możemy, użyć polecenia, które może być
          nieco bardziej powszechne:
        </p>
<pre class="code-block">
$ sudo poweroff
</pre>
        <p>
          Ma ono działanie identyczne działanie jak polecenie z przykładu
          powyżej. 
        </p>
        <p>
          Przy poleceniu <code class="code-inline">shutdown</code> należy
          wybrać czy system ma zostać zamknięty, zatrzymany, lub uruchomiony
          ponownie. Kolejnym wymaganym argumentem jest czas. Najczęściej
          używany jest argument <code class="code-inline">now</code> co
          przy przyjmowanym zapisze czasonym jest <em>+0</em> minut.
          Zapis czasowy możemy określić w minutach jak podałem powyżej lub
          lub przy zapisie <em>hh:mm</em> , który pozwala określić konkretną
          godzinę zamknięcia systemu.
        </p>
        <p>
          Innym sposobem na zamknięcie systemu jest ponowne uruchomienie
          komputera. System będzie musiał zostać poprawnie zamknięty, aby
          uruchomić komputer ponownie. W tym celu możemy użyć polecenia, 
        </p>
<pre class="code-block">
$ sudo shutdown -r now

#lub

$ sudo reboot
</pre>
        <p>
          Wyłączenie systemu dla <em>systemd</em> oznacza aktywację jednostek
          zatrzymywania (<em>systemd</em>, posiada wiele typów jednostek), dla
          <em>sysvinit</em> przejście z poziomu 5 na 6 lub 0.
        </p>
        <h2 id="6.6.initramfs">6.6. Początkowy system plików w pamięci RAM</h2>
        <p>
          <strong>initramfs</strong> czy <strong>initrd</strong>, z tych nazw
          korzysta się zamiennie mimo iż oznaczają coś innego, to odnoszą się
          do tego samego komponentu, czyli <strong>początkowego systemu plików
          w pamięci RAM</strong>. Jest to bardzo proste archiwum
          przechowujące mini przestrzeń użytkownika z mini katalogiem głównym.
          Zadaniem <em>initramfs</em> jest stworzenie optymalnego środowiska
          dla narzędzi pozwalających na załadowanie do jądra zewnętrznych
          modułów, wśród których może znajdować się sterownik dysku, co pozwoli
          zamontować już właściwyw katalog główny z dysku i przejść na kolejne
          etapy uruchamiania systemu. 
        </p>
        <p>
          Wykorzystując nasz system w stopniu podstawowym raczej nie będziemy
          mieć styczności z <em>initramfs</em>, chyba że używamy bardziej
          zaawansowanej dystrybucji, która może wymagać załadowania do niego
          dodatkowych modułów. Takie przypadki będą zazwyczaj opisane w na
          stronach dokumentacji dystrybucji. Przykładem takiego działania może 
          być
          szyfrowana partycja z katalogiem głównym, w takich dystrybucjach
          jak Arch Linux. Do obsługi początkowego systemu w pamięci RAM
          służa takie polecenia jak <strong>mkinitramfs</strong> lub
          <strong>update-initramfs</strong>. 
        </p>
        <p>
          System plików pamięci RAM może zostać pominięty w momencie gdy, w
          jądrze znajdują się wszystkie potrzebne mu sterowniki, jednak
          obecnie nie jest to praktykowane.
        </p>
        <p>
          Istnieją dystrybucje, których działanie opiera się na 
          <em>initramfs</em>, pliki dystrybucji znajdują się w tym archiwum, a
          oprogramowanie jest znajduje się wówczas w archiwach <em>squashfs</em>
          montowanych podczas w odpowiednich miejscach w systemie podczas
          jego ładowania. Taką dystrybucją jest na przykład TinyCore, którego
          obraz płyty waży 21 MB.
        </p>
        <h2 id="6.7.oneusermode">6.7. Tryb jednego użytkownika</h2>
        <p>
          Tryb pojedyńczego użytkownika, jest swojego rodzaju trybem
          awaryjnym na Linuksie, a jedynym dostępnym użytkownikiem będzie 
          superużytkownik. W tym trybie zostanie załadowane jądro, za
          montowany katalog główny, a proces typu init zapewni dostęp tylko
          do niezbędnych dla działania systemu usług, wyeliminowywując tym 
          samym potencjalnie wadliwe komponenty. To środowisko ma za zadanie
          umożliwić nam naprawę systemu. 
        </p>
        <p>
          Ze względu na to, iż to środowisko może nie zapewnić potrzebnych
          do takiej naprawy narzędzi, najlepiej jest skorzystać jednak z 
          obrazu <strong>LiveCD</strong>, który pozwala na korzystanie z
          systemu bez konieczności jego instalacji. Jednak na podstawie wiedzy
          zawartej w tym materiale nie sądze, aby można byłoby naprawić system.
          Dlatego też jeśli zdarzy się awaria systemu, to najlepszym
          rozwiązaniem na teraz jest zabezpieczenie osobistych danych i
          przeinstalowanie systemu, chodziaż nie chce nikogo zniechęcić do
          grzebania w systemie, w ten sposób możemy się wiele nauczyć. Z 
          drugiej strony, ciężko jest aby system przestał działać tak sam z
          siebie. Dlatego jesli tak się stało, więcej niż raz to warto zgłość
          problem społeczności za pomocą jednego z kanałów
          udostepnionych na stronie dystrybucji i zmienić dystrybucje na jakiś
          czas. Linux to głównie narzędzie do pracy na naszym komputerze, na
          tym etapie - podstawowym.
        </p>
        <h1 id="7.systemconfigurationandusers">7. Konfiguracje systemowe oraz użytkownicy</h1>
        <p>
          W tym rozdziale zajmiemy się drobnymi konfigracjami, nie których
          komponentów systemowych takich jak <em>syslog</em> czy <em>cron</em>
          zajmiemy się również tematem czasu systemowego na Linuksie. Rozdział
          zakończymy dodatkową wiedzą, (choć nadal w stopniu podstawowym) na
          temat użytkowników.
        </p>
        <p>
          Wszystkie te powyższe zagadnienia łączy jedna rzecz, ich pliki
          konfiguracyjne znajdują się w katalog <strong>/etc</strong> i od
          omówienia tego katalogu zaczniemy.
        </p>
        <h2 id="7.1.etcdirectory">7.1. Katalog /etc</h2>
        <p>
          Jak wiemy z opisu hierarchii systemu plików (katalogu głównego), w 
          katalogu <strong>/etc</strong> przechowywane są różnego rodzaju
          konfiguracje, i to nie zależnie do wielkości czy istotności programu
          w systemie. Kiedyś każdy z programów przechowywał luzem swoją
          konfigurację tym katalogu. Obecnie jak możemy się przekonać większość
          zawartości <em>/etc</em> stanowią podkatalogi. Oczywiście wiele
          plików nadal się w nim znajduje, najczęsciej są to takie pliki
          jak <em>/etc/fstab</em> czy
          <em>/etc/passwd</em> lub <em>/etc/shadow</em> służące do
          przechowywania informacji o użytkownikach. Katalogi w <em>/etc</em>
          mają nazwy przeważnie odpowiadające nazwom programów, które
          konfigurują. Wyjątkiem są katalogi z końcówką <em>.d</em>. Pliki
          konfiguracyjne
          zostały umieszczone w tych katalogach, aby nie zostały one nadpisane
          przez aktualizacje pakietów. Obecnie nie ma to już miejsca, a mimo
          to konfiguracje wielu pakietów są umieszczane w tych katalogach.
        </p>
        <p>
          Pliki konfiguracyjne, nie których pakietów mogą występować w
          dwóch różnych wersjach. Pierwsza
          to jest, ta którą wszyscy znamy czyli katalog <em>/etc</em> taka
          konfiguracja nazywana jest <em>konfiguracją z możliwością dostosowania</em>.
          Druga wersją jest <em>konfiguracja bez możliwości dostosowania</em>
          znajdująca się w katalogu <em>/usr/lib</em>. Oczywiście to jest tylko
          koncepcja, aby administratorzy zajęli się konfiguracją w <em>/etc</em>
          a konfiguracje w <em>/usr/lib</em> zostawili opiekunom pakietów
          (osobom przygotowywującym pakiet oprogramowania dla danej dystrybucji,
          z wybranym programem) oraz twórcom samej dystrybucji. Możemy zmieniać
          oczywiście konfiguracje w tym katalogu, jednak trzeba mieć na uwadze
          dwie rzeczy: 
        </p>
        <ol>
          <li>Trzeba wiedzieć co się robi</li>
          <li>Zmiany w konfiguracji znajdującej w <em>/usr/lib</em> mogą 
            zostać nadpisane przez aktualizacje pakietu.
        </ol>
        <p>
          System Linuks nie jest miejscem, gdzie się cokolwiek komu kolwiek
          zabrania. Zasady i jakieś regułu  wprowadza się po to aby zapewnić 
          względne bezpieczeństwo oraz stabilność dystrybucji czy też ogolnie 
          systemu. 
        </p>
        <h2 id="syslog">7.2. syslog</h2>
        <p>
          Znaczna część komunikatów dignostycznych z różnych komponentów
          systemowych spływa do protokołowania czy rejestrowania lub
          prowadzenia plików dziennika. W języku polskim istnieje kilka
          określeń na to co konkretnie robi usługa <strong>syslog</strong>, 
          której zadaniem jest nasłuchiwanie na komunikaty diagnostyczne i
          przekazywanie ich do pliku, na ekran poszczególnych użytkowników lub
          całkowite zignorowanie. Wszystko zależy od konfiguracji.
        </p>
        <p>
          Obecnie wykorzystywana jest nowsza wersja <em>syslog</em> -
          <strong>rsyslog</strong>. Funkcje tej wersji nie ograniczają się
          tylko do zapisywania komunikatów diagnostycznych do pliku, program
          może na przykład przesyłać je do bazy danych. Na tym etapie nie
          będziemy się jednak tym zajmować, póki co będziemy musieli się
          zadowolić zwykłymi plikami tekstowymi przechowywanymi w katalogu
          <em>/var/log</em>. Warto mieć jednak na uwadze fakt, iż nie
          wszystkie pliki przechowywane w tym katalogu są zarządzane, przez
          tę usługę. Nie które daemony mogą posiadać swoje sposoby na
          utrzymanie i prezentowanie użytkownikowi własnych komunikaty
          diagnostycznych. Więcej informacji na temat jakie <em>logi</em> są
          przechwytywane przez <em>rsyslog</em> znajduje się w pliku
          konfiguracyjnym - <strong>/etc/rsyslog.conf</strong>.
        </p>
        <p>
          Na konfiguracje składają się tradycyjne reguły oraz dyrektywy
          dostępne w rozszerzonej wersji <em>rsyslog</em>. Dyrektywy możemy
          poznać po tym, że rozpoczynają się od symbolu dolara
          (<strong>$</strong>). Natomiast reguły konfiguracyne klasycznej
          wersji protokołu są nieco bardziej złożone.
        </p>
        <p>
          Reguły protokołu <em>syslog</em> określają sposób przychwytywania
          komunikatów diagostnycznych oraz docelowe miejsce ich zapisu. Zasady
          składają się z selektora i akcji, o to kilka z nich.
        </p>
<pre class="code-block">
*.info;mail.none;authpriv.none;cron.none  /var/log/messages
authpriv.*  /var/log/secure,root
mail.*      -/var/log/maillog
*.emerg     :omusrmsg:*
</pre>
        <p>
          Reguły <em>syslog</em> możemy podzielić na dwie części prawą i lewą.
          Po lewej stronie znajduje się selektor, określający przechwywane
          dane. Natomiast po prawej znajduje się akcja zazwyczaj jest ścieżka
          do pliku docelowego dla przychwconych komunikatów. Przy jednej ze
          ścieżek znajduje się myślnik, który powoduje nie synchronizowanie
          tego pliku jeśli włączono by synchronizacje (jest ona domyślnie
          wyłączona). Synchronizacja powoduje znaczny spadek wydajność i może
          doprowadzić do gubienia komunikatów.
        </p>
        <p>
          Selektor zaś składa się z kolejnych dwóch części: 
          <strong>funkcji</strong> oraz <strong>priorytetu</strong>. Funkcja
          określa źródło komunikatów i są one na stałe zaimplementowane w
          <em>rsyslog</em> a priorytety ich rodzaj wśród, których możemy
          wymienić (ułożenie według od najniższego do najwyższego):
        </p>
<pre class="code-block">
debug, info, notice, warning, error, crit, alert, emerg
</pre>
        <p>
          Tworząc selektor oddziela się funkcję od priorytetu za pomocą kropki.
          Priorytet służy do ograniczania wielkość przechwytywanych komunikatów,
          albowiem <em>rsyslog</em> rozpoczyna przechwytywanie komunikatów od
          tego priorytetu w górę. Jeśli przypatrzmy się pierwszej linii
          konfiguracji, zauważymy, że do pliku 
          <code class="code-inline">/var/log/messages</code> będzie
          spływać masa informacji, ponieważ selektor uwzględnia komunikaty
          ze wszystkich funkcji z minimalnym priorytetem 
          <code class="code-inline">debug</code>. Istnieją jednak pewne
          wykluczenia. Na selektor może składać się więcej niż jedna para
          <em>funkcja.priorytet</em>, co również widać w pierwszej linii
          przykładu. Kolejne pary rozdzielone są średnikami. W omawianym
          przykładzie, pary mają ten sam priorytet, który nie został
          uwzględniony na powyższej liście <strong>none</strong> powoduje
          wyłączenie przechwytywania z użytych w raz z nim funkcji. Tak więc
          w pierwszej linii przechwytywane będą komunikaty ze wszystkich
          funkcji z minmalnym priorytetem <code class="code-inline">info</code>,
          poza takimi funkcjami jak <code class="code-inline">mail</code>,
          <code class="code-inline">authpriv</code> oraz 
          <code class="code-inline">cron</code>. Komunikaty będą zapisywane
          zgodnie z akcją w pliku <code class="code-inline">/var/log/messages</code>.
        </p>
        <p>
          Innymi ciekawymi przypadkami w pokazanymi na przykładzie jest
          podanie w akcji w drugiej linii dwóch miejsc docelowych. Pliku
          <code class="code-inline">/var/log/secure</code> oraz nazwy
          superużytkownika. Podanie jakiej kolwiek nazwy użytkownika w akcji
          spowoduje przesłanie mu (za pomocą polecenia <strong>write</strong>)
          komunikatu diagnostycznego, o ile użytkownik zezwala na wyświetlanie
          tego typu komunikatów (polecenie <strong>mesg</strong>). Chociaż
          komunikaty wysłane przez superużytkownika są wyświetlane mimo tych
          ustawień. Kolejnym przypadkiem związanym z wysyłaniem jest użycie
          specjalnego <strong>modułu wyjściowego</strong> reprezentującego
          konkretną akcje, w tym przypadku jest wysyłanie wiadomości do
          zobrazowane w ostatniej linii przykładu. Jak mogliśmy zauważyć w
          liniach reguł możemy używać symbolu wieloznacznego gwiazdki
          (<strong>*</strong>).
        </p>
        <p>
          Dyrektywy nowszej wersji daemona rejestrującego są dość proste
          do zrozumienia i nie wymgają dodatkowego opisu.
        </p>
<pre class="code-block">
$FileOwner syslog
$FileGroup adm
$FileCreateMode 0640
$DirCreateMode 0775
$Umask 0022
</pre>
        <p>
          Jeśli chodzi o <em>syslog</em>, to w przypadku usługi rejestrowania
          może stać się nie wiele złego, jedynym problemem jaki możemy
          napotkać jest brak przechwytywania komunikatów z powodu 
          nieuwzględnienia jakiejś funkcji lub priorytetu w selektorze.
          Niemniej jednak rejestrator systemowy możemy przetestować za pomocą
          polecenia <strong>logger</strong> podając mu parę 
          <em>funkcja.priorytet</em> po opcji <strong>-p</strong>
          (na stronie podręcznika opcja określona jest jako priorytet) oraz
          komunikat do zapisania. Jeśli priorytet został pominięty, zostanie
          użyty domyślny <em>user.notice</em>. W zależności od konfiguracji
	        <em>rsyslog</em> oraz użytej funkcji nasz komunikat powinien
	        pojawić jednym z plików wyszczególnionych w konfiguracji.
          W przypadku użycia narzędzia <em>logger</em> z domyślnymi wartościami
          komunikat zostanie zapisany do <em>/var/log/messages</em>.
        </p>
        <p>
          Większość rejestratorów istnieje nie tylko w postaci odrębnego 
          programu jakim
          jest <em>rsyslog</em>, ale także w postaci funkcji, nie których 
          <em>daemonów</em>
          jak np. serwer WWW <em>Apache2</em> one również zapisuje swoje 
          komunikaty
          diagnostyczne do <em>/var/log</em>. Bardzo duża ilość danych
          spływająca do jednego katalogu może powodować szybkie
          zapełnienie przestrzeni dyskowej. Jednak się to nie dzieje, dzięki 
          programowi <strong>logrotate</strong>, którego zadaniem jest
          (w zależności od konfiguracji) usuwanie lub kompresja starych plików
          dzienników i utworzenie miejsca na nowe komunikaty.
        </p>
        <p>
          Z racji tego, iż demony działają w trakcje czynności wykonywanych 
          przez <em>logrotate</em>, skrypty obsługujące konkretne pliki 
          dziennika, tworzą puste pliki o takiej samej nazwie jak te utworzone
          przez demon.
        </p>
        <h2 id="7.3.userconfig">7.3. Konfiguracja użytkowników</h2>
        <p>
          Komputery jak i systemy operacyjne mają za zadanie służyć
          użytkownikom. Jak wiemy użytkownicy w systemach istnieją aby
          wyznaczać granicę. Mówiąc kolokwialnie każdy z nas ma swoją
          piaskownice i swoje zabawki. W Linuksach użytkownicy są opisywani za
          pomocą kilku plików w katalogu <em>/etc</em>.
        </p>
        <h3 id="7.3.1.passwdfile">7.3.1. Plik /etc/passwd</h3>
        <p>
          Plik <em>/etc/passwd</em> jest podstawowym źródłem informacji o 
          użytkownikach w systemie. W tym pliku każdy wiersz to jeden wpis
          definiujący użytkownika. Każdy wiersz podzielony jest na 7 pól.
          Poniżej znajduje się kilka przykładowych wpisów:
        </p>
<pre class="code-block">
pulse:x:109:114:PulseAudio daemon,,,:/run/pulse:/usr/sbin/nologin
saned:x:110:117::/var/lib/saned:/usr/sbin/nologin
colord:x:111:118:colord colour management daemon,,,:/var/lib/colord:/usr/sbin/nologin
lightdm:x:112:119:Light Display Manager:/var/lib/lightdm:/bin/false
libvirt-qemu:x:64055:105:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
geoclue:x:113:124::/var/lib/geoclue:/usr/sbin/nologin
user:x:1000:1000::/home/user:/bin/bash
xf0r3m:x:1001:1001::/home/xf0r3m:/bin/bash
</pre>
        <p>
          Pola te zawierają kolejno:
        </p>
        <ul>
          <li><strong>Nazwa użytkownika</strong> - jednoznaczny identyfikator
            użytkownika, służący do rozpoznawania użytkowników miedzy innymi
            użytkownikami.</li>
          <li><strong>Zaszyfrowane hasło</strong> - w dystrybucjach Linuksa
            hasło nigdy nie było przechowywany w jawnej postaci, nawet w tak
            zamieszchłych czasas kiedy znajdowało się ono w pliku 
            <em>/etc/passwd</em>. Obecnie po haśle został tylko
            <code class="code-inline">x</code>, co oznacza, że hasło jest
            przechowywany w pliku <em>/etc/shadow</em>, który również zostanie
            tu omówiony.</li>
          <li><strong>UID (identyfikator użytkownika)</strong> - numer
            identyfikujący użytkownika, służy głównie odwołaniu się jądra do
            konkretnego użytkownika.</li>
          <li><strong>GID (identyfikator grupy)</strong> - numer
            identyfikujący podstawową grupę użytkownika.</li>
          <li><strong>Pole GECOS</strong> - pole przechowujące rzeczywiste
            informacje o użytkowniku takie jak imie, nazwisko, numer telefonu,
            adres e-mail, numer pokoju. Pole może zostać pominięte, co widzimy
            na kilku wpisach na przykładzie.</li>
          <li><strong>Katalog domowy</strong> - ścieżka wskazująca na katalog
            domowy użytkownika.</li>
          <li><strong>Program uruchamiany po zalogowaniu (powłoka)</strong> -
            ścieżka wskazująca na program jaki ma zostać uruchomiony po 
            zalogowaniu, najczęściej jest to interaktywna powłoka.</li>.
        </ul>
        <p>
          Drugie pole wpisu w <em>/etc/passwd</em> może przyjmować dwie
          dodatkowe wartości. Pole może zawierać gwiazdkę (<strong>*</strong>),
          która uniemożliwia logowanie lub pole może być puste co pozwala na
          zalogowanie się bez podawania hasła. 
        </p>
        <p>
          Jeśli przefiltrujemy za pomocą polecenia <em>grep</em> plik 
          <em>/etc/passwd</em> pod kątem ustawionych programów (powłok), to
          na powiedzmy ok. 50 (zależności od dystrybucji) tylko dwóch, trzech
          użytkowników ma ustawioną powłokę. Pozostali użytkownicy zazwyczaj
          mają ustawiony program, który uniemożliwia im korzystanie z systemu
          nawet gdy się zalogują. Tacy użytkownicy nazwani są 
          <strong>pseudoużytkownikami</strong>. Tego rodzaju użytkownicy
          istnieją w jednym celu, aby uruchamiać z ich uprawnieniami różne
          programy, głównie demony sieciowe. Co w razie włamania spowoduje, że
          atakujący zostanie uwięziony na koncie, na którym nic nie może
          zrobić.
        </p>
        <p>
          Pseudoużytkownicy zaliczają się do użytkowników specjalnych obok nich
          istnieje jeszcze jeden użytkownik - <strong>root</strong>, który ma
          niczym nie ograniczone uprawnienia. Dlatego też nosi nazwę
          <em>superużytkownika</em>. Posiada on UID i GID równy 0 oraz jego
          katalog domowy znajduje się bezpośrednio w głównym katalogu. Innym
          ciekawym użytkownikiem specjalnym jest użytkownik <em>nobody</em>,
          który nie ma możliwości zapisu niczego w systemie.
        </p>
        <p>
          Kombinacja wpisu w pliku <em>/etc/passwd</em> oraz katalogu domowego
          może być określana jako <strong>konto</strong>.
        </p>
        <h3 id="7.3.2.shadowfile">7.3.2. Plik /etc/shadow</h3>
        <p>
          Plik <em>/etc/shadow</em> jest podobnym plikiem <em>/etc/passwd</em>,
          jednak zamiast przechowywać informacje o użytkownika plik ten 
          przechowuje informacje o hasłach. Plik <em>/etc/shadow</em> posiada
          jedno wspólne pole wraz z plikiem <em>/etc/passwd</em> a jest nim
          nazwa użytkownika. Hasło podobnie do pliku <em>/etc/passwd</em> 
          znajduje się na drugim polu we wpisie. Pozostałe pola są
          odpowiedzialne za ważność hasła. Wpisy w pliku <em>/etc/shadow</em>
          biorą również czynny udział w blokowaniu dostępu użytkownikom. 
          Zawartośc pliku wygląda w następujący sposób:
        </p>
<pre class="code-block">
root:$y$j9T$h19rJ2ObBXMdBdXOHB0wF.$.Lqb5iG3.HpsO0FcghqSkXbcA6D5rIp9woC/Ovj40Q7:19251:0:99999:7:::
...
user:$y$j9T$bAf/P4bLm00VJQyS3Lf8I1$dzie3XL5lORpP7jmo4CeanOqhuWMpPzdQArAlQ9AfG0:19327:0:99999:7:::
</pre>
        <p>
          Na tym etapie nauki dalsza analiza tych wpisów nie ma sensu, jeśli
          jednak ktoś jest ciekawy pozostałych pól to może zajrzeć do mojego
          materiału przygotowywującego do RHCSA: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#6.1.passwordaging">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#6.1.passwordaging</a>
        </p>
        <p>
          Plik <em>/etc/shadow</em> jest dość mocno zabezpieczonym plikiem,
          zwykli użytkownicy nie posiadają do niego żadnych praw. Jedyną
          uprawnioną osobą do manipulacji nim jest superużytkownik.
        </p>
        <h3 id="7.3.3.changingusers">7.3.3. Manipulowanie użytkownikami i hasłami</h3>
        <p>
          Omawiane dotychczas pliki są zwykłymi plikami tekstowymi, których 
          zawartością możemy manipulować za pomocą ulubionego edytora
          tekstowego. Nie jest to jednak zalecane działanie. Ze względu na 
          ścisłą budowę (nie możliwe jest aby umieszczać w tych plikach 
          komentarze lub puste wiersze) oraz restrykcyjną składnie wierszy.
          Możemy użyć specjalnego narzędzia jakim jest <strong>vipw</strong>.
          Polecenie to tworzy kopię zmienianych plików i następnie otwiera
          ten plik w terminalowym edytorze. Konfiguruje ono również ten edytor
          aby zaznaczał składnię wpisów w plików, po zapisaniu zmian polecenie
          sprawdzi składnie zmienionych lub dodanych wpisów. Jeśli wszystko
          będzie dobrze, to polecenie zapisze zmiany jeśli coś będzie nie
          tak to polecenie zaproponuje poprawienie błędu. Polecenie wymaga
          oczywiście uprawnień administratora. Wydając polecenie bez żadnej
          opcji otworzy ono plik <em>/etc/passwd</em> do edycji a jesli dodamy
          opcje <strong>-s</strong> to wówczas zostanie otworzony plik 
          <em>/etc/shadow</em>.
        </p>
        <p>
          Inną metodą jest wykorzystanie np. opcji polecnia 
          <strong>passwd</strong> jego domyślną rolą jest zmiana hasła, bądź 
          ustawianie ważności hasła, jednak dodając opcję <strong>-s</strong>
          mozemy zmienić domyślny program startowy (powłokę) lub za pomocą
          opcji <strong>-f</strong> możemy zmienić nazwę użytkownika. Po
          więcej informacji zapraszam do strony podręcznika polecenia 
          <em>passwd</em>. Jeśli na naszym przypadku polecenie <em>passwd</em>
          może nie być zadowalające. Można wówczas skorzystać z polecenia typu
          <strong>usermod</strong>.
        </p>
        <h3 id="7.3.4.groups">7.3.4. Grupy</h3>
        <p>
          Rolą grup w systemach uniksopodobnych jest współdzielenie plików.
          Dzięki nim możemy zwiększyć uprawnienia do pliku, nie którym
          użytkownikom, chroniąc je przed innymi. Wynika to z możliwosci
          nadania uprawnień grupie, natomiast można je zabrać wszystkim 
          pozostałym. Obecnie stacje uniksowe stały się bardziej
          spersonalizowanie to współdzielenie plików przy użyciu grup
          straciło na znaczeniu. Jednak grupy tak jak użytkowników możemy 
          wykorzystać do uzyskiwania dodatkowych uprawnień lub ich
          ograniczania.
        </p>
        <p>
          Wraz z każdym nowym użytkownikiem tworzona jest nowa grupa o tej
          samej nazwie co użytkownik. Grupa ta jest również ustawiana jako
          grupa podstawowa tworzonego użytkownika. Definicje grup znajdują
          się w pliku <em>/etc/group</em>. Poniżej znajduje się fragment:
        </p>
<pre class="code-block">
libvirt:x:123:user,xf0r3m
libvirt-qemu:x:64055:libvirt-qemu,user,xf0r3m
geoclue:x:124:
user:x:1000:
xf0r3m:x:1001:
</pre>
        <p>
          Jak możemy zauważyć wpisy dzielą się na cztery pola, które kolejno
          oznaczają:
        </p>
        <ul>
          <li><strong>Nazwa grupy</strong> - nazwa jednoznacznie identyfikująca
            grupę.</li>
          <li><strong>Hasło grupy</strong> - hasło grupy. Obecnie aby podłączyć
            użytkownika do grupy potrzebna jest interwencja administratora lub
            kogoś z jego uprawnieniami. Jeśli jednak grupa posiada hasło to 
            użytkownik może podłączyć się do grupy za pomocą polecenia
            <strong>newgrp</strong> (dalej jest taka możliwość). Obecnie
            jednak nie stosuje się haseł dla grup. Hasła grup są przechowywane
            w pliku <em>/etc/gshadow</em>.</li>
          <li><strong>GID (identyfikator grupy)</strong> - numeryczny
            identyfikator grupy, służy do odniesienia jądra do konkretnej
            grupy.</li>
          <li><strong>List członków grupy</strong> - lista uzytkowników
            należących do grupy.</li>
        </ul>
        <p>
          Grupy odpowiadające istniejącym użytkownikom nie posiadają żadnych
          członków w tym pliku, jednak odpowiadający tym grupom użytkownicy są
          ich domyślnymi członkami.
        </p>
        <p>
          Jądro Linux, nie posługuje się nazwami użytkowników czy grup 
          odwołując się do jednego lub drugiego bytu. W tym celu używa wartości
          UID oraz GID, aby ich używanie miało sens muszą być one unikatowe
          w skali całego systemu. Oczywiście może zdażyć się przypadek, że
          dwóch użytkowników będzie miało ten sam UID, ale są to bardzo rzadkie
          i specyficzne przypadki.
        </p>
        <h2 id="gettyandlogin">7.4. Getty oraz login</h2>
        <p>
          Te dwa programy nie są zbyt skomplikowane w swoim działaniu.
          Działanie programu <em>getty</em> polega na podłaczeniu się pod
          terminal (nie ważne czy wirtualny czy fizyczny podłączony przez 
          port COM) i wyświetlenie znaku zachęty logowania (napisu "login: ")
          i oczekiwania na podanie nazwy użytkownika. Kiedy nazwa zostanie
          podana
          polecenie to zastępuje same siebie wywołując program <em>login</em>.
          Ten program odpowiedzialny jest za wyświetlenie znaku zachęty hasła
          (napisu "hasło:") po podaniu przez użytkownika hasła program
          spróbuje go uwierzytelnić. Jeśli to się powiedzie wówczas program
          <em>login</em> zastąpi sam siebie po przez wywołanie systemowe
          <em>exec()</em> programem startowym ustawionym w ostatnim polu 
          wpisu w pliku <em>/etc/passwd</em>.
        </p>
        <p>
          Prawdopodbnie nigdy nie będzie potrzeby konfiguracji tych programów,
          nie mniej jednak jest taka możliwość.
        </p>
        <h2 id="7.5.time">7.5. Ustawienia czasu.</h2>
        <p>
          Działanie wielu operacji w systemach uniksopodobnych opiera się o
          czas. Za zegar w tych systemach odpowiedzialne jest jądro. Jednak
          nie jest ono wstanie wziąć precyzyjnych ustawień czasowych samo z
          siebie. Większość komputerów klasy PC posiada potrzmywany bateryjnie
          zegar czasu rzeczywistego, jądro synchronizuje swój zegar z tym 
          zegarem jednak z racji tego, iż maszyny uniksowe nie są uruchamiane
          ponownie przez miesiące a nawet lata. W czasie systemowym pojawia 
          się odchylenie. 
        </p>
        <p>
          Zegar systemowy jądra również jest korygowany na podstawie ustawień
          strefy czasowej w jakiej się znajdujemy, dlatego też 
          RTC (ang. <em>Real Time Clock</em>) w BIOS lub UEFI powinien być 
          ustawiony zgodnie ze strefą czasową UTC. Za pomocą poniższego
          polecenia możemy ustawić czas UTC jądra względem RTC.
        </p>
<pre class="code-block">
$ sudo hwclock --hctosys --utc
</pre>
        <h3 id="7.5.1.timezonesandtimerepresentation">7.5.1. Strefy czasowe i reprezentacja czasu</h3>
        <p>
          Jądro przechowuje swój czas w formacie uniksowym, czyli ilości 
          sekund od północy 1 stycznia 1970 roku. Na podstawie tych informacji
          takie polecenia jak <strong>date</strong> dokonuja wszelkich 
          konwersji i wyświetlają nam zrozumiałą dla nas datę i czas. Czas
          uniksowy możemy wyświetlić sobie za pomocą polecenia <em>date</em>
          z opcją <strong>+%s</strong> (niestety polecenie <em>date</em> ma
          nieco inny format opcji).
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ date
śro, 28 gru 2022, 13:11:53 CET
xf0r3m@immudex:~$ date +%s
1672229517
</pre>
        <p>
          Domyślnie polecenie <code class="code-inline">date</code> wyświetla
          datę i czas skorygowany o ustawioną w naszym systemie, na podstawie
          przybliżonej lokalizacji strefę czasową. Ustawiona strefa czasowa
          znajduje się katalogu <em>/etc</em> jako dowiązanie symboliczne do
          jednego z plików stref dostępnych w systemie w katalogu 
          <em>/usr/share/zoneinfo</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ ls -al /etc/localtime 
lrwxrwxrwx 1 root root 33 11-04 17:46 /etc/localtime -&gt; /usr/share/zoneinfo/Europe/Warsaw
</pre>
        <p>
          Strefę czasową możemy zmienić za pomocą polecenia interaktywnego 
          polecenia <strong>tzselect</strong>. Polecenie to spróbuje określić
          twoją przybliżoną lokalizacje na podstawie stolicy kraju w jakim się
          znajdujesz. Następnie utworzy nowe dowiązanie symboliczne
          <em>/etc/localtime</em> do odpowiedniego pliku strefy.
        </p>
        <p>
          Jeśli z jakiś przyczyn potrzebujemy sprawdzić jaki bedzie czas w
          wybranej przez nas strefie czasowej, możemy zmienić zmienną
          środowiskową TZ, która przechowuje informacje o ustawionej strefie
          czasowej na czas wykonania polecenia. Tę czynność możemy wykonać na 
          czas wykonania pojedyńczego
          polecenia, ustawiając wartość zmiennej w tej samej linii co polecenie
          <em>date</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ TZ=Asia/Tokyo date
śro, 28 gru 2022, 21:29:01 JST
</pre>
        <h3 id="7.5.2.settingntptime">7.5.2. Czas sieciowy</h3>
        <p>
          Jeśli nasza maszyna sieciowa jest na przykład serwerem ze stałym 
          dostępem do sieci. To aby zniwelować to odchylenie czasowe, którym
          wspomniałem na początku tego podrozdziału możemy uruchomić na nim 
          specjalną usługę sieciową, która pobierze czas z serwerów
          podłączonych do bardzo precyzyjnych zegarów atomowych.
        </p>
        <p>
          Pierwszą rzeczą jak należy zrobić to pobrać pakiet odpowiedzialny
          za demon NTP w naszym systemie. Następnie skonfigurować go zgodnie
          jego dokumentacją. Najprostsza konfigurację możemy zapisać w
          poniższych krokach.
        </p>
        <ol>
          <li>Znalezienie najbliższego dla siebie serwera NTP, najlepiej
            na poziomie STRATUM nie większym niż 3.</li>
          <li>Zapisanie adresów serwera (serwerów, może być pula) w pliku
            konfiguracyjnym demona NTP, najczęściej jest to 
            <em>/etc/ntp.conf</em>.</li>
          <li>Uruchomienie polecenia <em>ntpdate</em>.</li>
          <li>Włącznienie demona NTP do uruchomienia w trakcie autostartu.</li>
        </ol>
        <p>
          Jeśli nasz komputery nie posiada stałego łącza internetowego możemy
          wówczas uruchomić takiego demona jak <em>chronyd</em>. Ostatecznie
          mozemy zsynchonizowany czas systemowy załadować do zegara RTC za 
          pomocą poniższego polecenia.
        </p>
<pre class="code-block">
$ sudo hwclock --systohc --utc
</pre>
        <p>
          W tym podrozdziale umieściłem polecenie, którego nie wyjaśniłem.
          Jest nim <strong>poziom STRATUM</strong>. Wyjasnienie tego pojecia
          wymaga zagłebienia się w protokół NTP, co zrobiłem w materiale
          przygotowawczym do RHCSA znajdującym się tutaj: <a href="https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#18.1.ntp">https://morketsmerke.github.io/articles/terminallog/RedHat_-_RHCSA.html#18.1.ntp</a>.
        </p>
        <h2 id="7.6.cron">7.6. Tworzenie powtarzalnych zadań za pomocą cron</h2>
        <p>
          Wróćmy na chwile do drugiego podrozdziału. Tam pod koniec omówiliśmy
          sobie gdzie znajdują się pliki dziennika i w jaki sposób system 
          radzi sobie z problem szybko przyrastających plików zawierających
          komunikaty diagnostyczne z przeróżnych demonów. Wspomnialiśmy tam 
          o <em>logrotate</em>. Ten program aby zapobiec zużyciu całego miejsca
          na dysku musi uruchamiać się co jakiś czas.
        </p>
        <p>
          W uniksach aby wykonywać jakieś czynności co określoną ilość czasu,
          musimy skorzystać z programu o nazwie <strong>cron</strong>. Ten 
          program to swojego rodzaju harmonogram zadań, w którym to może
          zdefiniować co uruchomić, kiedy lub co ile czasu i przez kogo.
          Definicje zadań znajdując się w specjalnych plikach zwanych
          <em>crontab</em>. Każdy użytkownik ma swój plik. Ponieważ pliki te
          znajdując się w miejscu, do którego zwykli użytkownicy nie mają 
          dostępu muszą używać
          dostarczonym wraz z <em>cron</em> narzędziem.
        </p>
        <p>
          Aby móc zdefiniować zadania należy wydać następujące polecenie:
        </p>
<pre class="code-block">
$ crontab -e
</pre>
        <p>
          Wówczas otworzy nam się wybrany przez nas wcześniej edytor
          terminalowy. Wewnątrz pliku znajdziemy obszerny komentarz, w którym
          to rozpisano dokładnie całą składnie definicji zadania <em>cron</em>.
        </p>
        <p>
          Otóż zadania <em>cron</em> to jednowierszowe wpisy definiujące na 
          początku czas (kiedy, co ile czasu) w którym należy uruchomić zadanie
          Następnie polecenie, które należy uruchomić.
        </p>
<pre class="code-block">
21 0 * * * /usr/local/bin/backup.sh &gt; /var/log/backup_sh.log 2&gt;&amp;1
</pre>
        <p>
          To zadanie zostanie uruchomione codziennie 21 minut po północy. Skąd
          to wiem, otóż już śpieszę z wyjaśnieniami. Najpierw objaśnie
          poszczególne pola.
        </p>
        <ul>
          <li><code class="code-inline">21</code> - pole minut, podanie tutaj
            takie zwykłej wartości jak na przykładzie, spowoduje uruchomienie
            zadania o podanej minucie godziny. Zakres wartości od 0 - 59.</li>
          <li><code class="code-inline">0</code> - pole godziny, podanie
            wartości w tym polu spowoduje, że zadanie zostanie uruchomione
            o tej samej pełnej godzinie każdego dnia, chyba że podano konkretną
            minutę. Zakres wartości od 0 - 23.</li>
          <li><strong><span style="color: lightgreen">*</span></strong> - pole
            dnia miesiąca, wartość w tym polu spowoduje, że zadanie zostanie
            uruchomione o północy podanego dnia miesiąca, chyba że zdefiniowano
            wcześniejsze pola. Zakres wartości od 1 - 31.</li>
          <li><strong><span color="color: fuchsia">*</span></strong> - pole
            miesiąca, wartość w tym polu spowoduje uruchomienie zadania o
            północy 1 dnia miesiąca, chyba że zdefiniowano wcześniejsze pola.
            Zakres wartości od 1 - 12.</li>
          <li><strong><span color="color: cornfloweblue">*</span></strong> -
            pole dnia tygodnia, wartość w tym polu spowoduje uruchomienie
            zadania co tydzeń o północy podanego dnia tygodnia. Chyba że 
            zdefiniowano wcześniejsze pola. Zakres wartości od 0 - 7, przy czym
            0 i 7 to niedziela.</li>
        </ul>
        <p>
          Ustawienia czasu wykonania zadania jest w miarę proste o ile nie
          wymagamy bardzo złożonego warunku czasowego lub nie próbujemy go 
          zrozumieć (zadając sobie pytanie: kiedy to dokładnie się wykona?).
          Załóżmy że chcemy aby zadanie wykonało się w każdy weekend wakacji
          w Polsce. Warunek czasowy może przyjmować: wartości krokowe
          (<strong>/2</strong>) co dwie minuty, godziny, dni, miesiące; 
          zakresy (<strong>5-10</strong>) od 5-10 minuty, godziny, dnia itd lub
          listy (<strong>11,12</strong>) zadanie wykoania się np. 11 i 12
          każdego miesiąca. Zakresy oraz listy można ze sobą łączyć, jak i
          dodać pojedyńczą wartość do zakresu, np. 5-10,12. Przy tworzeniu 
          warunku czasowego możemy posłużyć się stronami takimi jak:
        </p>
        <ul>
          <li><a href="https://crontab.guru">https://crontab.guru</a></li>
        </ul>
        <h3 id="7.6.1.instalationofcrontab">7.6.1. Instalacja tablicy cron.</h3>
        <p>
          Po zapisaniu zmian tablica z zadaniami crona (<em>crontab</em>)
          zostanie automatycznie zainstalowana w katalogu
          <em>/var/spool/cron/crontab</em>. Polecenie 
          <code class="code-inline">crontab</code> daje możliwość instalacji
          tablicy zadań z zwykłego pliku tekstowego, dokonujemy tego za pomocą
          polecenia <code class="code-inline">crontab</code> wraz z opcją 
          <strong>-l</strong>. Jednak
          korzystanie z opcji <code class="code-inline">-e</code> jest bardziej
          zalecane. Wówczas podczas zapisywania zmian polecenie sprawdzi 
          zadania pod kątem poprawności składni i przypadku błedu, zapyta czy
          nie chcemy go poprawić.
        </p>
        <p>
          Tablice z zdaniami cron możemy usunąć za pomocą opcji 
          <strong>-r</strong> polecania <code class="code-inline">crontab</code>.
        </p>
        <h3 id="7.6.2.systemwidecrontab">7.6.2. Systemowa tablica zadań crontab.</h3>
        <p>
          Prócz tablic użytkowników, istnieje jescze systemowa tablica
          z zadaniami <em>cron</em>. Ją edytujemy już pomocą edytora tekstowego
          ponieważ jej wpisy mają nieco inną składnie niż tablice użytkowników.
          W jej wpisach znajduje się dodatkowe pole między dniem tygodnia a
          poleceniem. W nim definiuje się użytkownika, z którego uprawnienami
          realizowane jest zapisane zadanie. Dlatego też polecenie 
          <em>crontab</em> z opcją <em>-e</em> nie ma tutaj zastosowania. Jako
          systemowej tablicy cron, nie wykorzystuje się również tablicy
          superużytkownika. Za tablicę systemową odpowiedzialny jest plik 
          <em>/etc/crontab</em>. Plik ten edytujemy za pomocą zwykłego edytora,
          kiedy zakończymy edycję, należy uruchomić demon <em>cron</em>
          ponownie.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo vim /etc/crontab 
xf0r3m@immudex:~$ sudo systemctl restart cron
</pre>
        <p>
          Inną metodą na powtarzalne wykonywanie czynności jest skorzystania
          z jednego katalogów: <em>/etc/cron.daily</em>, 
          <em>/etc/cron.hourly</em>, <em>/etc/cron.monthly</em> lub 
          <em>/etc/cron.weekly</em>. Wykorzystanie tych katalogów polega na 
          umieszczeniu skryptu (powłoki, nawet jednej linii z konkretnym
          poleceniem) w jednym z nich. W systemowej tablicy <em>cron</em> jest
          napisane o której wykonywane są zadania zapisane w tych katalogach.
          Skrypty uruchamiane są przez znane nam z poprzedniego rozdziału
          narzędzie jakim jest <em>run-parts</em>. W nowszych dystrybucjach
          obsługą tych katalogów może zajmować się demon <em>anacron</em>.
        </p>
        <h3 id="7.6.3.futureofcron">7.6.3. Przysłość narzędzia cron.</h3>
        <p>
          Narzędzie <em>cron</em> jest starsze od samego Linuksa. Jeśli coś
          jest, aż tak stare to kwalifikuje się do wymiany. Obecnie są czynione
          postępy w temacie zastąpienia <em>cron</em>-a jakimś innym
          rozwiązaniem. Kandydatem mogą być elementy licznika czasu
          <em>systemd</em>. Jednak utworzenie ulepszonej funkcjonalności to
          jedno, a zapewnienie wstecznej zgodność z systemami oraz narzedziami
          dalej wykorzystującymi cron to drugie, bez zapewnienia wstecznej
          zgodności zmian nie będzie, więc póki co <em>cron</em> jeszcze z
          nami pozostanie.
        </p>
        <h2 id="7.7.at">7.7. Planowanie jednorazowych zadań.</h2>
        <p>
          Jedno narzędzie do planowania zadań w przyszłości już poznaliśmy. 
          Narzędzie <strong>at</strong> na pewno nie ma tak szerokiego użycia
          jak <em>cron</em>, to pomaga wykonać pewne zadania po za czasem 
          czynnego użytkowania komputera. Jeśli musimy poczekać do powiedzmy
          północy, aby móc wykonać jakąś czynność, możemy ją zaplanować
          za pomocą polecenia <em>at</em>, pozostawić komputer włączony i
          iść spać.
        </p>
        <p>
          Za pomocą polecenia <em>at</em>, możemy nie tylko zaplanować
          wykonanie zadania na kilka godzin do przodu ale i nawet na kilka
          miesięcy. Aby jednak to zrealizować należy poznać polecenie
          <em>at</em>, które może nie być domyślnie dostępne w każdej
          dystrybucji i trzeba je będzie zainstalować.
        </p>
        <p>
          Aby rozpocząć planowanie zadania należy wydać polecenie <em>at</em>
          i jako argument podać czas ewentualnie datę jeśli zadanie ma zostać
          wykonane w dalszej przyszłości. Po wydaniu tego polecenia zostanie
          nam wyświetlony prompt <em>at&gt;</em>. Po wyświetleniu prompta
          podajemy polecenie do wykonania w zadaniu. Polecenia możemy podawać
          do momentu kiedy naciśniemy kombinację klawiszy <em>Ctrl+d</em>,
          przed zatwiedzeniem polecenia należy upewnić się, że zostało 
          poprawnie zapisane ponieważ nie będzie możliwości jego edycji.
          Po naciśnięciu wspomnianiej kombinacji zadanie zostanie zatwierdzone
          Na poniższym przykładzie utworzyłem jedno zadanie z jednym 
          poleceniem:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ at 00:00 01.01.2023
warning: commands will be executed using /bin/sh
at&gt; echo "Happy New Year" &gt; /dev/pts/1
at&gt; &lt;EOT&gt;
job 1 at Sun Jan  1 00:00:00 2023
</pre>
        <p>
          Za pomocą opcji <strong>-l</strong> polecenia <em>at</em> lub
          polecenia <em>atq</em> możemy wyświetlić znajdujące się w pamieci
          demona <em>atd</em> zadania.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ at -l
1	Sun Jan  1 00:00:00 2023 a xf0r3m
xf0r3m@immudex:~$ atq
1	Sun Jan  1 00:00:00 2023 a xf0r3m
</pre>
        <p>
          Natomiast za pomocą opcji <strong>-r</strong> polecenia <em>at</em>
          lub za pomocą polecenia <em>atrm</em>, możemy usunąć zdanie, przyczym
          należy podać numer zadnia widniejący w pierwszej kolumnie danych 
          wyjściowych zwracanych przez polecenie <em>at</em> w raz z opcją
          <em>-l</em> lub polecenie <em>atq</em>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ atq
1	Sun Jan  1 00:00:00 2023 a xf0r3m
xf0r3m@immudex:~$ at -r 1
xf0r3m@immudex:~$ atq
</pre>
        <h2 id="7.8.switchinguids">7.8. Identyfikatory użytkowników oraz ich przełączanie.</h2>
        <p>
          Jak pamiętamy, lub może nie bit <em>setuid</em> powodował fakt iż 
          program uruchomiony z tym bitem dział (jego proces) z uprawnieniami
          właściciela pliku. Tutaj poznamy inne możliwości przełączania
          użytkowników wraz regułami oraz jaki udział ma w tym wszystkim jądro.
        </p>
        <p>
          Na Linuksie istnieją dwie metody na przełączanie użytkowników.
          Pierwszym z nich jest ustawienie wspomnianego wcześniej bitu dla
          pliku wykonywalnego. A drugim sposobem jest wykorzystanie wywołania
          systemowego <strong>setuid()</strong>, a żeby sprawę jeszcze bardziej
          skomplikować to wersji tego wywołania systemowego jest kilka, w 
          zależności o tego na jaki identyfikator użytkownika chcemy się
          przełączyć. Zanim poznamy możliwe identyfikator (a przynajmniej ich
          część) warto poznać reguły dotyczące możliwości procesów w zakresie
          przełączania identyfikatorów. Otóż:
        </p>
        <ul>
          <li>Procesy działające z uprawnieniami superużytkownika mogą używać
            wywołania systemowego <em>setuid()</em> do uzyskania uprawnień 
            dowolnego innego użytkownika.</li>
          <li>Proces, który nie działa z uprawnieniami superużytkownika ma 
            poważne ograniczenia odnośnie korzystania z wywołania systemowego
            <em>setuid()</em>. Przeważnie takie procesy nie mogą z niego 
            korzystać.</li>
          <li>Dowolny proces może wykonać program z ustawionym bitem 
            <em>setuid</em>, o ile dysponuje odpowiednimi uprawnieniami do
            tego pliku (każdy proces działa z uprawnieniami jakiegoś
            jakiegoś użytkownika i dziedziczy po nim uprawnienia).</li>
        </ul>
        <p>
          Dla ścisłości w tym przełączaniu użytkowników nie chodzi o
          przełączanie między kontami. A raczej o to, że na podstawie
          dostępnych mechanizmów w systemie proces może zmieniać uprawnienia
          wrazie potrzeby oraz możliwości z jakim został uruchomiony.
        </p>
        <h3 id="7.8.1.processowneranduids">7.8.1. Właściciel procesu oraz identyfikatory użytkownikow</h3>
        <p>
          Dotych czas można było sądzić, że procesy, które uruchamiamy w
          Linuksie posiadły jeden identyfikator użytkownika. Użytkownika, który
          ten proces zainicjował. Rzeczywistość jest niestety zgoła inna. 
          Każdy proces posiada co najmniej dwa identyfikatory użytkowników.
          Pierwszym z nich jest <strong>euid</strong> 
          (ang. <em>Effective User IDentifier</em>) - efektywy identyfikator
          użytkownika. Ten identyfikator wskazuje na użytkownika, z ktorego 
          uprawnienia działa ten proces. Drugim jest <strong>ruid</strong>
          (ang. <em>Real User IDentifier</em>) - rzeczywisty identyfikator
          użytkownika. Ten wskazuje natomiast użytkownika, który zainicjował
          ten proces. 
        </p>
        <p>
          Ze względu na niejasność związane z rozgraniczeniem miedzy 
          <em>euid</em> a <em>ruid</em>. Rzeczywistemu identyfikatorowi
          użytkownika przypisje się rolę właściciela procesu. Może on 
          prowadzić interakcje z procesem wysyłać do niego sygnały w tym 
          kończyć jego działanie. W przypadku większości procesów 
          działających w systemie <em>ruid</em> oraz <em>euid</em> będą równe.
          Jednak w przypadku gdy uruchomimy proces z ustawionym bitem
          <em>setuid</em>, efektywny identyfikator zostanie ustawiony na
          właściciela pliku, zaś rzeczywisty identyfikator będzie 
          przechowywać nasz UID. Najprostszym przykładem uruchomienia programu 
          z bitem <em>setuid</em> a za razem doświadczenia przełączenia 
          identyfikatorów jest użycie polecenia <strong>sudo</strong>.
        </p>
        <p>
          Żeby całość jeszcze bardziej skomplikować, do tych dwóch
          identyfikatorów należy dodać jescze większego poziomu skomplikowania
          to istnieje trzeci identyfikator <strong>suid</strong>
          (ang. <em>Saved User IDentifier</em>) - zapisany identyfikator
          użytkownika. Podczas działania, proces może przełączać się między
          zapisanym a rzeczywistym identyfikatorem. 
        </p>
        <p>
          Jeśli uruchomimy jakiś proces przy użyciu polecenia <em>sudo</em>
          i ten proces będzie trwać, i spróbujemy go zabić to wówczas 
          dostaniemy informacje o braku dostępu. Polecenie <em>sudo</em>
          z ustawionym bitem <em>setuid</em> (jak i inne) zamienia 
          <strong>jawnie</strong>
          identyfikatory użytkowników za pomocą wywołania systemowego
          <em>setuid()</em>. Wynika to z kilku problemów jakie wynikają z
          braku zgodności między identyfikatorami, przez co nie musimy
          się zbytnio przejmować nimi oraz ich przełączaniem.
        </p>
        <p>
          Ze względu na duże uprawnienia (czynny udział jądra w przełączaniu
          użytkowników oraz obsłudzie uprawnień dostępu do pliku) programów z 
          ustawionym bitem 
          <em>setuid</em> i działającym wraz z nim wywowałań systemowych.
          Należy uważać jakim programom nadaje się ten bit. Pozostawienie
          kopii powłoki z ustawionym takim bitem, daje możliwość zwykłym 
          użytkownikom przejęcia kontroli nad całym systemem. Wydając jedno
          polecenie.
        </p>
        <h2 id="7.9.identifyandauthtenticate">7.9. Identyfikacja i uwierzytelnianie</h2>
        <p>
          Każdy wieloużytkowy system musi zapewnić mechanizmy czuwające nad
          kontrolą użytkowników. Użytkownicy powinni przedstawić się systemowi
          przekazać tajną informację (hasło), wówczas mechanizmy w systemie 
          będą wiedzieć, że
          ten użytkownik jest tym za kogo się podaje. Jeśli użytkownik został
          uwierzytelniony ma on dostęp do swojego konta, które jest
          autoryzowane (posiada pewne prawa w systemie) i w ten sposób systemy
          identyfikują użytkowników. To tak wygląda tylko w teorii. Z racji
          tego, iż jądro zna tylko UID, ustalenie nazwy użytkownika wymaga 
          kilku czynności. Można przedstawić tutaj krokowy algorytm, który
          byłby w stanie ustalić taką nazwę, jednak stosuje sie funkcję
          biblioteki standardowej, które pomagają w ustaleniu takich
          informacji. Problem stanowią natomiast hasła, ponieważ funkcje 
          biblioteki standardowej posiadają w sobie pewne założenia, które
          niestety nie sprawdzają się przy obecnym sposobie przechowywania
          haseł w systemie. Więc zatem w jaki sposób obecne dystrybucje
          dokonuja uwierzytelniania? Wykorzystują on do tego 
          <strong>podsystem PAM</strong>.
        </p>
        <h2 id="7.10.pamsystem">7.10. System PAM</h2>
        <p>
          System PAM (ang. <em>Pluggable Authentication Modules</em>) jest to
          zbiór bibliotek współdzielonych, których zadaniem jest udostępnienie
          uwierzytelniania użytkownika, w taki sposób aby aplikacja nie
          musiała się tym zajmować. System PAM może również kontrolować
          autoryzację użytkownika np. blokując mu dostęp do pewnych usług. Jak
          sama nazwa wskazuje system ten wykorzystuje dynamicznie ładowane
          moduły, które realizują poszczególne zadania w zależności od użytej
          funkcji (o tym za chwilę). Jeśli system ma sprawdzić hasło
          użytkownika użyje modułu <em>pam_unix.so</em>. Ze względu te 
          informacje dość łatwym zdaniem jest stworzenie dodatkowych modułów
          obsługujących uwierzytelniania dwuskładnikowe lub klucze fizyczne,
          mimo to system PAM dalej pozostaje spuścizną Uniksa przez co,
          niektóre zagadnienia bywają skomplikowane a intefejs programowania
          nie jest zbyt prosty. To z tego systemu korzysta większość aplikacji
          wymagających uwierzytelniania na dystrybucjach Linuksa, ponieważ 
          połączenie aplikacji z PAM wymaga niewiele pracy lub wcale.
        </p>
        <h3 id="7.10.1.pamconfig">7.10.1. Konfiguracja PAM</h3>
        <p>
          Ze względu na to, iż konfiguracja różni się w zależności od
          dystrybucji, cieżko jest się odnaleźć i wyjaśnić to w ogólny sposób.
          pliki konfiguracyjne systemu powinny znajdować się w katalogu 
          <em>/etc/pam.d/</em>. Ich nazwy często zawierają nazwy komponentów
          systemu, które wykorzystują system PAM. Najprostszym z nich jest
          plik <em>/etc/pam.c/chsh</em>. Polecenie <em>chsh</em> służy do
          zmiany powłowki. Pierwszy wiersz pliku wygląda następująco:
        </p>
<pre class="code-block">
auth  requisite pam_shell.so
</pre>
        <p>
          Nakłada on wymóg, aby podana podczas zmiany powłoka była wymieniona
          w pliku <em>/etc/shells</em>, w przeciwym wypadku uwierzytelnienie
          użytkownika kończy się nie powodzeniem.
        </p>
        <p>
          Każda linia konfiguracji PAM składa się z co najmniej trzech części.
          Między innymi z:
        </p>
        <ul>
          <li><strong>Typu funkcji</strong>, które aplikacja żąda od systemu PAM
            w tym przypadku jest to <code class="code-inline">auth</code>
            powodujący uwierzytelnienie użytkownika.</li>
          <li><strong>Argumentu kontrolnego</strong>, decydującego o tym jak
            system zareaguje na powodzenie lub niepowodzenie działania
            wykonywanego przez typ funkcji.</li>
          <li><strong>Modułu</strong>, określającego jaka czynność zostanie tak
            naprawdę wykonana. W tym przypadku jest sprawdzenie czy funkcja 
            występuje w pliku <em>/etc/shells</em>.</li>
        </ul>
        <h4>Typy funkcji</h4>
        <p>
          System PAM oferuje aplikacji wykonanie czynności określonej jedną z 
          z poniższych funkcji:
        </p>
        <ul>
          <li><strong>auth</strong> - uwierzytelnienie użytkownika.</li>
          <li><strong>account</strong> - sprawdzenie status (czy użytkownik
            jest autoryzowany do wykonania pewnej czynności).</li>
          <li><strong>session</strong> - wykonanie jakieś czynność na bierzącej
            sesji użytkownika.</li>
          <li><strong>password</strong> - zmiana danych uwierzytelniania.</li> 
        </ul>
        <p>
          Warto wspomnieć, że moduły mogą zachować się inaczej (wykonywać inną
          czynność, gdy zestawimy je z innymi funkcjami. Dla przykładu moduł
          <em>pan_unix.so</em> dla modułu <em>auth</em> sprawdzi poprawność
          podanego hasła, natomiast dla funkcji <em>password</em> ustawi je
          użytkownikowi. Dlatego też funkcję i moduł podczas konfiguracji
          PAM należy traktować jako parę.
        </p>
        <h4>Argumenty kontrolne</h4>
        <p>
          Inną częścią, wartą omówienie są argumenty kontrolne. Są one 
          stosowane ze względu na to, iż wiersz zapisane w konfiguracji są 
          zestawiane, co oznacza, że nie zawsze status (powodzenie,
          niepowodzenie) jednego 
          wiersza może oznaczać zwrócenie do aplikacji informacji o
          powodzeniu lub niepowodzeniu funkcji przez nią żądanej. Inną kwestią 
          jest rozszerzona składnia
          argumentów kontolnych dopuszająca inne wartości niż tylko prawda
          czy fałsz. Więcej na ten temat znajduje się na stronie podręcznika
          pliku <em>pam.conf</em>. Poniżej znajdują się arguementy kontrolne
          o prostej składni.
        </p>
        <ul>
          <li><strong>sufficient</strong>. Jeśli reguła opatrzona tym 
            argumentem powiedzie się, zbędne staje się sprawdzanie pozostałych
            reguł, system PAM nie musi tego robić. Jeśli się niepowiedzie to
            system przechodzi do kolejnej reguły.</li>
          <li><strong>requisite</strong>. Jeśli reguła z tym argumentem
            niepowiedzie się to wówczas całe uwierzytelnianie kończy się
            niepowodzeniem. Jeśli reguła powiedzie się, to system przechodzi do
            sprawdzenia pozostałych reguł, oczywiście jeśli zostały 
            zdefiniowane.
          </li>
          <li><strong>required</strong>. Jeśli reguła powiedzie się to system
            przechodzi do kolejnych reguł. Jeśli nie to system i tak sprawdzi
            pozostałe dostępne reguły jednak jedyną zwracaną infomacją bedzie
            niepowodzienie bez znaczenia czy następujące po <em>required</em>
            reguły sie powiodły lub nie.</li>
        </ul>
        <p>
          Znając składnię reguł systemu PAM, możemy spóbować samodzielnie
          przeanalizować drugą linię znajdującą się w pliku <em>chsh</em> w
          katalogu <em>/etc/pam.d</em>.
        </p>
<pre class="code-block">
auth  sufficient  pam_rootok.so
</pre>
        <p>
          Pamiętając o tym, że typ funkcji oraz moduł należy taktować jako
          parę. Skupimy się na początku na argumencie kontrolonym. Otóż jeśli
          ta reguła zakończy się powodzeniem system PAM nie będzie dalej
          sprawdzać reguł. Natomiast funkcja (wraz z modułem) mają za zadanie
          ustalenie czy to superużytkownik próbuje się uwierzytelnić.
        </p>
        <p>
          Zwrócićmy uwagę na to, iż mimo tego co poznaliśmy konfigrację PAM
          oraz przeanalizowaliśmy skonstruowany plik konfiguracyjny dla 
          <em>chsh</em>, to 
          <em>root</em> nadal może ustawić dowolną powłokę. Wynika to z
          konstrukcji samego narzędzia. W tym przypadku PAM ma działać nad
          uwierzytelnianiem zwykłego użytkownika i jego działań.
        </p>
        <p>
          Moduły w regułach PAM mogą posiadać argumenty i są one umieszczane
          po nazwie modułu, na przykład:
        </p>
<pre class="code-block">
auth  sufficient  pam_unix.so nullok
</pre>
        <p>
          Argument ten pozwala na stosowanie pustego hasła podczas
          uwierzytelnienia.
        </p>
        <h3 id="7.10.3.pamnotices">7.10.3. Uwagi dotyczące PAM</h3>
        <p>
          Ze względu na to, iż wiekszość mechanizmów opisanych w tym materiale
          zostało przedstawionych pobierznie, przecież to podstawy. To poniżej
          znajduje się kilka wskazówek odnośnie systemu PAM.
        </p>
        <ul>
          <li>Lista dostępnych w systemie modułów możemy wyświetlić za pomocą
            polecenia 
<pre class="code-block">
$ man -k pam_
</pre>
            Jeśli potrzebujemy znać lokalizację modułów PAM, wówczas możemy
            spróbowac użyć polecenia <em>locate</em> podając nazwę modułu
            jako argument polecenia.</li>
          <li>Strony podręcznika zawierają opis funkcji i argumentów dla
            każdego modułu.</li>
          <li>W wielu dystrybucjach pliki konfiguracji systemu PAM są
            generowane automatycznie, wiec ich modyfikacja może nie być
            najlepszym pomysłem. Przed wprowadzeniem zmian warto zapoznać
            się z umieszczonymi w tych plikach komentarzami.</li>
          <li>Plik <em>/etc/pam.d/other</em> definiuje konfigurację dla
            aplikacji, które nie posiadają własnego pliku. Zazwyczaj
            wszystko tam jest blokowane.</li>
          <li>Istnieje możliwość dołączenia dodatkowych plików konfiguracjnych.
            Za pomocą dyrektywy <em>@include</em> możemy załadować cały
            dodatkowy plik, ale za pomocą specjalnego argumentu kontrolnego
            możemy załadować plik konfiguracjny dla określonej funkcji. Te
            sposoby są określne przez dystrybucje.</li>
          <li>Definicja reguł systemu PAM nie kończy się na argumentach 
            modułów. Moduły mogą uzyskiwać dostęp do plików w katalogu
            <em>/etc/security</em>, które głownie mają na celu ograniczanie
            uprawnień użytkownikom.</li>
        </ul>
        <h3 id="7.10.3.pamandpasswords">7.10.3. System PAM i hasła</h3>
        <p>
          System PAM możemy wykorzystać do uzyskiwania informacji na temat
          haseł w systemie. Wykorzystanie modułu <em>pam_unix.so</em> wraz
          z funkcją <em>auth</em> powoduje sprawdzenie hasła. Natomiast
          jeśli użyjemy tego modułu wraz z funkcją <em>password</em> moduł
          ustawi podane przez uzytkownika hasło. Wyszukując odpowiednią 
          regułę możemy dowiedzieć się na przykład jakiego algorytmu użyto
          do tworzenia skrótu hasła. Do odnalezienia tej linii posłużymy się
          poniższym poleceniem. 
        </p>
<pre class="code-block">
xf0r3m@immudex:/ic0$ grep password.*unix /etc/pam.d/*
/etc/pam.d/common-password:# used to change user passwords.  The default is pam_unix.
/etc/pam.d/common-password:password	[success=1 default=ignore]	pam_unix.so obscure yescrypt
</pre>
        <p>
          W drugiej linii znajduje się poszukiwana przez nas 
          reguła. Skupmy się tylko na argumentach modułu. Otóż argument
          <code class="code-inline">obscure</code>, najprościej rzecz ujmując
          powoduje on sprawdzenie czy podane hasło jest wystarczająco 
          "przesłonięte" (nie jest zbliżone do obecnie używanego). Kolejny
          argument to algorytm szyfrowania w tym przypadku jest to
          nowy algorytm <code class="code-inline">yescrypt</code>, do Debiana
          został on wdrożony wraz z wypuszeniem wersji 11 "Bullseye".
        </p>
        <p>
          No dobrze, w przypadku ustawiania hasła mamy jawnie podany algorytm.
          A co w przypadku gdy moduł PAM musi sprawdzić czy podane hasło jest
          poprawne. Niestety w tym przypadku PAM próbuje odgadnąć algorytm
          wykorzystując do tego bibliotekę libcrypt, ktora wypróbowuje
          wszystkie dostępne możliwości do momentu aż coś zadziała lub
          nie pozostanie nic sprawdzenia.
        </p>
        <h1 id="processandresourcemonitoring">8. Procesy oraz monitorowania zasobów</h1>
        <p>
          Jeśli pamiętamy definicję procesu, to wiem że proces to nic innego
          jak wystąpienie uruchomionego programu. Każdy proces aby mógł
          wykonać swoje zadanie potrzebuje zasobów sprzetowych naszych 
          komputerów oferowanych przez system operacyjny. Jądro odpowiada
          za sprawiedliwy przydział zasobów systemowych. Samo jądro również
          może mieć być zasobem - zasobem programowym wykorzystywanym przez
          procesy do uzyskiwania dostępu do plików czy do urządzeń
          wejścia-wyjścia.  
        </p>
        <p>
          W tym rozdziale objaśnimy sobie nieco bardziej procesy oraz zajmiemy
          się monitorowaniem zasobów. Jednak nie po to aby optymalizować
          system, ponieważ ten na domyślnych ustawieniach dystrybucji działa 
          całkiem dobrze i nie potrzeba nic zmieniać. Zajmiemy się 
          natomiast monitorowaniem zasobów by lepiej zrozumieć co jest 
          dokładnie mierzone, dzięki czemu przybliżymy sobie, nie które
          działania jądra.
        </p>
        <h2 id="8.1.processtraking">8.1. Śledzenie procesów</h2>
        <p>
          Procesy możemy śledzić za pomocą polecenia <strong>ps</strong> i
          w zależności od użytych przełączników możemy uzyskać różne 
          rezultaty działania tego polecenia. Osobiście polecam
          kombinację trzech przełączników <strong>-aux</strong>. Poza tym
          to polecenie posiada trzy rózne możliwości wprowadzania do niego
          opcji. Ja skupie się na jednym myślniku i łączeniu razem opcji. 
          Inną godną polecenia kombinacją opcji jest <strong>-elf</strong>
          te opcje zwracaną najważniesze dla nas informacje, na przykład
          jak wartość priorytetu oraz wartość <em>nice</em>, które biorą
          udział w szeregowaniu procesów do wykoniania. Dlaczego polecam tę
          pierwszą kombinacją, ponieważ najczęściej do zarządzania jakimś
          procesami będzie nam potrzebny PID, właściciel procesu, z jakiego
          polecania proces pochodzi lub procentowe wartości zużycia pamięci
          czy procsora.
        </p>
        <p>
          Innym przydatnym narzędziem dla śledzenia procesów jest polecenie
          <strong>top</strong>. Ponieważ informacje wyświetlane przez to
          polecenie są odświerzane co 1 sekundę dając aktualy obraz tego co
          się aktualnie dzieje w systemie. Po uruchomieniu tego programu na
          same górze listy procesów znajdują się najbardziej aktywne z nich.
          Podczas działania programu, może przekazywać do niego opcje za
          pomocą naciśniecia odpowiedniego klawisza. Poniżej znajduje się
          kilka opisanych klawiszy.
        </p>
        <ul>
          <li><strong>Spacja</strong> - natychmiastowe odświerzania ekranu.</li>
          <li><strong>Shift + m</strong> - sortuje procesy pod względem
            zajętości pamięci.</li>
          <li><strong>Shift + t</strong> - sortuje procesy pod względem
            całkowitego zużycia czasu procesora.</li>
          <li><strong>Shift + p</strong> - sortuje procesy pod względem
            aktualnego zużycia czasu procesora. Użycie tego polecenia
            przywraca domyślne ustawienia.</li>
          <li><strong>u</strong> - wyświetla tylko dane procesów 
            użytkownika.<li>
          <li><strong>f</strong> - umożliwia wybranie różnych statystyk do
            wyświetlenia.</li>
          <li><strong>?</strong> - wyświetla informacje o opcjach programu
            <em>top></em>.</li>
        </ul>
        <p>
          W dystrybucjach Linuksa dostępne są różne odmiany polecenia
          <em>top</em>, takie jak <strong>htop</strong> lub <em>atop</em>.
          Polecenie <em>htop</em> jest znacznie bardziej rozbudowane, a
          jego interaktywna konfiguracja pozwala nie tylko na zmianę
          wyświetlanych danych, ale również zmianę tematu wyświetlania
          (kolorów). Za pomocą <em>htop</em> możemy monitorować stan baterii.
          Po za tym polecenie to posiada, nie które możliwości innego
          przydatnego polecenia jakim jest <em>lsof</em>.
        </p>
        <h2 id="8.2.lsof">8.2. Wyszukiwanie otwartych plików z pomocą polecenia lsof</h2>
        <p>
          Polecenie lsof może być bardzo przydatne ponieważ pozwala wyświetlić
          listę otwartych przez różnego rodzaju procesy. Co może okazać się
          przydatne przypadku gdy chcemy odmontować jakiś system plików, ale
          otrzymujemy informacje o tym że <em>target is busy</em>. Te komunikat
          może być spowowany tym, że w systemie istnieją jeszcze procesy 
          działające na plikach znajdujących się na odmontowywanym systemie
          plików. Poza tym polecenie to generuje masę danych ze względu na
          to, w systemach uniksopodobnych wszystko jest plikiem, a więc 
          nie otrzymamy informacji tylko i wyłącznie o konwencjonalnych
          plikach, ale również o gnizdkach czy nazwanych potokach. Poniżej
          znajduje się linia z otwartym plikiem podczas pisania tego tekstu. 
        </p>
<pre class="code-block">
COMMAND    PID   USER   FD      TYPE             DEVICE SIZE/OFF       NODE NAME
vim.gtk3  3645 xf0r3m    7u      REG              254,0    20480    8391246 /media/xf0r3m/immudex_crypt0/Repos/morketsmerke-dev/articles/terminallog/.Linux.Podstawy.html.swp
</pre>
        <p>
          Linia przedstawia otwarty plik z materiałem w trakcie redagowania.
          Zwróćmy uwagę na nazwę pliku. Wygląda na to, że edytor <em>Vim</em>
          ładuję zawartość pożądanego przez nas pliku do pliku bufora
          (rozszenienie .swp). W momencie zapisu otwiera właściwym pliku,
          zapisuje dane poczym go zamyka. Edytor ten jest znany z tej metody
          obsługi plików. Dzięki temu w przypadku nagłego wyłącznia komputera,
          dane wciąż pozostają w pliku bufora. Nawet w przypadku, kiedy
          będziemy otwierać ten plik to edytor zauważy pozostawiony plik
          bufora, który o opuszczeniu edytora powinien zostać usunięty. Jeśli
          dla otwieranego przez ten edytor istnieje już plik wymiany, wówczas
          edytor zapyta co zrobić z jego zawartościa. 
        </p>
        <p>
          Wracając, linie zwracane przez to polecenie podzielone są na 9 kolumn
          Każda z nich zawiera:
        </p>
        <ul>
          <li><strong>COMMAND</strong> - polecenie / nazwa procesu.</li>
          <li><strong>PID</strong> - identyfikator procesu.</li>
          <li><strong>USER</strong> - użytkownik, który zainicjował proces.</li>
          <li><strong>FD</strong> - deskryptor pliku lub jego przeznaczenie.
            Deskryptor otwartego pliku jest wykorzystywany przez proces przy
            użyciu bibliotek wspódzielonych oraz jądra do identyfikowania
            i manipulowania plikiem. Na przedstawionej linii mamy doczynienia
            z deskryptorem.</li>
          <li><strong>TYPE</strong> - rodzaj otwartego pliku (zwykły plik,
            katalog).</li>
          <li><strong>DEVICE</strong> - główny i poboczny numer urządzenia
            przechowywującego plik.</li>
          <li><strong>SIZE/OFF</strong> - rozmiar pliku.</li>
          <li><strong>NODE</strong> - numer węzła inode.</li>
          <li><strong>NAME</strong> - nazwa pliku / ścieżka do pliku.</li>
        </ul>
        <p>
          Ze względu na przytłaczającą ilość danych zwracanych przez to
          polecenie, możemy uruchomić je na dwa sposóby. Pierwszym z nich
          jest przepuszcznie danych zwracanych przez to polecenie przez jakiś
          filtr, najprostrzym jest chyba polecenie <em>less</em> jednak lepiej
          wyszukać informacji z użyciem wyrażeń regularnych (polecenia
          <em>grep</em>). Drugą metodą jest zawężenie informacji zwracanych
          porzez wykorzystanie dostępnych opcji narzędzia. Najłatwiejszym w
          użyciu jest podanie jako argumentu po prostu ścieżki do katalogu, z
          którego chcemy widzieć otwarte pliki. Na przykład:
        </p>
<pre class="code-block">
COMMAND    PID   USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
pipewire   978 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
dbus-daem  983 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
pipewire-  988 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
xfce4-ses  989 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
at-spi-bu 1042 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
dbus-daem 1047 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
xfconfd   1051 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
...
mpv       2923 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
atrild    3227 xf0r3m  cwd    DIR   0,27      400  638 /home/xf0r3m
</pre>
        <p>
          A jeśli chcelibyśmy się dowiedzieć jakie otawrte pliki posiada
          proces <em>mpv</em>, to możemy na przykład skorzystać z opcji
          <strong>-p</strong> a jako jej argument podać PID procesu
          <em>mpv</em> tak jak przedstawiłem to na przykładzie.
        </p>
<pre class="code-block">
COMMAND  PID   USER   FD      TYPE             DEVICE SIZE/OFF   NODE NAME
mpv     2923 xf0r3m  cwd       DIR               0,27      400    638 /home/xf0r3m
mpv     2923 xf0r3m  rtd       DIR               0,27      200      2 /
mpv     2923 xf0r3m  txt       REG               0,29  2158056   4302 /usr/bin/mpv
mpv     2923 xf0r3m  mem       REG                7,0            4302 /usr/bin/mpv (path dev=0,29)
...
mpv     2923 xf0r3m    5u     IPv4              26738      0t0    TCP 192.168.168.29:34108->prg03s12-in-f14.1e100.net:https (CLOSE_WAIT)
mpv     2923 xf0r3m    6u     IPv4              26743      0t0    TCP 192.168.168.29:34122->prg03s12-in-f14.1e100.net:https (CLOSE_WAIT)
mpv     2923 xf0r3m    7u     IPv4              88390      0t0    TCP 192.168.168.29:38584->prg03s13-in-f14.1e100.net:https (ESTABLISHED)
mpv     2923 xf0r3m    8u     IPv4              86801      0t0    TCP 192.168.168.29:48618->85.162.162.204:https (ESTABLISHED)
mpv     2923 xf0r3m    9u     unix 0x000000006b6ad31e      0t0  26745 type=STREAM
mpv     2923 xf0r3m   10r     FIFO               0,12      0t0  26746 pipe
mpv     2923 xf0r3m   11w     FIFO               0,12      0t0  26746 pipe
mpv     2923 xf0r3m   12u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   13u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   14u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   15u      CHR              226,0      0t0    237 /dev/dri/card0
mpv     2923 xf0r3m   16r     FIFO               0,12      0t0  26079 pipe
mpv     2923 xf0r3m   17w     FIFO               0,12      0t0  26079 pipe
mpv     2923 xf0r3m   18u  a_inode               0,13        0   7971 [eventfd]
mpv     2923 xf0r3m   19u     unix 0x0000000075d44df6      0t0  26081 type=STREAM
mpv     2923 xf0r3m   20u  a_inode               0,13        0   7971 [eventfd]
mpv     2923 xf0r3m   21r     FIFO               0,12      0t0  26082 pipe
mpv     2923 xf0r3m   22w     FIFO               0,12      0t0  26082 pipe
</pre>
        <p>
          Zastanawiające może być, dlaczego <em>mpv</em> korzysta z połączeń
          sieciowych, otóż za pomocą mpv oraz pakietu <em>youtube-dl</em>,
          można korzystać z serwisu YouTube bez nadmiernego obciążenia
          komputera przez nieoptymalną aplikację internetową.
        </p>
        <p>
          Jeśli często aktualizujemy jądro, poza aktualizacją całej dystrybucji
          to należy pamiętać o aktualizacji programu <em>lsof</em>.
          Po aktualizacji jądra oraz programu <em>lsof</em>, może ono nie
          nie działać, dopóki nie uruchomimy nowego jądra.
        </p>
        <h2 id="8.3.tracingprogramexecutionandsystemcalls">8.3. Śledzenie wykonania programów oraz wywołań systemowych</h2>
        <p>
          Zazwyczaj program jeśli się uruchamia i napotka podczas wykonywania
          swoich czynności błąd to zwróci jakąś informację o tym co się
          stało (większość programów uruchomianych na uniksach). Możemy jednak
          napotkać taki przypadek, że uruchomimy program i on odrazu się
          zamknie. Wówczas pojawia się problem w jaki sposób mamy dowiedzieć
          się co jest nie tak z programem czy naszym środowiskiem (czy wszyskie
          wymagane pakiety zostały zainstalowane, na przykład). Rozwiązania,
          które przedstawię w tym podrozdziale na pewno nie są idealne i nie
          sprawdzą się na pewno w przypadku każdego "migającego" programu.
          Nie mniej jednak warto uruchomić dla niego chodziaż jedno z
          zaprezentowanych tutaj poleceń.
        </p>
        <h3 id="8.3.1.stracecommand">8.3. Polecenie strace</h3>
        <p>
          Polecenie <em>strace</em> pozwala na uruchomienie programu wraz ze
          śledzeniem wywołań systemowych (interfejsu jądra, pozwalającego na
          wykonanie wielu czynności systemowych, na przykład otwarcia pliku
          zapisanego gdzieś na systemie plików). Najprostszą poleceniem jakie
          możemy wykonać dla przykładu jest wyświetlenie zawartości jakiegoś
          pliku. Polecenie <em>strace</em> może nie występować we wszystkich
          dystrybucjach, więc będzie trzeba je zainstalować. Z racji tego, iż
          informacji zwracanych przez to polecenie jest na prawdę dużo to 
          poniżej przedstawiłem najważniesze moim zdaniem linie:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ strace cat yt-links
execve("/usr/bin/cat", ["cat", "yt-links"], 0x7ffc8ee949b8 /* 39 vars */) = 0
brk(NULL)                               = 0x564490232000
access("/etc/ld.so.preload", R_OK)      = -1 ENOENT (Nie ma takiego pliku ani katalogu)
openat(AT_FDCWD, "/etc/ld.so.cache", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=105669, ...}) = 0
mmap(NULL, 105669, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2f770de000
close(3)                                = 0
openat(AT_FDCWD, "/lib/x86_64-linux-gnu/libc.so.6", O_RDONLY|O_CLOEXEC) = 3
read(3, "\177ELF\2\1\1\3\0\0\0\0\0\0\0\0\3\0&gt;\0\1\0\0\0@&gt;\2\0\0\0\0\0"..., 832) = 832
fstat(3, {st_mode=S_IFREG|0755, st_size=1905632, ...}) = 0
mmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2f770dc000
mmap(NULL, 1918592, PROT_READ, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f2f76f07000
mmap(0x7f2f76f29000, 1417216, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x22000) = 0x7f2f76f29000
mmap(0x7f2f77083000, 323584, PROT_READ, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17c000) = 0x7f2f77083000
mmap(0x7f2f770d2000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1ca000) = 0x7f2f770d2000
mmap(0x7f2f770d8000, 13952, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f2f770d8000
close(3)                                = 0
arch_prctl(ARCH_SET_FS, 0x7f2f770dd580) = 0
mprotect(0x7f2f770d2000, 16384, PROT_READ) = 0
mprotect(0x56448ed5a000, 4096, PROT_READ) = 0
mprotect(0x7f2f77122000, 4096, PROT_READ) = 0
munmap(0x7f2f770de000, 105669)          = 0
brk(NULL)                               = 0x564490232000
brk(0x564490253000)                     = 0x564490253000
openat(AT_FDCWD, "/usr/lib/locale/locale-archive", O_RDONLY|O_CLOEXEC) = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=3041312, ...}) = 0
mmap(NULL, 3041312, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f2f76c20000
close(3)                                = 0
fstat(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(0x88, 0), ...}) = 0
openat(AT_FDCWD, "yt-links", O_RDONLY)  = 3
fstat(3, {st_mode=S_IFREG|0644, st_size=512, ...}) = 0
fadvise64(3, 0, 0, POSIX_FADV_SEQUENTIAL) = 0
mmap(NULL, 139264, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f2f76bfe000
read(3, "lofi girl stream: www.youtube.co"..., 131072) = 512
write(1, "lofi girl stream: www.youtube.co"..., 512lofi girl stream: www.youtube.com/watch?v=jfKfPfyJRdk
Stalker czyste niebo: www.youtube.com/playlist?list=PLMnTK-S7An4KqvvXn6AMkE00s_aDNZ29o
Stalker zew prypeci: www.youtube.com/playlist?list=PLMnTK-S7An4K8BMXzFCVA0Y8KLSSHRfwV
MysteryTV CP S03: www.youtube.com/playlist?list=PLjkTsi__dtwWJm4gUqaFLBva0k1TljXcn
MysteryTC CP S04: www.youtube.com/playlist?list=PLjkTsi__dtwWR247M06TZ_2FxccG91f1u
Tu skończyłem: https://www.youtube.com/watch?v=wnY3cTAujMc

Iceberg o stalkerze: www.youtube.com/watch?v=uMHvO7LXVz8
) = 512
read(3, "", 131072)                     = 0
munmap(0x7f2f76bfe000, 139264)          = 0
close(3)                                = 0
close(1)                                = 0
close(2)                                = 0
exit_group(0)                           = ?
+++ exited with 0 +++
</pre>
        <p>
          Polecenie <code class="code-inline">strace</code> wykorzystuje
          wyołanie systemowe <em>fork()</em> aby utworzyć kopię swojego procesu
          następnie ta kopia jest zastępowana przez wywołanie systemowe
          <code class="code-inline">execve()</code>, które uruchamia
          zadany przez nas proces, w tym przypadku jest wyświetlenie
          zawartości pliku <code class="code-inline">yt-links</code>, po
          zinicjowaniu pamięci oraz odpytaniu się bibliotek
          (pominięto to na przykładzie) proces <em>cat</em> chcę otworzyć
          plik za pomocą wywołania systemowego
          <code class="code-inline">openat</code>, jeśli otwarcie pliku
          się powiedzie, otwartemu plikowi zostanie nadany pierwszy wolny
          deskryptor, najczęsiej będzie to <code class="code-inline">3</code>,
          co zostało przedstawione na przykładzie. Jeśli samodzielnie będziemy
          uruchamiać podobne polecenie (nie każdy w swoim systemie posiada,
          pliki <em>yt-links</em>), to zauważym że ten deskrytor jest
          przypisywany i zwalniany kilkukrotnie podczas wykonywania czynności
          Przed pobraniem zawartości pliku, pobierane są jego atrybuty za
          pomocą wywołanie <code class="code-inline">fstat()</code> oraz 
          alokowana jest pamięci operacyjna 
          (<code class="code-inline">mmap</code>) i wówczas następuje wywołanie
          systemowe <code class="code-inline">read()</code>, które pobiera
          zawartości pliku. Następne wywołanie systemowe odpowiedzialne jest
          za wypisanie zawartości, do deskryptora o numerze
          <code class="code-inline">1</code>. Jak pamiętamy polecenie 
          <em>cat</em> to wypisuje albo podaną jako argument ścieżkę do pliku,
          albo podane dane z standardowego wejścia na standardowe wyjście. A
          więc numer standardowego wyjścia, którym jest <strong>1</strong> jest
          deskryptorem otwartego pliku. Dlatego też wywołanie systemowe
          <code class="code-inline">write()</code> odwołuje się do
          deskryptora o numerze <code class="code-inline">1</code>. Następnie
          pamięć oraz wykorzystywane deskrytory zostają zwolnione i w ten
          sposób kończy się wykonanie procesu polecenia <em>cat</em>.
        </p>
        <p>
          Czytając ten obszerny opis możemy przyjrzeć się jak działają programy
          na uniksach. Nie mniej jednak polecenie <em>strace</em> może pomóc
          nam przy, nie których problemach z programami. Często sytuacją,
          w której program może nam "mignąć" jest brak jakiegoś pliku lub
          problem z jego dostępnością. Kiedy analizujemy wykonanie programu
          za pomocą polecenia <em>strace</em> to należy szczególną uwagę
          zwrócić na wywołania systemowe <em>openat()</em> Poniżej znajdują się
          dwa przykładowe komunikaty:
        </p>
<pre class="code-block">
openat(AT_FDCWD, "test.txt", O_RDONLY)  = -1 ENOENT (Nie ma takiego pliku ani katalogu)
openat(AT_FDCWD, "/etc/shadow", O_RDONLY) = -1 EACCES (Brak dostępu)
</pre>
        <p>
          W przypadku błędu, zazwyczaj otrzymujemy deskryptor o numerze
          <em>-1</em>, jednak zwróćmy uwagę na komunikaty błedów różnia się od
          siebie (<code class="code-inline">ENOENT</code> a 
          <code class="code-inline">EACCES</code>).
        </p>
        <h3 id="8.3.2.ltracecommand">8.3.2. Polecenie ltrace</h3>
        <p>
          Podobnym do <em>strace</em> narzędziem jest <strong>ltrace</strong>.
          Jednak zamiast wywołań systemowych śledzi on wywołania bibliotek
          wspóldzielnonych, dane wyjściowe tego programu są zbliżone do 
          <em>strace</em>. Program <em>ltrace</em> nie śledzi niczego na
          poziomie jądra, to jednak warto mieć na uwadzę fakt, iż programy
          o wiele częściej korzystają z bibliotek wspódzielonych niż z 
          wywołań systemowych. Polecenie <em>ltrace</em> nie zadziała w
          przypadku bibliotego dołączonych statycznie. A jego dane wyjściowe
          możemy odfiltrować za pomocą opcji polecenia, których opis dostępny
          jest na stronie podręcznika.
        </p>
        <h2 id="8.4.threads">8.4. Wątki</h2>
        <p>
          Procesy mogą dzielić się na podobne byty zwane 
          <strong>wątkami</strong>. Wątki w pewnym sensie są podobne do
          procesów, również zawierają identyfikator zwany <strong>TID</strong>
          (ang. <em>Thread IDentifier</em>). Podobnie jak program może mieć
          kilka procesów, odpowiadających wykonywanym przez niego czynnością,
          to wątki mogą być efektem podziału czynności procesu na jeszcze
          mniejsze części. W przypadku komputerów metoda rozwiązywania 
          problemów "dziel i rządź", będzie miała zastosowanie jeszcze
          nie jednokrotnie.
        </p>
        <h3 id="8.4.1.oneormultithreadprocess">8.4.1. Procesy jedno oraz wielowątkowe</h3>
        <p>
          Część procesów uruchamianych w systemie zawiera tylko jeden wątek.
          Wówczas taki proces jest procesem jednowątkowym. Na początku, każdy
          proces posiada jeden wątek, zwany <strong>wątkiem głównym</strong>.
          Wątek główny może tworzyć kolejne wątki, zmieniając ten proces tym
          samym w proces wielowątkowy.
        </p>
        <p>
          Podstawową zaletą procesów wielowątkowych jest fakt wykonania 
          zaplanowanych w procesie czynności o wiele szybciej, gdyż każdy
          wątek może być wykonywany przez jeden procesor (wątek procesora,
          tak rdzenie procesorów też mogą zawierać w sobie wątki, przeważnie
          na jeden rdzeń przypadają dwa wątki). Innym cechą wątków jest to
          iż wykorzystują one wspólne obszary pamięci, (nie tak jak w
          przypadku procesów, gdzie procesy nie mają dostępu do obszaru
          pamięci innych procesów) usprawniając tym samy komunikację miedzy
          wątkami. Wątki najczęsciej wykorzystywane są do obsługi operacji
          wejscia-wyjścia. Użycie w tym przypadku wątków zamiast procesów 
          pozwala nam zaoszczędzić trochę czasu procesora.
        </p>
        <h3 id="8.4.2.displaingthreads">8.4.2. Wyświetlanie wątków.</h3>
        <p>
          Pozanane do tej pory narzędzia służące do obserowania procesów
          również sprawdzą się gdy będzie chcieli wyświetlić informacje
          na temat wątków. W przypadku polecenie <em>ps</em> wystarczy dodać
          do polecenia opcję <strong>m</strong>, warto jednak zaznaczyć by 
          nie mieszać opcji <em>m</em> wraz z opcją <em>u</em>. Na poniższym
          przykładzie wyświetliłem moje procesy uruchomione w terminalach.
        </p>
<pre class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ ps -am -opid,tid,time,cmd
    PID     TID     TIME CMD
   1799       - 00:00:02 /usr/bin/python3 -O /usr/bin/ranger
      -    1799 00:00:02 -
   7507       - 00:00:00 /bin/sh -c set -- '/ic0/Repos/morketsmerke-dev/articles/terminallog/Linux.P
      -    7507 00:00:00 -
   7508       - 00:00:00 /bin/sh /usr/bin/sensible-editor -- /ic0/Repos/morketsmerke-dev/articles/te
      -    7508 00:00:00 -
   7512       - 00:00:05 /usr/bin/vim.gtk3 -- /ic0/Repos/morketsmerke-dev/articles/terminallog/Linux
      -    7512 00:00:05 -
  12070       - 00:00:00 ps -am -opid,tid,time,cmd
      -   12070 00:00:00 -
</pre>
        <p>
          Zwróćmy uwagę na to numery PID oraz TID są takie same. W przypadku
          poleceń jednowątkowych, wątek główny posiada takim sam TID jak
          proces macierzysty. Jeśli pojawiłby się procesy, wkorzystujące 
          wątki, to wówczas TIDy wynośiły by kolejne numery rozpoczynając od
          PID-u lub TID-u wątku głównego.
        </p>
        <p>
          Jeśli preferujemy narzędzie <em>top</em> to wówczas użycie kombinacji
          klawiszy <em>Śhift + h</em> pozwoli nam na wyświetlenie wątków.
          Możemy je rozpoznać po tym, że wyświetlone tam "procesy" są
          uruchomione z tego samego polecenia i posiadają następujące po sobie
          identyfikatory.
        </p>
        <p>
          Wątki w tym materiale zostały przedstawione, aby zaprezetować ich
          istnienie i na tym temat się kończy.
        </p>
        <h2 id="8.5.resourcemonitoring">8.5. Monitorowanie zasobów</h2>w
        <p>
          Monitorowanie zasobów komputerów przeprowadza się głównie, aby 
          dowiedzieć się, które z komponentów systemów lub komputerów należy
          z optymalizować, aby nasza praca była jescze bardziej wydajna, abyśmy
          mogli zrobić coś lepiej, szybciej oraz niższym nakładem pracy. Jak
          już wspomniałem jądro Linuksa jest bardzo wydajne przy domyślnych
          ustawieniach i nie trzeba się tym przejmować. Dlatego też
          wykorzystamy monitorowanie zasobów czasu procesora, pamięci
          operacyjnej oraz operacji wejścia-wyjścia do sprawdzenia w jaki
          sposób dzieli je między procesami.
        </p>
        <h2 id="8.6.measuringprocessorusage">8.6. Pomiar czasu procesora</h2>
        <p>
          Do monitorowania w czasie rzeczywistym pojedynczych procesów możemy
          wykorzystać polecenie <em>top</em> wraz z opcją <strong>-p</strong>.
          Jako argumenty opcji podajemy listę identyfikatorów procesów.
        </p>
<pre class="code-block">
$ top -p 3329,1230
</pre>
        <p>
          Wówczas polecenie <em>top</em> pokaże na swojej liście tylko te dwa
          procesy.
        </p>
        <p>
          Aby dowiedzieć się ile czasu procesora w trakcie swojego działania
          wykorzystało konkretne polecenie, to należy je uruchomić za pomocą
          polecenia <strong>time</strong>, jednak tu musimy się na chwilę
          zatrzymać gdyż przeważnie w większości dystrybucji istnieją dwa
          polecenia <em>time</em>. Jedno jest polecenie wbudowanym w powłokę
          i nie ma z niego za bardzo pożytku. Dla przykładu poniżej umieszczam
          pomiar czasu procesora wbudowanym w powłokę polecenie <em>time</em>:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ time ls
...
real	0m0,007s
user	0m0,001s
sys	  0m0,007s
</pre>
        <p>
          Z kolei dostęp do właściwego polecenie uzyskamy uruchamiając
          konkretny plik: <strong>/usr/bin/time</strong>, jednak twórcy
          wiodących dystrybucji uznają, że polecenie wbudowane w powłokę
          wystarczy, dlatego też prawdopodbne jest, że omawiany przez nas
          program nie będzie domyślnie zainstalowany w naszym systemie. 
          Poniżej znajduje się to samo polecenie wykonane za pomocą właściwego
          programu.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ /usr/bin/time ls
...
0.00user 0.00system 0:00.00elapsed 100%CPU (0avgtext+0avgdata 2516maxresident)k
0inputs+0outputs (0major+123minor)pagefaults 0swaps
</pre>
        <p>
          To polecenie zwraca znacznie więcej informacji na temat wykonanego
          polecenia. Na tym etapie będą interesować trzy pierwsze wartości:
          <code class="code-inline">0.00user 0.00system 0:00.00elapsed</code>.
          Wskazują one kolejno: 
        </p>
        <ul>
          <li><strong>Czas użytkownika</strong>
            (<code class="code-inline">0.00user</code>) - liczba sekund
            poświęcona przez procesor na wykonanie właściwego kodu programu.
            Przy obecnej mocy obliczeniowej komputerów czas wykonania prosty
            czynności jest natyle krótki, że program zaokrągla go do zera.</li>
          <li><strong>Czas systemowy</strong>
            (<code class="code-inline">0.00system</code>) - czas poświęcony
            przez jądro na obsługę procesu (na przykład, odczyt zawartości
            plików lub katalogów).</li>
          <li><strong>Czas trwania</strong>
            (<code class="code-inline">0.00elapsed</code>) - całkowity czas
            działania procesu od początku do końca jego życia, wraz ze
            wszystkimi dodatkowymi czynnościami. Czas ten nie jest szczególnie
            brany pod uwagę podczas pomiarów wydajności, ale odjęcie sumy
            czasu użytkownika oraz czasu systemowego od tej wartości przedstawi
            czas oczekiwania na zasoby.</li>
        </ul>
        <p>
          Pozostałe wartości zwracane przez to polecenie dotyczą pamięci,
          operacji wejścia-wyjścia oraz stronicowania (do stronicowania jeszcze
          wrócimy w tym rozdziale).
        </p>
        <h2 id="8.7.processprioritization">8.7. Priorytetyzacja procesów</h2>
        <p>
          W pierwszym rodziale poruszyliśmy temat zarządzania protetami przez
          jądro, dowiedzielśmy się, że każdy proces otrzymuje dostęp do
          procesora na ułamek sekundy. Modułem odpowiedzialnym za to, który
          z procesów uzyska w chwili obecnej dostęp do procesora jest
          <strong>program szeregujący</strong>, który na podstawie
          <strong>priorytetu</strong> procesu może przydzielć mu więcej lub
          mniej czasu. W dystrybucja Linuksa priorytety funkcji przedstawiane
          są dwojako. Polecenie <em>top</em> przestawia domyślny priorytet
          wartością <strong>20</strong> (kolumna PR), jeśli jednak wywołamy 
          polecenie
          <em>ps</em> z opcjami <em>-elf</em> (ta sama kolumna), to domyślnym 
          priorytetem będzie
          <strong>80</strong>. My na tym etapie będziemy trzymać się raczej
          wartosci przedstawianych przez polecenie <em>top</em>, ponieważ
          łatwiej będzie nam je zrozumieć. Więc domyślnym priorytem jest
          <em>20</em>, poniżej przedstawiam kilka procesów wyświetlonych przez
          narzędzie <em>top</em>:
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ top

top - 09:32:04 up  1:55,  1 user,  load average: 0,73, 0,65, 0,61
...
PID UŻYTK.    PR  NI    WIRT    REZ    WSP S  %CPU  %PAM     CZAS+ KOMENDA
2364 xf0r3m    20   0 2504764 158992  90048 S   0,3   2,0   0:37.66 Isolated Web Co
2418 xf0r3m    20   0  474048  94468  66272 S   0,3   1,2   1:39.81 xfce4-terminal
4395 root      20   0       0      0      0 I   0,3   0,0   0:01.40 kworker/3:0-events
33705 xf0r3m    20   0   10404   4212   3452 R   0,3   0,1   0:00.36 top 
</pre>
        <p>
          Najniższym priortem w tym przypadku jest działanie w czasie
          rzeczywistym, ale na tym etapie nie będziemy się tym zajmować. Tak
          więc na chwilę obecną najniższym priortetem jest <strong>0</strong>,
          a najwyższym <strong>39</strong>.
        </p>
        <p>
          Do manipulacji priorytetami wartość <strong>nice</strong>
          (kolumna NI), przechowuje ona wartość wpływającą na priorytet
          zwiększając go lub zmieniajszając. Do ustawienia wartości
          <em>nice</em> służy polecenie <strong>renice</strong>. To polecenie
          możemy wykonać bez uprawnień administrator o ile zmniejszamy
          priorytet (podając wysoką wartość <em>nice</em>, która dodawana jest
          do domyślnej wartości priortety), zmniejszenie priorytetu
          (podanie ujemnej wartości <em>nice</em>) wymaga już uprawnień
          superużytkownika. Polecenie to poza nową wartością <em>nice</em>
          wymaga podania PID-u procesu.
        </p>
<pre style="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ pidof top
37426
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ renice 20 37426
37426 (process ID) old priority 0, new priority 19

#lub krócej:

xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ renice 20 $(pidof top) 
37426 (process ID) old priority 0, new priority 19
</pre>
        <p>
          Polecenie <code class="code-inline">pidof</code> pozwala uzyskać
          PID procesu na podstawie polecenia, jeśli uruchomionych jest więcej
          niż jedna instancja danego programu polecenie zwróci listę PID-ów.
          Podczas zmiany priorytetu mimo, iż podaliśmy wartość 20 to
          największą wartością <em>nice</em> jest 19 tak samo jest w drugą
          stronę. Najmniejszą wartością <em>nice</em> (a zatem proces będzie
          mieć największy priortet) jest <em>-19</em>.
        </p>
        <p>
          Priortety i manipulacja nimi miała dużo większe znaczenie w czasch
          gdy z jednego systemu korzystało wielużytkowników. Obecnie maja one
          mniejsze znaczenie. Warto też dodać, aby nie wymuszać wysokich
          priortetów, gdyż mogą one zablokować istotne dla funkcjonowania
          systemu procesy i go zdestabilizować.
        </p>
        <h2 id="8.8.loadaverages">8.8. Średnie obciążenia</h2>
        <p>
          <strong>Średnie obciążenia</strong> jest to o szaczowana liczba
          procesów do uruchomienia. Ten parametr określa ilość procesów
          gotowych w każdej chwili użyć procesora. Jak pamiętamy nie wszystkie
          procesy są gotowe do działania, część z nich czeka na dane. Średnie
          obciążenia są wyświetlane przez polecenie <strong>uptime</strong>. 
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ uptime
 10:40:15 up  3:03,  1 user,  load average: 1,14, 0,99, 1,17
</pre>
        <p>
          Wartości przedstawione obok etykiety
          <code class="code-inline">load average</code> przedstawiaja średnie
          obciążenia z minuty, 5 i 15 minut. Na powszszym przykładzie widzimy
          że ciągu ostatniej minuty z użyto na wykonanie procesów użytkownika
          114% procent procesora. Jeśli obiążenia tak jak na przykładzie stale
          utrzymują się powyżej 1, to oznacza to, że jeden proces cały czas
          wykorzystuje jeden rdzeń procesora. Pełne obiążenie komputera w
          przypadku tego wskaźnika będzie oscylować w granicach ilości
          rdzeni/wątków procesora zamontowanego w naszym komputerze.
        </p>
        <p>
          Wysokie średnie obiążenia mogą wynikać nie tylko z działania w
          systemie procesów ale również ze zwględu na pozostałą nie wielką
          ilość pamięci dostępnej w systemie. Wówczas jądro może zarządzić
          <strong>proces przeładowania</strong> (ang. <em>trashing</em>), 
          powoduje to szybkie
          przenoszenie stron pamięci na dysk oraz z dysku. Gdy ma to miejsce
          ilość procesów gotowych do uruchomienia zwiększa sią powodując
          znacznie zwiększenie średniej obiążenia. Ze względu na małą ilość
          wolnej pamięci system może działać znacznie wolniej i niż zwykle.
        </p>
        <h2 id="8.9.operating memory">8.9. Pamięc</h2>
        <p>
          Pamięć operacyjna jest bardzo ważnym komponentem komputera, jeśli
          chodzi o maszyny uniksowe. W pamięci rezydują obszary, w których
          procesy przechowują swoje dane, a jej ilość jest ograniczona. Do
          monitorowania pamięci możemy posłużyć się takimi narzędziami jak
          polecenie <strong>free</strong> (w przypadku tego polecenia, warto
          przeskalować sobie wartości zwracane za pomocą opcji 
          <strong>-h</strong>) lub skorzystać z interfejsu systemowego
          wyświetlając zawartość pliku <em>/proc/meminfo</em> (tutaj jednak
          jestśmy skazani na wartość wyrażone w kilobajtach). Jeśli pamięć
          podręczna/bufora nie zajmuje dużego obszaru pamięci fizycznej, a
          mimo to nie mamy w zanadrzu wiekszej ilości wolnej pamięci to 
          niezbędne może być dołożenie pamięci do naszego komputera, aby
          poprawić jego wydajność.
        </p>
        <h3 id="8.9.1.memorymanagement">8.9.1. Zarządzenie pamięcią</h3>
        <p>
          Jądro w tym zadaniu opera się na jednosce <strong>MMU</strong>
          (ang. Memory Management Unit), której zadaniem jest zamiana adresów
          pamięci wirtualnej na adresu pamięci fizycznej. Pamięć wirtualna
          jest wykorzystywana przez procesy. Jądro współpracuje
          z MMU dzieląc obszary procesów na mniejsze strony, trzymając w tym
          samym dane służące MMU do odzworowania adresów w strukturze danych
          zwanej <strong>tabelą stron</strong>. W momencie uzyskania przez
          proces dostępu do pamięci jednostka MMU dzięki tej strukturze może
          dokonywać translacji adresów.
        </p>
        <p>
          Procesy zazwyczaj nie wymagają dostępu do pełnego obszaru w pamięci
          od razu. Jądro ładuje wówczas tylko te strony, których proces
          wymaga. Taki rodzaj przydzielania pamięci nazywany jest
          <strong>stronicowaniem na żądanie</strong>.
        </p>
        <p>
          Przydzielenie pamięci nowmy procesowi, możemy zapisać w czterech
          krokach. 
        </p>
        <ol>
          <li>Jądro ładuje do stron pamięci początek kodu programu</li>
          <li>Jeśli zajdzie taka potrzeba jądro może przypisać procesowi kilka
            stron pamięci.</li>
          <li>W trakcie działania procesu, może zajść potrzeba załadowania
            większej ilości kodu, ponieważ następna instrukcja do wykonania
            nie znajduje się na załadowanych początkowo stronach. W takiej
            sytuacji jądro przejmuje kontrolę, ładuje wymagane strony i
            pozwala programowi wznowic działanie.</li>
          <li>Jeśli zajdzie potrzeba przydzielenia więcej pamięci niż
            zakładano na początku, jądro znajduje nieużywane strony, zwalnia
            je i przydziela procesowi.</li>
        </ol>
        <h3 id="8.9.2.pageserrors">8.9.2. Błędy stron</h3>
        <p>
          Nie zawsze wyżej wymienione czynności da się spiąć w czasie. Jeśli
          żądana przez proces strona w pamięci nie jest jeszcze gotowa to
          generują on <strong>błąd strony</strong>. Gdy taki błąd zostanie
          wygenerowany, to kontrolę nad procesorem przejmuje jądro aby
          załadować żądaną stronę. Błędy dzielą się na podstawowe oraz
          drugorzędne.
        </p>
        <h4>Drugorzędne błedy stron</h4>
        <p>
          Błędy tego typu nię są poważnym błedami, i zdarzają się dość często.
          Ich najczęstszym powodem występowania jest fakt iż MMU nie zna 
          położenia strony z instrukcjami programu. Samo MMU może nie mieć
          odpowiednio dużo miejsca aby przechować adresy wszystkich obszarów.
          W przypadku występowania takiego błędu jądro przekazuje do MMU
          informacje o położeniu strony i pozwala na wznowienie działania
          procesu.
        </p>
        <h4>Podstawowe błędy stron</h4>
        <p>
          Podstawowe błędy występują wówczas gdy strony nie ma w ogóle w
          pamięci. Jądro musi ją załadować z jakiegoś nośnika najczęsciej jest
          to dysk. Duża ilość tego typu błędów może przeciążyć system ponieważ
          procesor jest zajęty przez jądro ładujące kod z niekoniecznie
          szybkich nośników, blokując go tym samym dla innych procesów. 
          Niestety pewna ilość tego typu błedów jest
          nie unikniona, a mają one miejsce kiedy po raz pierwszy uruchamiamy
          jakiś program, wówczas należy załadować kod z dysku. 
        </p>
        <h4>Obserowowanie błędów stron</h4>
        <p>
          Do obserwowania błędów stron przydatne staje się polecenie 
          <strong>time</strong>, o którym wspomniałem przy okazji pomiaru
          czasu procesora. Jednak w tym przypadku będzie interesować nas
          wartość w nawiasie obok napisu 
          <code class="code-inline">pagefaults</code>.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ /usr/bin/time timedatectl
               Local time: nie 2023-01-08 17:59:08 CET
           Universal time: nie 2023-01-08 16:59:08 UTC
                 RTC time: nie 2023-01-08 16:59:08
                Time zone: Europe/Warsaw (CET, +0100)
System clock synchronized: no
              NTP service: n/a
          RTC in local TZ: no
0.00user 0.01system 0:00.10elapsed 24%CPU (0avgtext+0avgdata 7416maxresident)k
522inputs+0outputs (8major+359minor)pagefaults 0swaps
</pre>
        <p>
          W przypadku uruchomienia w moim systemie polecenia
          <code class="code-inline">timedatectl</code> wystąpiły 8 błędów
          podstawowych (<code class="code-inline">8major</code>) oraz 359
          błedów drugorzędnych.
        </p>
        <p>
          Inne narzędzia takie <em>top</em> oraz <em>ps</em> również mogą 
          wyświetlać informacje o błędach stron pamięć, w przypadku polecenia
          <em>top</em> należy włączyć wyświetlanie <em>nMaj</em> oraz
          <em>nMin</em>, aby przejść do konfiguracji należy nacisnąć literę
          <em>f</em>, a następnie postępować zgodnie z instrukcją. Program
          <em>ps</em> pozwala na wyświetlenie błędów strony poprzez podanie
          niestandardowego wyświetlania kolumn (opcja <em>-o</em>) kolumny
          noszą kolejno nazwy <em>maj_ftl</em> i <em>min_ftl</em>.
        </p>
        <h2 id="8.10.vmstat">8.10. Monitorowanie wydajności za pomocą polecenia vmstat</h2>
        <p>
          Polecenie <em>vmstat</em> pozwala na monitorowanie wielu aspektów
          wydajności systemu, a jest jednym z najstarszych narzędzi tego typu.
          Dane wyświetlane również pozostawiają wiele do życzenia i osoba
          nie mająca styczności z tym narzędziem, może uznać je za mało
          czytelne.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ vmstat 2
proc. -----------pamięć---------- ---swap-- ---we/wy--- -system-- ------cpu-----
dz bl   swap  wolna  bufor  cache   si   so    bi    bo   in   cs uż sy be io sk
 0  0      0 861264  13196 5331448    0    0    56     3  189  210 13  4 83  0  0
 0  0      0 861112  13196 5330624    0    0     0     0 2071 4073  8  4 88  0  0
 0  0      0 861712  13196 5330664    0    0     0     0 1944 3661  7  4 88  0  0
 0  0      0 862012  13196 5330608    0    0     0     0 2007 3866  7  4 89  0  0
</pre>
        <p>
          Polecenie to przyjmuje jako argument interwał czasowym co ile sekund
          ma wyświetlać nowe statystki. Każda linia to w tym przypadku
          statustyki pobrane co dwie sekundy. Wyjście polecenia zawiera
          tematyczne kolumny. Pierwszą z nich są procesy, ta kolumna zawiera
          jeszcze dwie inne kolumny wskazujące procesy gotowe do uruchomienia
          (<code class="code-inline">dz</code>) oraz te
          zablokowane (<code class="code-inline">bl</code>). W następnej 
          kolumnie znajdują się informacje na temat
          pamięci, a w niej informacje o wykorzystaniu przestrzeni wymiany
          (<code class="code-inline">swap</code>), ilości wolnej
          pamięci, pamięci przez naczonej na bufor oraz pamięci przeznaczonej
          na pamięć podręczną. W trzeciej kolumnie znajdują się informacje o
          przestrzeni wymiany, ile stron zostało przeniesionych na dysk
          (<code class="code-inline">si</code>) oraz ile stron zostało
          załadowanych z dysku do pamięci 
          (<code class="code-inline">so<code>). Czwarta kolumna zawiera 
          informacje o użyciu urządzeń wejścia-wyjścia, dane odczytane z dysku
          (<code class="code-inline">bi</code>) oraz dane zapisane na dysku
          (<code class="code-inline">bo</code>). Piąta kolumna zwiera
          informacje systemowe, w niej znajdują się liczniki wywołań
          systemowych (<code class="code-inline">in</code>) oraz przełączeń
          kontekstu (<code class="code-inline">cs</code>). Ostatnia kolumna
          zawiera procentowe zużycie czasu procesora dla kolejno: aplikacji
          użytkownika (<code class="code-inline">uż</code>), jądra oraz obsługi
          procesów (<code class="code-inline">sy</code>), stanu bezczynności
          (<code class="code-inline">be</code>), czasu przeznaczonego na
          obsługę operacji wejścia-wyjścia 
          (<code class="code-inline">io</code>), czasu skradziony wirtualnej
          maszynie (<code class="code-inline">sk</code>).
        </p>
        <p>
          Polecenie to zawiera wiele przydanych opcji, które są zawarte na
          stronie podręcznika programu. Jak na przykład opcję
          <strong>-d</strong>, która pozwala na monitorowanie dysków.
        </p>
        <h2 id="8.11.iomonitoring">8.11. Monitorowanie operacji wejścia-wyjścia</h2>
        <p>
          Na dystrybucje Linuksa dostępnych jest kilka narzędzi służących do
          monitorowania operacji wejścia-wyjścia, które w dużej mierze są
          operacjami dyskowymi.
        </p>
        <h3 id="8.11.1.iostat">8.11.1. Polecenie iostat</h3>
        <p>
          Jedno znich przypomina omawiany w wcześniejszym
          podrozdziale program <em>vmstat</em>, a jest nim polecenie
          <strong>iostat</strong>, to polecenie może nie być domyślnie
          zainstalowane i jeśli chcemy z niego skorzystać to należy je
          zainstalować. Pakiet zawierający ten program zajduje się w
          repozytoriach <em>Debiana</em> po nazwą <em>sysstat</em>. Poniżej
          znajduje się przykład:
        </p>
<code class="code-block">
xf0r3m@immudex:/media/xf0r3m/immudex_crypt0$ iostat 
Linux 5.10.0-20-amd64 (immudex) 	10.01.2023 	_x86_64_	(4 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
          17,27    0,00    4,22    0,01    0,00   78,50

Device             tps    kB_read/s    kB_wrtn/s    kB_dscd/s    kB_read    kB_wrtn    kB_dscd
dm-0              0,35         3,52         0,61         0,00      25273       4396          0
loop0             6,27        73,04         0,00         0,00     524237          0          0
sda               1,55        66,41         0,56         0,00     476690       4048          0
</code>
        <p>
          Oryginalny wydruk jest kolorowy. Ciemno niebieskie pola, mogą być
          trochę nieczytelne, ale oznaczają one wartość
          <code class="code-inline">0,00</code>. Pierwsza linia zawiera nazwę
          jądra, nazwę hosta w nawiasie, aktualną datę, architekturę procesora
          oraz liczbę logicznych procesorów (rdzenie/wątków). Druga oraz
          trzecia linia zawierają średnie zużycie czasu procesora oraz 
          objaśnienia tych wartości. Poniżej znajduje się tabelka
          przedstawiająca urządzenia (<code class="code-inline">Device</code>),
          liczba transferów na sekundę (liczba operacji wejścia-wyjścia na
          sekundę wystosowana wobec urządzenia, 
          <code class="code-inline">tps</code>); liczba danych odczytanych na
          sekundę (<code class="code-inline">kB_read/s</code>); liczba danych
          zapisanych na sekundę (<code class="code-inline">kB_write/s</code>);
          liczba danych odrzuconych na sekundę dla urządznia
          (<code class="code-inline">kB_dscd</code>), ostatnie trzy kolmny
          wrażają podobne wartości tylko zamiast prędkości jest przedstawiona
          tam łączna ilość.
        </p>
        <p>
          Domyślnie dane wyrażane są w kilobajtach, jak prawie wszystko w
          systemie co dotyczy pamięci masowych, jednostki możemy przeskalować
          do megabajtów za pomocą opcji <strong>-m</strong>, natomiast za
          pomocą opcji <strong>-p</strong> wraz z argumentem <em>ALL</em>
          możemy wyświetlić statystki dla wszystkich urządzeń blokowych
          dostępnych w systemie. Podobnie do <em>vmstat</em> podanie gołej
          liczby jako argumentu spowoduje włączenie interwału czasowego o 
          podanej wartości. Więcej opcji oraz bardziej szczegółowe wyjaśnienia
          znajdują się na stronie podręcznika programu.
        </p>
        <h3 id="8.11.2.iotop">8.11.2. Polecenie iotop</h3>
        <p>
          Innym poleceniem służącym do monitorowania operacji wejścia-wyjścia
          jest program <strong>iotop</strong>, zasada działania tego programu
          jest podobna do znanego nam już narzędzia <em>top</em> tylko tym
          razem zamiast skupiać się na procesach, położono nacisk na operacje
          wejścia wyjścia.
        </p>
<pre class="code-block">
xf0r3m@immudex:~$ sudo iotop
Total DISK READ:         0.00 B/s | Total DISK WRITE:         0.00 B/s
Current DISK READ:       0.00 B/s | Current DISK WRITE:       0.00 B/s
    TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO&gt;    COMMAND                            
      1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
      2 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kthreadd]
      3 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_gp]
      4 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_par_gp]
      6 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [kworker/0:0H-events_highpri]
      8 be/0 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [mm_percpu_wq]
      9 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_tasks_rude_]
     10 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_tasks_trace]
     11 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/0]
     12 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [rcu_sched]
     13 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/0]
     15 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/0]
     16 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [cpuhp/1]
     17 rt/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [migration/1]
     18 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % [ksoftirqd/1]
</pre>
        <p>
          Jak możemy zauważyć to polecenie wyświetla nam identyfikatory wątków.
          Jest to jedno z nielicznych narzędzi wyświetlających wyświetlających
          wątki, ponieważ często procesy dzielą się na nie aby własnie
          zająć się obsługą wejścia-wyjścia. Inna kolumną wartą opisania jest
          <code class="code-inline">PRIO</code>, podobnie jak procesy jądro
          stara się szergować operacje wejścia-wyjścia. Przyczym priorytet
          tutaj dzieli się na dwie wartości, klasę oraz poziom samego
          priorytetu. Wątki o priorytecie
          <code class="code-inline">be/0</code> otrzymają więcej czasu 
          procesora na realizacje operacji niż wątki z priorytetem
          <code class="code-inline">be/4</code>. Samych klas priorytetów
          mogą wystąpić trzy rodzaje takie jak:
        </p>
        <ul>
          <li><strong>be</strong>(<strong>best-effort</strong>) - w przypadku
            tego priorytetu jądro stara się jak najbardziej sprawiedliwie
            uszeregować operacje wejścia-wyjścia. Tę klasę posiada większość
            operacji.</li>
          <li><strong>rt</strong>(<strong>real-time</strong>) - Jądro
            bezwarunkowo szereguje operacje opatrzone tą klasą ponad każdą
            inną.</li>
          <li><strong>idle</strong>, klasa bezczynności. Jądro będzie wykonywać
            operacje z tą klasą, tylko wtedy gdy nie jest wykonywana żadna 
            inna operacja. Ta klasa nie posiada żadnych poziomów, będąc
            zarazem najniższym priorytetem.</li>
        </ul>
        <p>
          Do manipulacji priortetami operacji wejścia-wyjścia służy polecenie
          <strong>ionice</strong>, więcej na jego temat znajdziemy na stronie
          podręcznika.
        </p>
      </div>
			<p style="margin: 15px; padding: 0; outline: 0;">
				2022; COPYLEFT; ALL RIGHTS REVERSED;
			</p>
		</body>
	</html>
